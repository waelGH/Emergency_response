{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this script, we split the data set into train (70%) and test (30%) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/wkhal001/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "##### imports ############\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import joblib\n",
    "\n",
    "import os\n",
    "import math\n",
    "\n",
    "import torch\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import AdamW, XLNetTokenizer, XLNetModel, XLNetLMHeadModel, XLNetConfig\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm, trange\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "#from utils_crisis_classification import clean_text\n",
    "from preprocessing_step import clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wkhal001/envs/Twitter_crisis/lib/python3.7/site-packages/tensorflow_addons/utils/ensure_tf_install.py:68: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.2.0 and strictly below 2.4.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.8.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  UserWarning,\n"
     ]
    }
   ],
   "source": [
    "from string import punctuation\n",
    "from os import listdir\n",
    "from numpy import array\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import string\n",
    "\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as pn\n",
    "from numpy import mean\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import string\n",
    "\n",
    "import collections\n",
    "from collections import Counter\n",
    "\n",
    "from string import punctuation\n",
    "from os import listdir\n",
    "from numpy import array\n",
    "\n",
    "from pickle import load\n",
    "from numpy import array\n",
    "\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers.merge import concatenate\n",
    "\n",
    "\n",
    "from keras.layers import LSTM\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "from numpy import mean\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import statistics as s\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### imports ############\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import joblib\n",
    "\n",
    "import os\n",
    "import math\n",
    "\n",
    "import torch\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import AdamW, XLNetTokenizer, XLNetModel, XLNetLMHeadModel, XLNetConfig\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm, trange\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "#from utils_crisis_classification import clean_text\n",
    "\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from transformers import AdamW\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import transformers\n",
    "from transformers import AutoModel, BertTokenizerFast\n",
    "\n",
    "# specify GPU\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "from Baseline_Models import Display_metrics,Display_classification_report,Confusion_matrix\n",
    "from keras.backend import clear_session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data split for experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Read harvey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeledDF=pd.read_csv(\"/home/wkhal001/Desktop/data_rescue_mining/labeled_ds_Corrected_csv.csv\") \n",
    "del labeledDF['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>status_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>address</th>\n",
       "      <th>loc</th>\n",
       "      <th>situ</th>\n",
       "      <th>save</th>\n",
       "      <th>sos</th>\n",
       "      <th>sos.pred</th>\n",
       "      <th>sos.correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>9.021280e+17</td>\n",
       "      <td>8/28/2017 11:19</td>\n",
       "      <td>#Harvey floods TV station #KHOU in #Houston. h...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>9.022140e+17</td>\n",
       "      <td>8/28/2017 16:58</td>\n",
       "      <td>@RandiRhodes RR call him out for visiting SA, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9.018300e+17</td>\n",
       "      <td>8/27/2017 15:35</td>\n",
       "      <td>Wow a tv station is flooding in Houston! So sc...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>9.023740e+17</td>\n",
       "      <td>8/29/2017 3:36</td>\n",
       "      <td>My son, dil &amp;amp; 2 grandkids in grand lakes, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>9.021410e+17</td>\n",
       "      <td>8/28/2017 12:09</td>\n",
       "      <td>is the beltway still flooded? ya boy need to g...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5787</th>\n",
       "      <td>5788</td>\n",
       "      <td>9.023810e+17</td>\n",
       "      <td>8/29/2017 4:04</td>\n",
       "      <td>Around 10,000,000,000,000 gallons of water fro...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5788</th>\n",
       "      <td>5789</td>\n",
       "      <td>9.023830e+17</td>\n",
       "      <td>8/29/2017 4:09</td>\n",
       "      <td>The road to my residence is flooded. Thank God...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5789</th>\n",
       "      <td>5790</td>\n",
       "      <td>9.023830e+17</td>\n",
       "      <td>8/29/2017 4:09</td>\n",
       "      <td>Texas road closures and flooding kept up to da...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5790</th>\n",
       "      <td>5791</td>\n",
       "      <td>9.023860e+17</td>\n",
       "      <td>8/29/2017 4:22</td>\n",
       "      <td>@HellerWeather Tim, any maps to show where flo...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5791</th>\n",
       "      <td>5792</td>\n",
       "      <td>9.023870e+17</td>\n",
       "      <td>8/29/2017 4:25</td>\n",
       "      <td>lrt more people died on the road trying to eva...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5792 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id     status_id       created_at  \\\n",
       "0        1  9.021280e+17  8/28/2017 11:19   \n",
       "1        2  9.022140e+17  8/28/2017 16:58   \n",
       "2        3  9.018300e+17  8/27/2017 15:35   \n",
       "3        4  9.023740e+17   8/29/2017 3:36   \n",
       "4        5  9.021410e+17  8/28/2017 12:09   \n",
       "...    ...           ...              ...   \n",
       "5787  5788  9.023810e+17   8/29/2017 4:04   \n",
       "5788  5789  9.023830e+17   8/29/2017 4:09   \n",
       "5789  5790  9.023830e+17   8/29/2017 4:09   \n",
       "5790  5791  9.023860e+17   8/29/2017 4:22   \n",
       "5791  5792  9.023870e+17   8/29/2017 4:25   \n",
       "\n",
       "                                                   text  address  loc  situ  \\\n",
       "0     #Harvey floods TV station #KHOU in #Houston. h...        0  NaN     0   \n",
       "1     @RandiRhodes RR call him out for visiting SA, ...        0  NaN     0   \n",
       "2     Wow a tv station is flooding in Houston! So sc...        0  NaN     1   \n",
       "3     My son, dil &amp; 2 grandkids in grand lakes, ...        0  NaN     0   \n",
       "4     is the beltway still flooded? ya boy need to g...        0  NaN     0   \n",
       "...                                                 ...      ...  ...   ...   \n",
       "5787  Around 10,000,000,000,000 gallons of water fro...        0  NaN     0   \n",
       "5788  The road to my residence is flooded. Thank God...        0  NaN     0   \n",
       "5789  Texas road closures and flooding kept up to da...        0  NaN     0   \n",
       "5790  @HellerWeather Tim, any maps to show where flo...        1  NaN     0   \n",
       "5791  lrt more people died on the road trying to eva...        0  NaN     0   \n",
       "\n",
       "      save  sos  sos.pred  sos.correct  \n",
       "0        0    0         0            0  \n",
       "1        0    0         0            0  \n",
       "2        0    0         0            0  \n",
       "3        1    1         1            0  \n",
       "4        0    0         0            0  \n",
       "...    ...  ...       ...          ...  \n",
       "5787     0    0         0            0  \n",
       "5788     0    0         0            0  \n",
       "5789     0    0         0            0  \n",
       "5790     0    0         0            0  \n",
       "5791     0    0         0            0  \n",
       "\n",
       "[5792 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeledDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### clean our data set\n",
    "labeledDF['cleaned_tweet'] = labeledDF['text'].apply(lambda x: \" \".join(clean_text(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>status_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>address</th>\n",
       "      <th>loc</th>\n",
       "      <th>situ</th>\n",
       "      <th>save</th>\n",
       "      <th>sos</th>\n",
       "      <th>sos.pred</th>\n",
       "      <th>sos.correct</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>9.021280e+17</td>\n",
       "      <td>8/28/2017 11:19</td>\n",
       "      <td>#Harvey floods TV station #KHOU in #Houston. h...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>harvey floods tv station khou houston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>9.022140e+17</td>\n",
       "      <td>8/28/2017 16:58</td>\n",
       "      <td>@RandiRhodes RR call him out for visiting SA, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>randirhodes rr call visiting sa flooding mayor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9.018300e+17</td>\n",
       "      <td>8/27/2017 15:35</td>\n",
       "      <td>Wow a tv station is flooding in Houston! So sc...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>wow tv station flooding houston scary sad rain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>9.023740e+17</td>\n",
       "      <td>8/29/2017 3:36</td>\n",
       "      <td>My son, dil &amp;amp; 2 grandkids in grand lakes, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>son dil amp 2 grandkids grand lakes katy tx wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>9.021410e+17</td>\n",
       "      <td>8/28/2017 12:09</td>\n",
       "      <td>is the beltway still flooded? ya boy need to g...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>beltway still flooded ya boy need go pay bills ðŸ˜’</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5787</th>\n",
       "      <td>5788</td>\n",
       "      <td>9.023810e+17</td>\n",
       "      <td>8/29/2017 4:04</td>\n",
       "      <td>Around 10,000,000,000,000 gallons of water fro...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>around 10000000000000 gallons water harvey ins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5788</th>\n",
       "      <td>5789</td>\n",
       "      <td>9.023830e+17</td>\n",
       "      <td>8/29/2017 4:09</td>\n",
       "      <td>The road to my residence is flooded. Thank God...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>road residence flooded thank god left safe sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5789</th>\n",
       "      <td>5790</td>\n",
       "      <td>9.023830e+17</td>\n",
       "      <td>8/29/2017 4:09</td>\n",
       "      <td>Texas road closures and flooding kept up to da...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>texas road closures flooding kept date</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5790</th>\n",
       "      <td>5791</td>\n",
       "      <td>9.023860e+17</td>\n",
       "      <td>8/29/2017 4:22</td>\n",
       "      <td>@HellerWeather Tim, any maps to show where flo...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>hellerweather tim maps show flooding would mas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5791</th>\n",
       "      <td>5792</td>\n",
       "      <td>9.023870e+17</td>\n",
       "      <td>8/29/2017 4:25</td>\n",
       "      <td>lrt more people died on the road trying to eva...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>lrt people died road trying evacuate hurricane...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5792 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id     status_id       created_at  \\\n",
       "0        1  9.021280e+17  8/28/2017 11:19   \n",
       "1        2  9.022140e+17  8/28/2017 16:58   \n",
       "2        3  9.018300e+17  8/27/2017 15:35   \n",
       "3        4  9.023740e+17   8/29/2017 3:36   \n",
       "4        5  9.021410e+17  8/28/2017 12:09   \n",
       "...    ...           ...              ...   \n",
       "5787  5788  9.023810e+17   8/29/2017 4:04   \n",
       "5788  5789  9.023830e+17   8/29/2017 4:09   \n",
       "5789  5790  9.023830e+17   8/29/2017 4:09   \n",
       "5790  5791  9.023860e+17   8/29/2017 4:22   \n",
       "5791  5792  9.023870e+17   8/29/2017 4:25   \n",
       "\n",
       "                                                   text  address  loc  situ  \\\n",
       "0     #Harvey floods TV station #KHOU in #Houston. h...        0  NaN     0   \n",
       "1     @RandiRhodes RR call him out for visiting SA, ...        0  NaN     0   \n",
       "2     Wow a tv station is flooding in Houston! So sc...        0  NaN     1   \n",
       "3     My son, dil &amp; 2 grandkids in grand lakes, ...        0  NaN     0   \n",
       "4     is the beltway still flooded? ya boy need to g...        0  NaN     0   \n",
       "...                                                 ...      ...  ...   ...   \n",
       "5787  Around 10,000,000,000,000 gallons of water fro...        0  NaN     0   \n",
       "5788  The road to my residence is flooded. Thank God...        0  NaN     0   \n",
       "5789  Texas road closures and flooding kept up to da...        0  NaN     0   \n",
       "5790  @HellerWeather Tim, any maps to show where flo...        1  NaN     0   \n",
       "5791  lrt more people died on the road trying to eva...        0  NaN     0   \n",
       "\n",
       "      save  sos  sos.pred  sos.correct  \\\n",
       "0        0    0         0            0   \n",
       "1        0    0         0            0   \n",
       "2        0    0         0            0   \n",
       "3        1    1         1            0   \n",
       "4        0    0         0            0   \n",
       "...    ...  ...       ...          ...   \n",
       "5787     0    0         0            0   \n",
       "5788     0    0         0            0   \n",
       "5789     0    0         0            0   \n",
       "5790     0    0         0            0   \n",
       "5791     0    0         0            0   \n",
       "\n",
       "                                          cleaned_tweet  \n",
       "0                harvey floods tv station khou houston   \n",
       "1     randirhodes rr call visiting sa flooding mayor...  \n",
       "2     wow tv station flooding houston scary sad rain...  \n",
       "3     son dil amp 2 grandkids grand lakes katy tx wo...  \n",
       "4      beltway still flooded ya boy need go pay bills ðŸ˜’  \n",
       "...                                                 ...  \n",
       "5787  around 10000000000000 gallons water harvey ins...  \n",
       "5788  road residence flooded thank god left safe sta...  \n",
       "5789            texas road closures flooding kept date   \n",
       "5790  hellerweather tim maps show flooding would mas...  \n",
       "5791  lrt people died road trying evacuate hurricane...  \n",
       "\n",
       "[5792 rows x 12 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeledDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract useful columns \n",
    "df_training = labeledDF[['text','cleaned_tweet','sos.correct']]\n",
    "df_training.columns= ['non_cleaned_text','text','label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>non_cleaned_text</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#Harvey floods TV station #KHOU in #Houston. h...</td>\n",
       "      <td>harvey floods tv station khou houston</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@RandiRhodes RR call him out for visiting SA, ...</td>\n",
       "      <td>randirhodes rr call visiting sa flooding mayor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wow a tv station is flooding in Houston! So sc...</td>\n",
       "      <td>wow tv station flooding houston scary sad rain...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My son, dil &amp;amp; 2 grandkids in grand lakes, ...</td>\n",
       "      <td>son dil amp 2 grandkids grand lakes katy tx wo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>is the beltway still flooded? ya boy need to g...</td>\n",
       "      <td>beltway still flooded ya boy need go pay bills ðŸ˜’</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5787</th>\n",
       "      <td>Around 10,000,000,000,000 gallons of water fro...</td>\n",
       "      <td>around 10000000000000 gallons water harvey ins...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5788</th>\n",
       "      <td>The road to my residence is flooded. Thank God...</td>\n",
       "      <td>road residence flooded thank god left safe sta...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5789</th>\n",
       "      <td>Texas road closures and flooding kept up to da...</td>\n",
       "      <td>texas road closures flooding kept date</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5790</th>\n",
       "      <td>@HellerWeather Tim, any maps to show where flo...</td>\n",
       "      <td>hellerweather tim maps show flooding would mas...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5791</th>\n",
       "      <td>lrt more people died on the road trying to eva...</td>\n",
       "      <td>lrt people died road trying evacuate hurricane...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5792 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       non_cleaned_text  \\\n",
       "0     #Harvey floods TV station #KHOU in #Houston. h...   \n",
       "1     @RandiRhodes RR call him out for visiting SA, ...   \n",
       "2     Wow a tv station is flooding in Houston! So sc...   \n",
       "3     My son, dil &amp; 2 grandkids in grand lakes, ...   \n",
       "4     is the beltway still flooded? ya boy need to g...   \n",
       "...                                                 ...   \n",
       "5787  Around 10,000,000,000,000 gallons of water fro...   \n",
       "5788  The road to my residence is flooded. Thank God...   \n",
       "5789  Texas road closures and flooding kept up to da...   \n",
       "5790  @HellerWeather Tim, any maps to show where flo...   \n",
       "5791  lrt more people died on the road trying to eva...   \n",
       "\n",
       "                                                   text  label  \n",
       "0                harvey floods tv station khou houston       0  \n",
       "1     randirhodes rr call visiting sa flooding mayor...      0  \n",
       "2     wow tv station flooding houston scary sad rain...      0  \n",
       "3     son dil amp 2 grandkids grand lakes katy tx wo...      0  \n",
       "4      beltway still flooded ya boy need go pay bills ðŸ˜’      0  \n",
       "...                                                 ...    ...  \n",
       "5787  around 10000000000000 gallons water harvey ins...      0  \n",
       "5788  road residence flooded thank god left safe sta...      0  \n",
       "5789            texas road closures flooding kept date       0  \n",
       "5790  hellerweather tim maps show flooding would mas...      0  \n",
       "5791  lrt people died road trying evacuate hurricane...      0  \n",
       "\n",
       "[5792 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5539\n",
       "1     253\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_training['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Split data set (unified accross all experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length training...... 4054\n",
      "Length testing...... 1738\n"
     ]
    }
   ],
   "source": [
    "################ Split data into: 70% training and 30% testing #####################\n",
    "Train_X, Test_X, Train_Y, Test_Y = train_test_split(df_training,df_training['label'], \n",
    "                                                                    random_state=2018, \n",
    "                                                                    test_size=0.3,\n",
    "                                                                    stratify=df_training['label'])\n",
    "\n",
    "print('Length training......',len(Train_Y))\n",
    "print('Length testing......',len(Test_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>non_cleaned_text</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5667</th>\n",
       "      <td>If you want to figure out the road situation i...</td>\n",
       "      <td>want figure road situation area check harveyfl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>The Wall Street Journal: Houston flooding expe...</td>\n",
       "      <td>wall street journal houston flooding expected ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3312</th>\n",
       "      <td>@cinnamonfire8 oh and that white oak and houst...</td>\n",
       "      <td>cinnamonfire8 oh white oak houston ave floodin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5021</th>\n",
       "      <td>Guys, I'm south of the Conroe dam. Where is ev...</td>\n",
       "      <td>guys im south conroe dam everyone evacuating g...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5104</th>\n",
       "      <td>12:43pm.. flooding in Breaux Bridge (St. Marti...</td>\n",
       "      <td>1243pm flooding breaux bridge st martin parish...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Heavy Rain, Flooding Cause Concern Across Tamp...</td>\n",
       "      <td>heavy rain flooding cause concern across tampa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3755</th>\n",
       "      <td>The Wall Street Journal: Hurricane Harvey like...</td>\n",
       "      <td>wall street journal hurricane harvey likely sn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5438</th>\n",
       "      <td>Please DO NOT drive into the water if you can ...</td>\n",
       "      <td>please drive water see road please harvey</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5419</th>\n",
       "      <td>President Trump Tweets About 2016 Election and...</td>\n",
       "      <td>president trump tweets 2016 election border wa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194</th>\n",
       "      <td>@KHOUBlake11 #Houston: Dam opened, flooding do...</td>\n",
       "      <td>khoublake11 houston dam opened flooding downst...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4054 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       non_cleaned_text  \\\n",
       "5667  If you want to figure out the road situation i...   \n",
       "813   The Wall Street Journal: Houston flooding expe...   \n",
       "3312  @cinnamonfire8 oh and that white oak and houst...   \n",
       "5021  Guys, I'm south of the Conroe dam. Where is ev...   \n",
       "5104  12:43pm.. flooding in Breaux Bridge (St. Marti...   \n",
       "...                                                 ...   \n",
       "48    Heavy Rain, Flooding Cause Concern Across Tamp...   \n",
       "3755  The Wall Street Journal: Hurricane Harvey like...   \n",
       "5438  Please DO NOT drive into the water if you can ...   \n",
       "5419  President Trump Tweets About 2016 Election and...   \n",
       "1194  @KHOUBlake11 #Houston: Dam opened, flooding do...   \n",
       "\n",
       "                                                   text  label  \n",
       "5667  want figure road situation area check harveyfl...      0  \n",
       "813   wall street journal houston flooding expected ...      0  \n",
       "3312  cinnamonfire8 oh white oak houston ave floodin...      0  \n",
       "5021  guys im south conroe dam everyone evacuating g...      0  \n",
       "5104  1243pm flooding breaux bridge st martin parish...      0  \n",
       "...                                                 ...    ...  \n",
       "48    heavy rain flooding cause concern across tampa...      0  \n",
       "3755  wall street journal hurricane harvey likely sn...      0  \n",
       "5438          please drive water see road please harvey      0  \n",
       "5419  president trump tweets 2016 election border wa...      0  \n",
       "1194  khoublake11 houston dam opened flooding downst...      0  \n",
       "\n",
       "[4054 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>non_cleaned_text</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1094</th>\n",
       "      <td>Photos of flooding at Villas Dr./Golden Beach ...</td>\n",
       "      <td>photos flooding villas drgolden beach sent us ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1762</th>\n",
       "      <td>Hurricane Harvey videos | Fort Worth Star-Tele...</td>\n",
       "      <td>hurricane harvey videos fort worth startelegra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2034</th>\n",
       "      <td>11830 Greenspark Ln. - Awaiting Update. #Houst...</td>\n",
       "      <td>11830 greenspark ln awaiting update houston ha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2951</th>\n",
       "      <td>@ManBoobiees @LukeBryanSucks @klstorey Oh and ...</td>\n",
       "      <td>manboobiees lukebryansucks klstorey oh also ho...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5520</th>\n",
       "      <td>Guys, this storm is no joke ðŸ˜³#HurricaneHarvey ...</td>\n",
       "      <td>guys storm joke ðŸ˜³hurricaneharvey fl side effec...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4914</th>\n",
       "      <td>@jackmcme @matthaig1 Indeed, and sometimes dro...</td>\n",
       "      <td>jackmcme matthaig1 indeed sometimes drought fo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4737</th>\n",
       "      <td>My family is #blessed to have spent #Hurricane...</td>\n",
       "      <td>family blessed spent hurricaneharvey south for...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5435</th>\n",
       "      <td>HARVEY UPDATE: Williamson County officials mon...</td>\n",
       "      <td>harvey update williamson county officials moni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3007</th>\n",
       "      <td>Please continue to keep Houston in your though...</td>\n",
       "      <td>please continue keep houston thoughts amp pray...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>Houston, Texas freeway sign nearly submerged a...</td>\n",
       "      <td>houston texas freeway sign nearly submerged am...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1738 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       non_cleaned_text  \\\n",
       "1094  Photos of flooding at Villas Dr./Golden Beach ...   \n",
       "1762  Hurricane Harvey videos | Fort Worth Star-Tele...   \n",
       "2034  11830 Greenspark Ln. - Awaiting Update. #Houst...   \n",
       "2951  @ManBoobiees @LukeBryanSucks @klstorey Oh and ...   \n",
       "5520  Guys, this storm is no joke ðŸ˜³#HurricaneHarvey ...   \n",
       "...                                                 ...   \n",
       "4914  @jackmcme @matthaig1 Indeed, and sometimes dro...   \n",
       "4737  My family is #blessed to have spent #Hurricane...   \n",
       "5435  HARVEY UPDATE: Williamson County officials mon...   \n",
       "3007  Please continue to keep Houston in your though...   \n",
       "1258  Houston, Texas freeway sign nearly submerged a...   \n",
       "\n",
       "                                                   text  label  \n",
       "1094  photos flooding villas drgolden beach sent us ...      0  \n",
       "1762  hurricane harvey videos fort worth startelegra...      0  \n",
       "2034  11830 greenspark ln awaiting update houston ha...      0  \n",
       "2951  manboobiees lukebryansucks klstorey oh also ho...      0  \n",
       "5520  guys storm joke ðŸ˜³hurricaneharvey fl side effec...      0  \n",
       "...                                                 ...    ...  \n",
       "4914  jackmcme matthaig1 indeed sometimes drought fo...      0  \n",
       "4737  family blessed spent hurricaneharvey south for...      0  \n",
       "5435  harvey update williamson county officials moni...      0  \n",
       "3007  please continue keep houston thoughts amp pray...      0  \n",
       "1258  houston texas freeway sign nearly submerged am...      0  \n",
       "\n",
       "[1738 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3877\n",
       "1     177\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_X['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1662\n",
       "1      76\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_X['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### save split data set for final evaluation #####\n",
    "# train_path = '/home/wkhal001/Crisis-classification/scripts-rescue-detection/__Comparison_thesis/Data/train_harvey_final_evaluation.csv'\n",
    "# Train_X.to_csv(train_path,index=False)\n",
    "\n",
    "# #### save split data set for final evaluation #####\n",
    "# test_path = '/home/wkhal001/Crisis-classification/scripts-rescue-detection/__Comparison_thesis/Data/test_harvey_final_evaluation.csv'\n",
    "# Test_X.to_csv(test_path,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Assign training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_validation = Train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>non_cleaned_text</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>If you want to figure out the road situation i...</td>\n",
       "      <td>want figure road situation area check harveyfl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Wall Street Journal: Houston flooding expe...</td>\n",
       "      <td>wall street journal houston flooding expected ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@cinnamonfire8 oh and that white oak and houst...</td>\n",
       "      <td>cinnamonfire8 oh white oak houston ave floodin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Guys, I'm south of the Conroe dam. Where is ev...</td>\n",
       "      <td>guys im south conroe dam everyone evacuating g...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12:43pm.. flooding in Breaux Bridge (St. Marti...</td>\n",
       "      <td>1243pm flooding breaux bridge st martin parish...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4934</th>\n",
       "      <td>please help my friend in a wheelchair flooded ...</td>\n",
       "      <td>please help friend wheelchair flooded home plz...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4935</th>\n",
       "      <td>@HCSOTexas @HoustonPolice Elderly couple await...</td>\n",
       "      <td>hcsotexas houstonpolice elderly couple awaitin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4936</th>\n",
       "      <td>Life threatening situation!!!  9231 Oak knoll ...</td>\n",
       "      <td>life threatening situation 9231 oak knoll rd h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4937</th>\n",
       "      <td>@TrillChino09 A family of 6 adults and 4 kids ...</td>\n",
       "      <td>trillchino09 family 6 adults 4 kids need boat ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4938</th>\n",
       "      <td>@RedCross @USNationalGuard @USCG #CajunNavy 34...</td>\n",
       "      <td>redcross usnationalguard uscg cajunnavy 3406 o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4939 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       non_cleaned_text  \\\n",
       "0     If you want to figure out the road situation i...   \n",
       "1     The Wall Street Journal: Houston flooding expe...   \n",
       "2     @cinnamonfire8 oh and that white oak and houst...   \n",
       "3     Guys, I'm south of the Conroe dam. Where is ev...   \n",
       "4     12:43pm.. flooding in Breaux Bridge (St. Marti...   \n",
       "...                                                 ...   \n",
       "4934  please help my friend in a wheelchair flooded ...   \n",
       "4935  @HCSOTexas @HoustonPolice Elderly couple await...   \n",
       "4936  Life threatening situation!!!  9231 Oak knoll ...   \n",
       "4937  @TrillChino09 A family of 6 adults and 4 kids ...   \n",
       "4938  @RedCross @USNationalGuard @USCG #CajunNavy 34...   \n",
       "\n",
       "                                                   text  label  \n",
       "0     want figure road situation area check harveyfl...      0  \n",
       "1     wall street journal houston flooding expected ...      0  \n",
       "2     cinnamonfire8 oh white oak houston ave floodin...      0  \n",
       "3     guys im south conroe dam everyone evacuating g...      0  \n",
       "4     1243pm flooding breaux bridge st martin parish...      0  \n",
       "...                                                 ...    ...  \n",
       "4934  please help friend wheelchair flooded home plz...      1  \n",
       "4935  hcsotexas houstonpolice elderly couple awaitin...      1  \n",
       "4936  life threatening situation 9231 oak knoll rd h...      1  \n",
       "4937  trillchino09 family 6 adults 4 kids need boat ...      1  \n",
       "4938  redcross usnationalguard uscg cajunnavy 3406 o...      1  \n",
       "\n",
       "[4939 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_training_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### save grids ##########\n",
    "ls_grid = [save_sets[0]['grid'],save_sets[1]['grid'],save_sets[2]['grid'],save_sets[3]['grid'],save_sets[4]['grid']]\n",
    "\n",
    "path = \"/home/wkhal001/Crisis-classification/scripts-rescue-detection/__comparison_new_experimental_design/SVM-CV\"\n",
    "\n",
    "iteration =1\n",
    "for g in ls_grid:  \n",
    "    save_path = path + \"/\" + \"grid-CV-iter\"+ str(iteration)\n",
    "    joblib.dump(g, save_path)\n",
    "    iteration = iteration + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### load grids ##########\n",
    "import joblib\n",
    "\n",
    "grid1 = joblib.load(\"/home/wkhal001/Crisis-classification/scripts-rescue-detection/__comparison_new_experimental_design/SVM-CV/500_uni_bi(2)/grid-CV-iter1\")\n",
    "grid2 = joblib.load(\"/home/wkhal001/Crisis-classification/scripts-rescue-detection/__comparison_new_experimental_design/SVM-CV/500_uni_bi(2)/grid-CV-iter2\")\n",
    "grid3 = joblib.load(\"/home/wkhal001/Crisis-classification/scripts-rescue-detection/__comparison_new_experimental_design/SVM-CV/500_uni_bi(2)/grid-CV-iter3\")\n",
    "grid4 = joblib.load(\"/home/wkhal001/Crisis-classification/scripts-rescue-detection/__comparison_new_experimental_design/SVM-CV/500_uni_bi(2)/grid-CV-iter4\")\n",
    "grid5 = joblib.load(\"/home/wkhal001/Crisis-classification/scripts-rescue-detection/__comparison_new_experimental_design/SVM-CV/500_uni_bi(2)/grid-CV-iter5\")\n",
    "\n",
    "ls_grid = [grid1,grid2,grid3,grid4,grid5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### best models and scores\n",
    "best_models = [g.best_params_ for g in ls_grid]\n",
    "best_f_scores = [g.best_score_ for g in ls_grid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'C': 10, 'degree': 2, 'gamma': 0.1, 'kernel': 'rbf'},\n",
       " {'C': 10, 'degree': 2, 'gamma': 0.1, 'kernel': 'rbf'},\n",
       " {'C': 15, 'degree': 2, 'gamma': 0.1, 'kernel': 'rbf'},\n",
       " {'C': 20, 'degree': 2, 'gamma': 0.1, 'kernel': 'rbf'},\n",
       " {'C': 10, 'degree': 2, 'gamma': 0.1, 'kernel': 'rbf'}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8262187812187813,\n",
       " 0.84452331872108,\n",
       " 0.8556929174831988,\n",
       " 0.8354080219521084,\n",
       " 0.841232699225657]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_f_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1 = ls_grid[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=0, shuffle=True),\n",
       "             estimator=SVC(), n_jobs=-1,\n",
       "             param_grid={'C': [1, 5, 10, 15, 20, 50, 100, 150],\n",
       "                         'degree': [2, 3], 'gamma': [0.001, 0.1, 1, 5, 10],\n",
       "                         'kernel': ['linear', 'poly', 'rbf']},\n",
       "             scoring='f1', verbose=1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'param_C', 'param_degree', 'param_gamma', 'param_kernel', 'params', 'split0_test_score', 'split1_test_score', 'split2_test_score', 'split3_test_score', 'split4_test_score', 'mean_test_score', 'std_test_score', 'rank_test_score'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g1.cv_results_.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold1 = g1.cv_results_['split0_test_score']\n",
    "fold2 = g1.cv_results_['split1_test_score']\n",
    "fold3 = g1.cv_results_['split2_test_score']\n",
    "fold4 = g1.cv_results_['split3_test_score']\n",
    "fold5 = g1.cv_results_['split4_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "\n",
    "average_5_folds = [] \n",
    "for v1,v2,v3,v4,v5 in zip(fold1,fold2,fold3,fold4,fold5): \n",
    "    ls = [v1,v2,v3,v4,v5]\n",
    "    average_f1 = statistics.mean(ls)\n",
    "    average_5_folds.append(average_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8262187812187812\n"
     ]
    }
   ],
   "source": [
    "print(max(average_5_folds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average 5-fold F1 scores... 0.5474111372118114\n",
      "Stdev 5-fold F1 scores..... 0.3135862231804127\n"
     ]
    }
   ],
   "source": [
    "print('Average F1 scores (5-fold)...',statistics.mean(average_5_folds))\n",
    "print('Stdev F1 scores (5-fold).....',statistics.stdev(average_5_folds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3135862231804127\n"
     ]
    }
   ],
   "source": [
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Final comparsion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models to compare on the testing set: SVM TFIDF; SVM BERT; CNN; logical filters; Integrated model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Results by logical approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_crisis_hashtags = ['SOSHouston','SOSHarvey','HelpHouston','harveysos','harveyrescue','sendhelp','HarveySOS','Rescue','rescue'\n",
    "                      ,'HarveyFlood','HARVEYHELP','Relief','PLEASEHELP','URGENT']\n",
    "\n",
    "def extract_hash_tags(sentence,ls_crisis_hashtags):\n",
    "    crisis_hashtag_found = False\n",
    "    for part in sentence.split():\n",
    "        if part.startswith('#'): \n",
    "            if part[1:] in ls_crisis_hashtags:\n",
    "                crisis_hashtag_found =True\n",
    "                \n",
    "    return crisis_hashtag_found\n",
    "\n",
    "\n",
    "#--------------------  Create filter 1 ---------------------------------------#\n",
    "# Feature 1.1 keywords with hurricane/flood\n",
    "rgx_f1_1 = \"\\\\b(Hurricane|HurricaneHarvey|Harvey2017|HARVEYHELP|HarveyStorm|harveyhouston|houstonflood|houstonfloods|houstonflooding|texasflood|texasfloods|texasflooding|harveyflood|harveyflooding|HurricaneFlood|HurricaneSOS)\\\\b\"\n",
    "\n",
    "# Feature 1.2 keywords with situation descriptions\n",
    "rgx_f1_2 = \"\\\\b(stranded|stuck|trapped|traps?|trapping|roofs?|rooftop|injured|hurt)\\\\b\"\n",
    "\n",
    "\n",
    "# Feature 1.3: contain both the following two keyword groups (ignore case):\n",
    "# group 1: names of cities and towns near Houston\n",
    "# group 2: flood related keywords. e.g. flood, flooding\n",
    "rgx_f1_3a = \"\\\\b(Houston|Texas|Galveston|Lake\\\\sJackson|Pasadena|League\\\\sCity|DICKINSON|Pearland|Missouri\\\\sCity|Sugar\\\\sLand|Richmond|Rosenberg|Alvin|Baytown|Fresno|Mont\\\\sBelvieu|Humble|Woodlands|Spring|Tomball|Cypress|Brookshire\\\\sKaty|FRIENDSWOOD)\\\\b\"\n",
    "rgx_f1_3b = \"\\\\b(flood|floods|flooding|flooded)\\\\b\"\n",
    "\n",
    "\n",
    "#------------------ Create filter 2: Requesting rescue ------------------------#\n",
    "rgx_f2 = \"\\\\b(rescue|rescues|rescuing|rescued|helps?|helping|WaterRescue|WaterRescueNeeded|aid|assistance|boats?|HarveyRescue|HarveySOS|HurricaneRescue|FloodRescue|HurricaneSOS|HarveyRelief)\\\\b\"\n",
    "\n",
    "# ------ Create filter 3: address description-----------------------------------#\n",
    "address_pattern = \"(\\\\b\\\\d+\\\\s+(#?[A-z]+\\\\.?(-[A-z]+)?\\\\s+){1,3}\\\\b(#@#|ANNEX|ANEX|ANNX|ANX|#@#|ARCADE|ARC|#@#|AVENUE|AV|AVE|AVEN|AVENU|AVN|AVNUE|#@#|BAYOU|BAYOO|BYU|BAYOU|#@#|BEACH|BCH|BEACH|#@#|BEND|BND|#@#|BLUFF|BLF|BLUF|BLUFFS|BLFS|#@#|BOTTOM|BOT|BTM|BOTTM|#@#|BOULEVARD|BLVD|BOUL|BOULV|#@#|BRANCH|BR|BRNCH|#@#|BRIDGE|BRDGE|BRG|#@#|BROOK|BRK|BROOKS|BRKS|#@#|BURG|BG|BURGS|BGS|#@#|BYPASS|BYP|BYPA|BYPAS|BYPS|#@#|CAMP|CP|CMP|#@#|CANYON|CANYN|CYN|CNYN|#@#|CAPE|CPE|#@#|CAUSEWAY|CSWY|CAUSWA|CSWY|#@#|CENTER|CEN|CTR|CENT|CENTR|CENTRE|CNTER|CNTR|CENTERS|CTRS|#@#|CIRCLE|CIR|CIRC|CIRCL|CRCL|CRCLE|CIRCLES|CIRS|#@#|CLIFF|CLF|CLIFFS|CLFS|CLIFFS|#@#|CLUB|CLB|#@#|COMMON|CMN|COMMONS|CMNS|#@#|CORNER|COR|CORNERS|CORS|#@#|COURSE|CRSE|#@#|COURT|CT|COURTS|CTS|#@#|COVE|CV|COVES|COVES|CVS|#@#|CREEK|CRK|#@#|CRESCENT|CRES|CRSENT|CRSNT|CREST|CRST|CR|#@#|CROSSING|CRSSNG|XING|#@#|CROSSROAD|XRD|CROSSROADS|XRDS|#@#|CURVE|CURV|#@#|DALE|DL|#@#|#DAM#|#DM#|#@#|DIVIDE|DIV|DV|DIVIDE|DVD|#@#|DRIVE|DR|DRIV|DRV|DRIVES|DRS|#@#|ESTATE|EST|ESTATES|ESTS|#@#|EXPRESSWAY|EXP|EXPY|EXPR|EXPRESS|EXPW|#@#|EXTENSION|EXT|EXTN|EXTNSN|EXTENSIONS|EXTS|#@#|FALL|FALLS|FLS|#@#|FERRY|FRY|FRRY|FRY|#@#|FIELD|FLD|FIELDS|FLDS|#@#|FLAT|FLT|FLATS|FLTS|#@#|FORD|FRD|FORDS|FRDS|#@#|FOREST|FRST|FORESTS|FRST|#@#|FORGE|FORG|FRG|FORGES|FRGS|#@#|FORK|FRK|FORKS|FRKS|#@#|FORT|FT|FRT|#@#|FREEWAY|FWY|FREEWY|FRWAY|FRWY|FWY|#@#|GARDEN|GDN|GRDN|GARDENS|GDNS|GRDNS|#@#|GATEWAY|GTWY|GATEWY|GATWAY|GTWAY|GTWY|#@#|GLEN|GLN|GLENS|GLNS|#@#|GREEN|GRN|GREENS|GRNS|#@#|GROVE|GROV|GRV|GROVES|GRVS|#@#|HARBOR|HARB|HBR|HARBR|HRBOR|HARBORS|HBRS|#@#|HAVEN|HVN|#@#|HEIGHTS|HT|HTS|#@#|HIGHWAY|HWY|HIWAY|HIWY|HWAY|HWY|#@#|HILL|HL|HILLS|HLS|#@#|HOLLOW|HLLW|HOLW|HOLLOWS|HOLWS|#@#|INLET|INLT|#@#|ISLAND|#IS#|ISLND|ISLANDS|ISS|ISLNDS|#@#|ISLE|ISLES|#@#|JUNCTION|JCT|JCTION|JCTN|JUNCTN|JUNCTON|JUNCTIONS|JCTNS|JCTS|JUNCTIONS|#@#|KEY|KY|KEYS|KYS|#@#|KNOLL|KNL|KNOL|KNOLLS|KNLS|#@#|LAKE|LK|LAKES|LKS|#@#|LAND|LANDING|LNDG|LNDNG|#@#|LANE|LN|#@#|LIGHT|LGT|LIGHTS|LGTS|#@#|LOAF|LF|#@#|LOCK|LCK|LOCKS|LCKS|#@#|LODGE|LDG|LDGE|#@#|LOOP|LOOPS|#@#|MALL|#@#|MANOR|MNR|MANORS|MNRS|#@#|MEADOW|MDW|MEADOWS|MDWS|#@#|MEWS|#@#|MILL|ML|MILLS|MLS|#@#|MISSION|MISSN|MSN|MSSN|#@#|MOTORWAY|MTWY|#@#|MOUNT|MNT|MT|MOUNTAIN|MNTAIN|MTN|MNTN|MOUNTIN|MTIN|MOUNTAINS|MNTNS|MTNS|#@#|NECK|NCK|#@#|ORCHARD|ORCH|ORCHRD|#@#|OVAL|OVL|#@#|OVERPASS|OPAS|#@#|PARK|PRK|PARKS|#@#|PARKWAY|PARKWY|PKWAY|PKWY|PKY|PARKWAYS|PKWYS|#@#|PASS|PASSAGE|PSGE|#@#|#PATH#|#PATHS#|#@#|PIKE|PIKES|#@#|PINE|PNE|PINES|PNES|#@#|PLACE|PL|#@#|PLAIN|PLN|PLAINS|PLNS|#@#|PLAZA|PLZ|PLZA|#@#|#POINT#|PT|#POINTS#|PTS|#@#|PORT|PRT|PORTS|PRTS|#@#|PRAIRIE|PR|PRR|#@#|RADIAL|RAD|RADL|RADIEL|RADL|#@#|RAMP|#@#|RANCH|RNCH|RANCHES|RNCHS|#@#|RAPID|RPD|RAPIDS|RPDS|#@#|REST|RST|#@#|RIDGE|RDG|RDGE|RIDGES|RDGS|#@#|RIVER|RIV|RVR|RIVR|#@#|ROAD|RD|ROADS|RDS|#@#|ROUTE|RTE|#@#|ROW|#@#|RUE|#@#|#RUN#|#@#|SHOAL|SHL|SHL|SHOALS|SHLS|#@#|SHORE|SHOAR|SHR|SHORES|SHOARS|SHRS|#@#|SKYWAY|SKWY|#@#|SPRING|SPG|SPNG|SPRINGS|SPGS|SPNGS|#@#|SPUR|SPURS|#@#|SQUARE|SQ|SQR|SQRE|SQU|SQUARES|SQRS|#@#|STATION|STA|STATN|STN|#@#|STRAVENUE|STRA|STRAV|STRAVEN|STRAVN|STRVN|STRVNUE|#@#|STREAM|STRM|STREME|#@#|STREET|ST|STRT|STR|STREETS|STS|#@#|SUMMIT|SMT|SUMIT|SUMITT|SUMMIT|#@#|TERRACE|TER|TERR|#@#|THROUGHWAY|TRWY|#@#|TRACE|TRCE|TRACES|TRCE|#@#|TRACK|TRAK|TRACKS|TRAK|TRK|TRKS|#@#|TRAFFICWAY|TRFY|#@#|TRAIL|TRL|TRAILS|TRL|TRLS|#@#|TRAILER|TRLR|TRLRS|#@#|TUNNEL|TUNL|TUNLS|TUNNELS|TUNNL|#@#|TURNPIKE|TRNPK|TPKE|TURNPK|#@#|UNDERPASS|UPAS|#@#|UNION|UN|UNIONS|UNS|#@#|VALLEY|VLY|VALLY|VLLY|VLY|VALLEYS|VLYS|#@#|VIADUCT|VDCT|#VIA#|VIADCT|#@#|VIEW|VW|VIEWS|VWS|#@#|VILLAGE|VILL|VLG|VILLG|VILLIAGE|VILLAGES|VLGS|#@#|VILLE|VL|#@#|VISTA|VIS|VIST|VST|VSTA|#@#|#WALK#|#WALKS#|#@#|#WALL#|#@#|#WAY#|WY|#WAYS#|#@#|#WELL#|WL|WELLS|WLS|#@#)\\\\.?\\\\b|#@#)|(\\\\b\\\\d+\\\\s+(AVENUE|AV|AVE|AVEN|AVENU|AVN|AVNUE|#@#|HIGHWAY|HWY|HIWAY|HIWY|HWAY|#@#|ROAD|RD|ROADS|RDS|#@#|ROUTE|RTE|#@#|STREET|ST|STRT|STR|STREETS|STS|#@#)\\\\.?\\\\s+([A-z]|\\\\d+)\\\\b)\"\n",
    "non_address_pattern = \"\\\\b\\\\d+\\\\s+(am|pm|hrs?|hours?|mins?|minutes?|seconds?|#@#|days?|months?|mon|yr|yrs|years?|#@#|ft|feet|foot|in|inch(es)?|meters?|miles?|#@#|pounds?|pnd|ounce|oz|kg|kilograms?|grams?|tons?|#@#|gallons?|liters?|cubes?|volumes?|quarts?|bottles?|cups?|#@#|per|per\\\\s+cent|percent|degrees?|times?|#@#|dollars?|USD|GBP|hundreds?|thousands?|millions?|billions?|trillions?|#@#|from|to|at|and|or|were|are|Fan\\\\sClub|live|hurricane|exit|entrance|#@#|rescued|donation|people|patients|seniors|elderly|women|children|clergy|#@#)\\\\.?\\\\s+(#?[A-z]+\\\\.?(-[A-z]+)?\\\\s+){0,2}\\\\b(#@#|ANNEX|ANEX|ANNX|ANX|#@#|ARCADE|ARC|#@#|AVENUE|AV|AVE|AVEN|AVENU|AVN|AVNUE|#@#|BAYOU|BAYOO|BYU|BAYOU|#@#|BEACH|BCH|BEACH|#@#|BEND|BND|#@#|BLUFF|BLF|BLUF|BLUFFS|BLFS|#@#|BOTTOM|BOT|BTM|BOTTM|#@#|BOULEVARD|BLVD|BOUL|BOULV|#@#|BRANCH|BR|BRNCH|#@#|BRIDGE|BRDGE|BRG|#@#|BROOK|BRK|BROOKS|BRKS|#@#|BURG|BG|BURGS|BGS|#@#|BYPASS|BYP|BYPA|BYPAS|BYPS|#@#|CAMP|CP|CMP|#@#|CANYON|CANYN|CYN|CNYN|#@#|CAPE|CPE|#@#|CAUSEWAY|CSWY|CAUSWA|CSWY|#@#|CENTER|CEN|CTR|CENT|CENTR|CENTRE|CNTER|CNTR|CENTERS|CTRS|#@#|CIRCLE|CIR|CIRC|CIRCL|CRCL|CRCLE|CIRCLES|CIRS|#@#|CLIFF|CLF|CLIFFS|CLFS|CLIFFS|#@#|CLUB|CLB|#@#|COMMON|CMN|COMMONS|CMNS|#@#|CORNER|COR|CORNERS|CORS|#@#|COURSE|CRSE|#@#|COURT|CT|COURTS|CTS|#@#|COVE|CV|COVES|COVES|CVS|#@#|CREEK|CRK|#@#|CRESCENT|CRES|CRSENT|CRSNT|CREST|CRST|CR|#@#|CROSSING|CRSSNG|XING|#@#|CROSSROAD|XRD|CROSSROADS|XRDS|#@#|CURVE|CURV|#@#|DALE|DL|#@#|#DAM#|DM|#@#|DIVIDE|DIV|DV|DIVIDE|DVD|#@#|DRIVE|DR|DRIV|DRV|DRIVES|DRS|#@#|ESTATE|EST|ESTATES|ESTS|#@#|EXPRESSWAY|EXP|EXPY|EXPR|EXPRESS|EXPW|#@#|EXTENSION|EXT|EXTN|EXTNSN|EXTENSIONS|EXTS|#@#|FALL|FALLS|FLS|#@#|FERRY|FRY|FRRY|FRY|#@#|FIELD|FLD|FIELDS|FLDS|#@#|FLAT|FLT|FLATS|FLTS|#@#|FORD|FRD|FORDS|FRDS|#@#|FOREST|FRST|FORESTS|FRST|#@#|FORGE|FORG|FRG|FORGES|FRGS|#@#|FORK|FRK|FORKS|FRKS|#@#|FORT|FT|FRT|#@#|FREEWAY|FWY|FREEWY|FRWAY|FRWY|FWY|#@#|GARDEN|GDN|GRDN|GARDENS|GDNS|GRDNS|#@#|GATEWAY|GTWY|GATEWY|GATWAY|GTWAY|GTWY|#@#|GLEN|GLN|GLENS|GLNS|#@#|GREEN|GRN|GREENS|GRNS|#@#|GROVE|GROV|GRV|GROVES|GRVS|#@#|HARBOR|HARB|HBR|HARBR|HRBOR|HARBORS|HBRS|#@#|HAVEN|HVN|#@#|HEIGHTS|HT|HTS|#@#|HIGHWAY|HWY|HIWAY|HIWY|HWAY|HWY|#@#|HILL|HL|HILLS|HLS|#@#|HOLLOW|HLLW|HOLW|HOLLOWS|HOLWS|#@#|INLET|INLT|#@#|ISLAND|#IS#|ISLND|ISLANDS|ISS|ISLNDS|#@#|ISLE|ISLES|#@#|JUNCTION|JCT|JCTION|JCTN|JUNCTN|JUNCTON|JUNCTIONS|JCTNS|JCTS|JUNCTIONS|#@#|KEY|KY|KEYS|KYS|#@#|KNOLL|KNL|KNOL|KNOLLS|KNLS|#@#|LAKE|LK|LAKES|LKS|#@#|LAND|LANDING|LNDG|LNDNG|#@#|LANE|LN|#@#|LIGHT|LGT|LIGHTS|LGTS|#@#|LOAF|LF|#@#|LOCK|LCK|LOCKS|LCKS|#@#|LODGE|LDG|LDGE|#@#|LOOP|LOOPS|#@#|MALL|#@#|MANOR|MNR|MANORS|MNRS|#@#|MEADOW|MDW|MEADOWS|MDWS|#@#|MEWS|#@#|MILL|ML|MILLS|MLS|#@#|MISSION|MISSN|MSN|MSSN|#@#|MOTORWAY|MTWY|#@#|MOUNT|MNT|MT|MOUNTAIN|MNTAIN|MTN|MNTN|MOUNTIN|MTIN|MOUNTAINS|MNTNS|MTNS|#@#|NECK|NCK|#@#|ORCHARD|ORCH|ORCHRD|#@#|OVAL|OVL|#@#|OVERPASS|OPAS|#@#|PARK|PRK|PARKS|#@#|PARKWAY|PARKWY|PKWAY|PKWY|PKY|PARKWAYS|PKWYS|#@#|PASS|PASSAGE|PSGE|#@#|#PATH#|#PATHS#|#@#|PIKE|PIKES|#@#|PINE|PNE|PINES|PNES|#@#|PLACE|PL|#@#|PLAIN|PLN|PLAINS|PLNS|#@#|PLAZA|PLZ|PLZA|#@#|#POINT#|PT|#POINTS#|PTS|#@#|PORT|PRT|PORTS|PRTS|#@#|PRAIRIE|PR|PRR|#@#|RADIAL|RAD|RADL|RADIEL|RADL|#@#|RAMP|#@#|RANCH|RNCH|RANCHES|RNCHS|#@#|RAPID|RPD|RAPIDS|RPDS|#@#|REST|RST|#@#|RIDGE|RDG|RDGE|RIDGES|RDGS|#@#|RIVER|RIV|RVR|RIVR|#@#|ROAD|RD|ROADS|RDS|#@#|ROUTE|RTE|#@#|ROW|#@#|RUE|#@#|#RUN#|#@#|SHOAL|SHL|SHL|SHOALS|SHLS|#@#|SHORE|SHOAR|SHR|SHORES|SHOARS|SHRS|#@#|SKYWAY|SKWY|#@#|SPRING|SPG|SPNG|SPRINGS|SPGS|SPNGS|#@#|SPUR|SPURS|#@#|SQUARE|SQ|SQR|SQRE|SQU|SQUARES|SQRS|#@#|STATION|STA|STATN|STN|#@#|STRAVENUE|STRA|STRAV|STRAVEN|STRAVN|STRVN|STRVNUE|#@#|STREAM|STRM|STREME|#@#|STREET|ST|STRT|STR|STREETS|STS|#@#|SUMMIT|SMT|SUMIT|SUMITT|SUMMIT|#@#|TERRACE|TER|TERR|#@#|THROUGHWAY|TRWY|#@#|TRACE|TRCE|TRACES|TRCE|#@#|TRACK|TRAK|TRACKS|TRAK|TRK|TRKS|#@#|TRAFFICWAY|TRFY|#@#|TRAIL|TRL|TRAILS|TRL|TRLS|#@#|TRAILER|TRLR|TRLRS|#@#|TUNNEL|TUNL|TUNLS|TUNNELS|TUNNL|#@#|TURNPIKE|TRNPK|TPKE|TURNPK|#@#|UNDERPASS|UPAS|#@#|UNION|UN|UNIONS|UNS|#@#|VALLEY|VLY|VALLY|VLLY|VLY|VALLEYS|VLYS|#@#|VIADUCT|VDCT|#VIA#|VIADCT|#@#|VIEW|VW|VIEWS|VWS|#@#|VILLAGE|VILL|VLG|VILLG|VILLIAGE|VILLAGES|VLGS|#@#|VILLE|VL|#@#|VISTA|VIS|VIST|VST|VSTA|#@#|#WALK#|#WALKS#|#@#|#WALL#|#@#|#WAY#|WY|#WAYS#|#@#|#WELL#|WL|WELLS|WLS|#@#)\\\\.?\\\\b\"\n",
    "\n",
    "# ------ Create filter 4: with key words of tweets about political -------#\n",
    "rgx_f4 = \"\\\\b(realDonaldTrump|Trump|DonaldTrump|BarackObama|Obama|Election|Election2016|vote|republicans|republican|democrats|democrat|GOP|dems|immigrant|immigrants|climate\\\\s?change|gas\\\\s?prices|ICE|buzzfeed(news)?|tedcruz|SenTedCruz)\\\\b\"\n",
    "# all tweets about ICE and buzzfeed are polical ones\n",
    "\n",
    "# ------ Create filter 5: with key words of tweets about offering helps -------#\n",
    "rgx_f5 = \"\\\\b(donate|donating|donated|donations|Charity|Charities|church|shelters?|sheltering|(we|I)\\\\s+can\\\\s+help|open\\\\s+for\\\\s+helps?|drop\\\\s+off|HELP\\\\sthe\\\\s#?AmericanRedCross)\\\\b\"\n",
    "\n",
    "# ------ Create filter 6: with key words of tweets about commercial -------#\n",
    "rgx_f6 = \"\\\\$\\\\d+(.\\\\d{0,2})?|\\\\$\\\\$+|\\\\b(sales|for\\\\ssale|dollors|hundreds?|thousands?|millions?|billions?|trillions?|[A-z]*market)\\\\b\"\n",
    "# 2 regex, one  for market; one for open;\n",
    "\n",
    "\n",
    "# ------ Create filter 7: with key words of tweets of newsreport -------#\n",
    "rgx_f7 = \"#BREAKING:\\\\s+|\\\\b(Press\\\\sConference|Live\\\\svideo\\\\sfeed|Live\\\\sStream|County\\\\sUpdate:|National\\\\s+Hurricane\\\\s+Center|Tropical\\\\s+Storm\\\\s+Harvey|MANDATORY\\\\s+EVACUATION|After\\\\s+Hurricane\\\\s+Harvey|Ahead\\\\s+of\\\\s+Hurricane\\\\s+Harvey|like\\\\s+a\\\\s+river|6\\\\s+mil\\\\s+people|High\\\\s+call\\\\s+volume|Epic\\\\s+flooding|cameras?|webcam|\\\\bFM\\\\s+\\\\d+|News\\\\s+in\\\\s+the\\\\s+#?DMV)\\\\b\"\n",
    "# SOS tweet not likely use \"Tropical Storm Harvey\" or \"National Hurricane Center\"\n",
    "# typically used by news\n",
    "\n",
    "\n",
    "# ------ Create filter 8: rescue status update --------------#\n",
    "rgx_f8 = \"-\\\\sAwaiting\\\\sUpdates?\\\\b|-\\\\sRescued!\\\\s|\\\\b(Ha(ve|s)\\\\sBeen\\\\sRescued)\\\\b\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Testing_set_comparison = Test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>non_cleaned_text</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1094</th>\n",
       "      <td>Photos of flooding at Villas Dr./Golden Beach ...</td>\n",
       "      <td>photos flooding villas drgolden beach sent us ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1762</th>\n",
       "      <td>Hurricane Harvey videos | Fort Worth Star-Tele...</td>\n",
       "      <td>hurricane harvey videos fort worth startelegra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2034</th>\n",
       "      <td>11830 Greenspark Ln. - Awaiting Update. #Houst...</td>\n",
       "      <td>11830 greenspark ln awaiting update houston ha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2951</th>\n",
       "      <td>@ManBoobiees @LukeBryanSucks @klstorey Oh and ...</td>\n",
       "      <td>manboobiees lukebryansucks klstorey oh also ho...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5520</th>\n",
       "      <td>Guys, this storm is no joke ðŸ˜³#HurricaneHarvey ...</td>\n",
       "      <td>guys storm joke ðŸ˜³hurricaneharvey fl side effec...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4914</th>\n",
       "      <td>@jackmcme @matthaig1 Indeed, and sometimes dro...</td>\n",
       "      <td>jackmcme matthaig1 indeed sometimes drought fo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4737</th>\n",
       "      <td>My family is #blessed to have spent #Hurricane...</td>\n",
       "      <td>family blessed spent hurricaneharvey south for...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5435</th>\n",
       "      <td>HARVEY UPDATE: Williamson County officials mon...</td>\n",
       "      <td>harvey update williamson county officials moni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3007</th>\n",
       "      <td>Please continue to keep Houston in your though...</td>\n",
       "      <td>please continue keep houston thoughts amp pray...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>Houston, Texas freeway sign nearly submerged a...</td>\n",
       "      <td>houston texas freeway sign nearly submerged am...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1738 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       non_cleaned_text  \\\n",
       "1094  Photos of flooding at Villas Dr./Golden Beach ...   \n",
       "1762  Hurricane Harvey videos | Fort Worth Star-Tele...   \n",
       "2034  11830 Greenspark Ln. - Awaiting Update. #Houst...   \n",
       "2951  @ManBoobiees @LukeBryanSucks @klstorey Oh and ...   \n",
       "5520  Guys, this storm is no joke ðŸ˜³#HurricaneHarvey ...   \n",
       "...                                                 ...   \n",
       "4914  @jackmcme @matthaig1 Indeed, and sometimes dro...   \n",
       "4737  My family is #blessed to have spent #Hurricane...   \n",
       "5435  HARVEY UPDATE: Williamson County officials mon...   \n",
       "3007  Please continue to keep Houston in your though...   \n",
       "1258  Houston, Texas freeway sign nearly submerged a...   \n",
       "\n",
       "                                                   text  label  \n",
       "1094  photos flooding villas drgolden beach sent us ...      0  \n",
       "1762  hurricane harvey videos fort worth startelegra...      0  \n",
       "2034  11830 greenspark ln awaiting update houston ha...      0  \n",
       "2951  manboobiees lukebryansucks klstorey oh also ho...      0  \n",
       "5520  guys storm joke ðŸ˜³hurricaneharvey fl side effec...      0  \n",
       "...                                                 ...    ...  \n",
       "4914  jackmcme matthaig1 indeed sometimes drought fo...      0  \n",
       "4737  family blessed spent hurricaneharvey south for...      0  \n",
       "5435  harvey update williamson county officials moni...      0  \n",
       "3007  please continue keep houston thoughts amp pray...      0  \n",
       "1258  houston texas freeway sign nearly submerged am...      0  \n",
       "\n",
       "[1738 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Testing_set_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Testing_set_comparison['f1_1'] = Testing_set_comparison.apply(lambda row: 1 if re.findall(rgx_f1_1,row['non_cleaned_text'],re.IGNORECASE) else 0,axis=1)\n",
    "Testing_set_comparison['f1_2'] = Testing_set_comparison.apply(lambda row: 1 if re.findall(rgx_f1_2,row['non_cleaned_text'],re.IGNORECASE) else 0,axis=1)\n",
    "\n",
    "#### added filter 1: hashtags\n",
    "Testing_set_comparison['f1_4'] = Testing_set_comparison.apply(lambda row:1 if extract_hash_tags(row['non_cleaned_text'],ls_crisis_hashtags) == True else 0,axis=1)\n",
    "\n",
    "Testing_set_comparison['f2'] = Testing_set_comparison.apply(lambda row: 1 if re.findall(rgx_f2,row['non_cleaned_text'],re.IGNORECASE) else 0,axis=1)\n",
    "\n",
    "Testing_set_comparison['f3_1'] = Testing_set_comparison.apply(lambda row: 1 if re.findall(address_pattern,row['non_cleaned_text'],re.IGNORECASE) else 0,axis=1)\n",
    "Testing_set_comparison['f3_2'] = Testing_set_comparison.apply(lambda row: 1 if re.findall(non_address_pattern,row['non_cleaned_text'],re.IGNORECASE) else 0,axis=1)\n",
    "\n",
    "Testing_set_comparison['f4'] = Testing_set_comparison.apply(lambda row: 1 if re.findall(rgx_f4,row['non_cleaned_text'],re.IGNORECASE) else 0,axis=1)\n",
    "\n",
    "Testing_set_comparison['f5'] = Testing_set_comparison.apply(lambda row: 1 if re.findall(rgx_f5,row['non_cleaned_text'],re.IGNORECASE) else 0,axis=1)\n",
    "\n",
    "Testing_set_comparison['f6'] = Testing_set_comparison.apply(lambda row: 1 if re.findall(rgx_f6,row['non_cleaned_text'],re.IGNORECASE) else 0,axis=1)\n",
    "\n",
    "Testing_set_comparison['f7'] = Testing_set_comparison.apply(lambda row: 1 if re.findall(rgx_f7,row['non_cleaned_text'],re.IGNORECASE) else 0,axis=1)\n",
    "\n",
    "Testing_set_comparison['f8'] = Testing_set_comparison.apply(lambda row: 1 if re.findall(rgx_f8,row['non_cleaned_text'],re.IGNORECASE) else 0,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>non_cleaned_text</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>f1_1</th>\n",
       "      <th>f1_2</th>\n",
       "      <th>f1_4</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3_1</th>\n",
       "      <th>f3_2</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1094</th>\n",
       "      <td>Photos of flooding at Villas Dr./Golden Beach ...</td>\n",
       "      <td>photos flooding villas drgolden beach sent us ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1762</th>\n",
       "      <td>Hurricane Harvey videos | Fort Worth Star-Tele...</td>\n",
       "      <td>hurricane harvey videos fort worth startelegra...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2034</th>\n",
       "      <td>11830 Greenspark Ln. - Awaiting Update. #Houst...</td>\n",
       "      <td>11830 greenspark ln awaiting update houston ha...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2951</th>\n",
       "      <td>@ManBoobiees @LukeBryanSucks @klstorey Oh and ...</td>\n",
       "      <td>manboobiees lukebryansucks klstorey oh also ho...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5520</th>\n",
       "      <td>Guys, this storm is no joke ðŸ˜³#HurricaneHarvey ...</td>\n",
       "      <td>guys storm joke ðŸ˜³hurricaneharvey fl side effec...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4914</th>\n",
       "      <td>@jackmcme @matthaig1 Indeed, and sometimes dro...</td>\n",
       "      <td>jackmcme matthaig1 indeed sometimes drought fo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4737</th>\n",
       "      <td>My family is #blessed to have spent #Hurricane...</td>\n",
       "      <td>family blessed spent hurricaneharvey south for...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5435</th>\n",
       "      <td>HARVEY UPDATE: Williamson County officials mon...</td>\n",
       "      <td>harvey update williamson county officials moni...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3007</th>\n",
       "      <td>Please continue to keep Houston in your though...</td>\n",
       "      <td>please continue keep houston thoughts amp pray...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>Houston, Texas freeway sign nearly submerged a...</td>\n",
       "      <td>houston texas freeway sign nearly submerged am...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1738 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       non_cleaned_text  \\\n",
       "1094  Photos of flooding at Villas Dr./Golden Beach ...   \n",
       "1762  Hurricane Harvey videos | Fort Worth Star-Tele...   \n",
       "2034  11830 Greenspark Ln. - Awaiting Update. #Houst...   \n",
       "2951  @ManBoobiees @LukeBryanSucks @klstorey Oh and ...   \n",
       "5520  Guys, this storm is no joke ðŸ˜³#HurricaneHarvey ...   \n",
       "...                                                 ...   \n",
       "4914  @jackmcme @matthaig1 Indeed, and sometimes dro...   \n",
       "4737  My family is #blessed to have spent #Hurricane...   \n",
       "5435  HARVEY UPDATE: Williamson County officials mon...   \n",
       "3007  Please continue to keep Houston in your though...   \n",
       "1258  Houston, Texas freeway sign nearly submerged a...   \n",
       "\n",
       "                                                   text  label  f1_1  f1_2  \\\n",
       "1094  photos flooding villas drgolden beach sent us ...      0     0     0   \n",
       "1762  hurricane harvey videos fort worth startelegra...      0     1     0   \n",
       "2034  11830 greenspark ln awaiting update houston ha...      0     1     0   \n",
       "2951  manboobiees lukebryansucks klstorey oh also ho...      0     0     0   \n",
       "5520  guys storm joke ðŸ˜³hurricaneharvey fl side effec...      0     1     0   \n",
       "...                                                 ...    ...   ...   ...   \n",
       "4914  jackmcme matthaig1 indeed sometimes drought fo...      0     0     0   \n",
       "4737  family blessed spent hurricaneharvey south for...      0     1     0   \n",
       "5435  harvey update williamson county officials moni...      0     0     0   \n",
       "3007  please continue keep houston thoughts amp pray...      0     0     0   \n",
       "1258  houston texas freeway sign nearly submerged am...      0     0     0   \n",
       "\n",
       "      f1_4  f2  f3_1  f3_2  f4  f5  f6  f7  f8  \n",
       "1094     0   0     0     0   0   0   0   0   0  \n",
       "1762     0   0     0     0   0   0   0   0   0  \n",
       "2034     1   1     1     0   0   0   0   0   1  \n",
       "2951     0   0     0     0   0   0   0   0   0  \n",
       "5520     0   0     0     0   0   0   0   0   0  \n",
       "...    ...  ..   ...   ...  ..  ..  ..  ..  ..  \n",
       "4914     0   0     0     0   0   0   0   0   0  \n",
       "4737     0   0     0     0   0   0   0   0   0  \n",
       "5435     0   0     0     0   0   0   0   0   0  \n",
       "3007     0   0     0     0   0   0   0   0   0  \n",
       "1258     0   0     0     0   0   0   0   0   0  \n",
       "\n",
       "[1738 rows x 14 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Testing_set_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "### add column corresponding to our filter classification\n",
    "Testing_set_comparison['filter_sos'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logical_evaluation_address(x,y):\n",
    "    if x == 1:\n",
    "        if y == 0:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def logical_evaluation_final(x,y):\n",
    "    if x == 1:\n",
    "        if y == 0:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "    \n",
    "### evaluate the tweet using the logical expression ####\n",
    "def evaluate_expression(f1_1,f1_2,f1_4,f2,f3_1,f3_2,f4,f5,f6,f7,f8): \n",
    "    f1 = f1_1 or f1_2 or f1_4\n",
    "    f3 = logical_evaluation_address(f3_1,f3_2)\n",
    "    f1_union_f2= f1 or f2\n",
    "    f1_f2_intersect_f3 = f1_union_f2 and f3\n",
    "    excluded_filters = f4 or f5 or f6 or f7 or f8\n",
    "    return logical_evaluation_final(f1_f2_intersect_f3,excluded_filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## run classifier ###\n",
    "Testing_set_comparison['filter_sos'] = Testing_set_comparison.apply(lambda row: 1 if evaluate_expression(row['f1_1'],row['f1_2'],row['f1_4'],row['f2'],row['f3_1'],row['f3_2'],row['f4'],row['f5'],row['f6'],row['f7'],row['f8']) else 0,axis=1)\n",
    "\n",
    "labels = Testing_set_comparison['label']\n",
    "preds = Testing_set_comparison['filter_sos']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Testing_set_comparison.to_csv('/home/wkhal001/Desktop/logical_results.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7fb71e297fd0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "%matplotlib inline\n",
    "\n",
    "cm = confusion_matrix(labels, preds, labels=np.unique(labels))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=np.unique(labels))\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 0.9945454545454545,\n",
       "  'recall': 0.9873646209386282,\n",
       "  'f1-score': 0.9909420289855072,\n",
       "  'support': 1662},\n",
       " '1': {'precision': 0.7613636363636364,\n",
       "  'recall': 0.881578947368421,\n",
       "  'f1-score': 0.8170731707317073,\n",
       "  'support': 76},\n",
       " 'accuracy': 0.9827387802071347,\n",
       " 'macro avg': {'precision': 0.8779545454545454,\n",
       "  'recall': 0.9344717841535246,\n",
       "  'f1-score': 0.9040075998586072,\n",
       "  'support': 1738},\n",
       " 'weighted avg': {'precision': 0.984348781253269,\n",
       "  'recall': 0.9827387802071347,\n",
       "  'f1-score': 0.9833390179226252,\n",
       "  'support': 1738}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_r = classification_report(labels, preds,output_dict = True)\n",
    "\n",
    "dict_r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Results by SVM-TFIDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model setting: TFIDF 500 unigrams (C=10,degree=2,gamma=1,kernel='rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>non_cleaned_text</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#Harvey floods TV station #KHOU in #Houston. h...</td>\n",
       "      <td>harvey floods tv station khou houston</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@RandiRhodes RR call him out for visiting SA, ...</td>\n",
       "      <td>randirhodes rr call visiting sa flooding mayor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wow a tv station is flooding in Houston! So sc...</td>\n",
       "      <td>wow tv station flooding houston scary sad rain...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My son, dil &amp;amp; 2 grandkids in grand lakes, ...</td>\n",
       "      <td>son dil amp 2 grandkids grand lakes katy tx wo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>is the beltway still flooded? ya boy need to g...</td>\n",
       "      <td>beltway still flooded ya boy need go pay bills ðŸ˜’</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5787</th>\n",
       "      <td>Around 10,000,000,000,000 gallons of water fro...</td>\n",
       "      <td>around 10000000000000 gallons water harvey ins...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5788</th>\n",
       "      <td>The road to my residence is flooded. Thank God...</td>\n",
       "      <td>road residence flooded thank god left safe sta...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5789</th>\n",
       "      <td>Texas road closures and flooding kept up to da...</td>\n",
       "      <td>texas road closures flooding kept date</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5790</th>\n",
       "      <td>@HellerWeather Tim, any maps to show where flo...</td>\n",
       "      <td>hellerweather tim maps show flooding would mas...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5791</th>\n",
       "      <td>lrt more people died on the road trying to eva...</td>\n",
       "      <td>lrt people died road trying evacuate hurricane...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5792 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       non_cleaned_text  \\\n",
       "0     #Harvey floods TV station #KHOU in #Houston. h...   \n",
       "1     @RandiRhodes RR call him out for visiting SA, ...   \n",
       "2     Wow a tv station is flooding in Houston! So sc...   \n",
       "3     My son, dil &amp; 2 grandkids in grand lakes, ...   \n",
       "4     is the beltway still flooded? ya boy need to g...   \n",
       "...                                                 ...   \n",
       "5787  Around 10,000,000,000,000 gallons of water fro...   \n",
       "5788  The road to my residence is flooded. Thank God...   \n",
       "5789  Texas road closures and flooding kept up to da...   \n",
       "5790  @HellerWeather Tim, any maps to show where flo...   \n",
       "5791  lrt more people died on the road trying to eva...   \n",
       "\n",
       "                                                   text  label  \n",
       "0                harvey floods tv station khou houston       0  \n",
       "1     randirhodes rr call visiting sa flooding mayor...      0  \n",
       "2     wow tv station flooding houston scary sad rain...      0  \n",
       "3     son dil amp 2 grandkids grand lakes katy tx wo...      0  \n",
       "4      beltway still flooded ya boy need go pay bills ðŸ˜’      0  \n",
       "...                                                 ...    ...  \n",
       "5787  around 10000000000000 gallons water harvey ins...      0  \n",
       "5788  road residence flooded thank god left safe sta...      0  \n",
       "5789            texas road closures flooding kept date       0  \n",
       "5790  hellerweather tim maps show flooding would mas...      0  \n",
       "5791  lrt people died road trying evacuate hurricane...      0  \n",
       "\n",
       "[5792 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>non_cleaned_text</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5667</th>\n",
       "      <td>If you want to figure out the road situation i...</td>\n",
       "      <td>want figure road situation area check harveyfl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>The Wall Street Journal: Houston flooding expe...</td>\n",
       "      <td>wall street journal houston flooding expected ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3312</th>\n",
       "      <td>@cinnamonfire8 oh and that white oak and houst...</td>\n",
       "      <td>cinnamonfire8 oh white oak houston ave floodin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5021</th>\n",
       "      <td>Guys, I'm south of the Conroe dam. Where is ev...</td>\n",
       "      <td>guys im south conroe dam everyone evacuating g...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5104</th>\n",
       "      <td>12:43pm.. flooding in Breaux Bridge (St. Marti...</td>\n",
       "      <td>1243pm flooding breaux bridge st martin parish...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Heavy Rain, Flooding Cause Concern Across Tamp...</td>\n",
       "      <td>heavy rain flooding cause concern across tampa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3755</th>\n",
       "      <td>The Wall Street Journal: Hurricane Harvey like...</td>\n",
       "      <td>wall street journal hurricane harvey likely sn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5438</th>\n",
       "      <td>Please DO NOT drive into the water if you can ...</td>\n",
       "      <td>please drive water see road please harvey</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5419</th>\n",
       "      <td>President Trump Tweets About 2016 Election and...</td>\n",
       "      <td>president trump tweets 2016 election border wa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194</th>\n",
       "      <td>@KHOUBlake11 #Houston: Dam opened, flooding do...</td>\n",
       "      <td>khoublake11 houston dam opened flooding downst...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4054 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       non_cleaned_text  \\\n",
       "5667  If you want to figure out the road situation i...   \n",
       "813   The Wall Street Journal: Houston flooding expe...   \n",
       "3312  @cinnamonfire8 oh and that white oak and houst...   \n",
       "5021  Guys, I'm south of the Conroe dam. Where is ev...   \n",
       "5104  12:43pm.. flooding in Breaux Bridge (St. Marti...   \n",
       "...                                                 ...   \n",
       "48    Heavy Rain, Flooding Cause Concern Across Tamp...   \n",
       "3755  The Wall Street Journal: Hurricane Harvey like...   \n",
       "5438  Please DO NOT drive into the water if you can ...   \n",
       "5419  President Trump Tweets About 2016 Election and...   \n",
       "1194  @KHOUBlake11 #Houston: Dam opened, flooding do...   \n",
       "\n",
       "                                                   text  label  \n",
       "5667  want figure road situation area check harveyfl...      0  \n",
       "813   wall street journal houston flooding expected ...      0  \n",
       "3312  cinnamonfire8 oh white oak houston ave floodin...      0  \n",
       "5021  guys im south conroe dam everyone evacuating g...      0  \n",
       "5104  1243pm flooding breaux bridge st martin parish...      0  \n",
       "...                                                 ...    ...  \n",
       "48    heavy rain flooding cause concern across tampa...      0  \n",
       "3755  wall street journal hurricane harvey likely sn...      0  \n",
       "5438          please drive water see road please harvey      0  \n",
       "5419  president trump tweets 2016 election border wa...      0  \n",
       "1194  khoublake11 houston dam opened flooding downst...      0  \n",
       "\n",
       "[4054 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>non_cleaned_text</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1094</th>\n",
       "      <td>Photos of flooding at Villas Dr./Golden Beach ...</td>\n",
       "      <td>photos flooding villas drgolden beach sent us ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1762</th>\n",
       "      <td>Hurricane Harvey videos | Fort Worth Star-Tele...</td>\n",
       "      <td>hurricane harvey videos fort worth startelegra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2034</th>\n",
       "      <td>11830 Greenspark Ln. - Awaiting Update. #Houst...</td>\n",
       "      <td>11830 greenspark ln awaiting update houston ha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2951</th>\n",
       "      <td>@ManBoobiees @LukeBryanSucks @klstorey Oh and ...</td>\n",
       "      <td>manboobiees lukebryansucks klstorey oh also ho...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5520</th>\n",
       "      <td>Guys, this storm is no joke ðŸ˜³#HurricaneHarvey ...</td>\n",
       "      <td>guys storm joke ðŸ˜³hurricaneharvey fl side effec...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4914</th>\n",
       "      <td>@jackmcme @matthaig1 Indeed, and sometimes dro...</td>\n",
       "      <td>jackmcme matthaig1 indeed sometimes drought fo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4737</th>\n",
       "      <td>My family is #blessed to have spent #Hurricane...</td>\n",
       "      <td>family blessed spent hurricaneharvey south for...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5435</th>\n",
       "      <td>HARVEY UPDATE: Williamson County officials mon...</td>\n",
       "      <td>harvey update williamson county officials moni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3007</th>\n",
       "      <td>Please continue to keep Houston in your though...</td>\n",
       "      <td>please continue keep houston thoughts amp pray...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>Houston, Texas freeway sign nearly submerged a...</td>\n",
       "      <td>houston texas freeway sign nearly submerged am...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1738 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       non_cleaned_text  \\\n",
       "1094  Photos of flooding at Villas Dr./Golden Beach ...   \n",
       "1762  Hurricane Harvey videos | Fort Worth Star-Tele...   \n",
       "2034  11830 Greenspark Ln. - Awaiting Update. #Houst...   \n",
       "2951  @ManBoobiees @LukeBryanSucks @klstorey Oh and ...   \n",
       "5520  Guys, this storm is no joke ðŸ˜³#HurricaneHarvey ...   \n",
       "...                                                 ...   \n",
       "4914  @jackmcme @matthaig1 Indeed, and sometimes dro...   \n",
       "4737  My family is #blessed to have spent #Hurricane...   \n",
       "5435  HARVEY UPDATE: Williamson County officials mon...   \n",
       "3007  Please continue to keep Houston in your though...   \n",
       "1258  Houston, Texas freeway sign nearly submerged a...   \n",
       "\n",
       "                                                   text  label  \n",
       "1094  photos flooding villas drgolden beach sent us ...      0  \n",
       "1762  hurricane harvey videos fort worth startelegra...      0  \n",
       "2034  11830 greenspark ln awaiting update houston ha...      0  \n",
       "2951  manboobiees lukebryansucks klstorey oh also ho...      0  \n",
       "5520  guys storm joke ðŸ˜³hurricaneharvey fl side effec...      0  \n",
       "...                                                 ...    ...  \n",
       "4914  jackmcme matthaig1 indeed sometimes drought fo...      0  \n",
       "4737  family blessed spent hurricaneharvey south for...      0  \n",
       "5435  harvey update williamson county officials moni...      0  \n",
       "3007  please continue keep houston thoughts amp pray...      0  \n",
       "1258  houston texas freeway sign nearly submerged am...      0  \n",
       "\n",
       "[1738 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5667    0\n",
       "813     0\n",
       "3312    0\n",
       "5021    0\n",
       "5104    0\n",
       "       ..\n",
       "48      0\n",
       "3755    0\n",
       "5438    0\n",
       "5419    0\n",
       "1194    0\n",
       "Name: label, Length: 4054, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1662\n",
       "1      76\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_X['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------- rep  0 ---------------------\n",
      "F1 score..... 0.7887323943661972\n",
      "Recall..... 0.7368421052631579\n",
      "Precision..... 0.8484848484848485\n",
      "-------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from Baseline_Models import Create_TFIDF,Vector_Encoding_TFIDF,Create_BOW,Vector_Encoding_BOW\n",
    "\n",
    "TFID = Create_TFIDF(df_training['text'],500,1,1)\n",
    "\n",
    "rep = 0\n",
    "eval_results = {}\n",
    "f1_list = []\n",
    "recall_list = [] \n",
    "precision_list = []\n",
    "for i in range(1):\n",
    "    \n",
    "    print('------------------- rep ',rep,'---------------------')\n",
    "    \n",
    "    ###### SVM - vectorize input text using TF-IDF ######\n",
    "    Train_X_TFIDF = Vector_Encoding_TFIDF(TFID,Train_X['text'])\n",
    "    \n",
    "    ###### defining parameter range ######\n",
    "    param_grid = {'C':10 ,'gamma':1 ,'degree':2 ,'kernel':'rbf'} \n",
    "    \n",
    "    ###### Train SVM ######\n",
    "    SVM = SVC(C=param_grid['C'], kernel=param_grid['kernel'],degree=param_grid['degree'] ,gamma=param_grid['gamma']) \n",
    "    SVM.fit(Train_X_TFIDF,Train_Y)\n",
    "    \n",
    "    ##### Predict ##########\n",
    "    Test_X_TFIDF = Vector_Encoding_TFIDF(TFID,Test_X['text'])\n",
    "    preds = SVM.predict(Test_X_TFIDF)\n",
    "    \n",
    "    ##### classification results on the test set ##########\n",
    "    dict_r = classification_report(Test_Y, preds,output_dict = True)\n",
    "    \n",
    "    print('F1 score.....',dict_r['1']['f1-score'])\n",
    "    f1_list.append(dict_r['1']['f1-score'])\n",
    "    \n",
    "    print('Recall.....',dict_r['1']['recall'])\n",
    "    recall_list.append(dict_r['1']['f1-score'])\n",
    "    \n",
    "    print('Precision.....',dict_r['1']['precision'])\n",
    "    f1_list.append(dict_r['1']['f1-score'])\n",
    "    precision_list.append({rep: dict_r})\n",
    "    \n",
    "    print('-------------------------------------------------')\n",
    "    \n",
    "    rep = rep + 1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 0.9880382775119617,\n",
       "  'recall': 0.9939831528279182,\n",
       "  'f1-score': 0.9910017996400721,\n",
       "  'support': 1662},\n",
       " '1': {'precision': 0.8484848484848485,\n",
       "  'recall': 0.7368421052631579,\n",
       "  'f1-score': 0.7887323943661972,\n",
       "  'support': 76},\n",
       " 'accuracy': 0.9827387802071347,\n",
       " 'macro avg': {'precision': 0.9182615629984051,\n",
       "  'recall': 0.865412629045538,\n",
       "  'f1-score': 0.8898670970031346,\n",
       "  'support': 1738},\n",
       " 'weighted avg': {'precision': 0.9819358260700396,\n",
       "  'recall': 0.9827387802071347,\n",
       "  'f1-score': 0.9821568774301673,\n",
       "  'support': 1738}}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Results by SVM-BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>non_cleaned_text</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5667</th>\n",
       "      <td>If you want to figure out the road situation i...</td>\n",
       "      <td>want figure road situation area check harveyfl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>The Wall Street Journal: Houston flooding expe...</td>\n",
       "      <td>wall street journal houston flooding expected ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3312</th>\n",
       "      <td>@cinnamonfire8 oh and that white oak and houst...</td>\n",
       "      <td>cinnamonfire8 oh white oak houston ave floodin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5021</th>\n",
       "      <td>Guys, I'm south of the Conroe dam. Where is ev...</td>\n",
       "      <td>guys im south conroe dam everyone evacuating g...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5104</th>\n",
       "      <td>12:43pm.. flooding in Breaux Bridge (St. Marti...</td>\n",
       "      <td>1243pm flooding breaux bridge st martin parish...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Heavy Rain, Flooding Cause Concern Across Tamp...</td>\n",
       "      <td>heavy rain flooding cause concern across tampa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3755</th>\n",
       "      <td>The Wall Street Journal: Hurricane Harvey like...</td>\n",
       "      <td>wall street journal hurricane harvey likely sn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5438</th>\n",
       "      <td>Please DO NOT drive into the water if you can ...</td>\n",
       "      <td>please drive water see road please harvey</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5419</th>\n",
       "      <td>President Trump Tweets About 2016 Election and...</td>\n",
       "      <td>president trump tweets 2016 election border wa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194</th>\n",
       "      <td>@KHOUBlake11 #Houston: Dam opened, flooding do...</td>\n",
       "      <td>khoublake11 houston dam opened flooding downst...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4054 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       non_cleaned_text  \\\n",
       "5667  If you want to figure out the road situation i...   \n",
       "813   The Wall Street Journal: Houston flooding expe...   \n",
       "3312  @cinnamonfire8 oh and that white oak and houst...   \n",
       "5021  Guys, I'm south of the Conroe dam. Where is ev...   \n",
       "5104  12:43pm.. flooding in Breaux Bridge (St. Marti...   \n",
       "...                                                 ...   \n",
       "48    Heavy Rain, Flooding Cause Concern Across Tamp...   \n",
       "3755  The Wall Street Journal: Hurricane Harvey like...   \n",
       "5438  Please DO NOT drive into the water if you can ...   \n",
       "5419  President Trump Tweets About 2016 Election and...   \n",
       "1194  @KHOUBlake11 #Houston: Dam opened, flooding do...   \n",
       "\n",
       "                                                   text  label  \n",
       "5667  want figure road situation area check harveyfl...      0  \n",
       "813   wall street journal houston flooding expected ...      0  \n",
       "3312  cinnamonfire8 oh white oak houston ave floodin...      0  \n",
       "5021  guys im south conroe dam everyone evacuating g...      0  \n",
       "5104  1243pm flooding breaux bridge st martin parish...      0  \n",
       "...                                                 ...    ...  \n",
       "48    heavy rain flooding cause concern across tampa...      0  \n",
       "3755  wall street journal hurricane harvey likely sn...      0  \n",
       "5438          please drive water see road please harvey      0  \n",
       "5419  president trump tweets 2016 election border wa...      0  \n",
       "1194  khoublake11 houston dam opened flooding downst...      0  \n",
       "\n",
       "[4054 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5667    0\n",
       "813     0\n",
       "3312    0\n",
       "5021    0\n",
       "5104    0\n",
       "       ..\n",
       "48      0\n",
       "3755    0\n",
       "5438    0\n",
       "5419    0\n",
       "1194    0\n",
       "Name: label, Length: 4054, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------- rep  0 -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wkhal001/envs/Twitter_crisis/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2143: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert embedding train shape torch.Size([4054, 36, 13, 768])\n",
      "Bert embedding test shape torch.Size([1738, 36, 13, 768])\n",
      "encoded......\n",
      "4054\n",
      "1738\n",
      "F1 score... 0.842857142857143\n",
      "-------------------------------------------\n",
      "---------------- rep  1 -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wkhal001/envs/Twitter_crisis/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2143: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert embedding train shape torch.Size([4054, 36, 13, 768])\n",
      "Bert embedding test shape torch.Size([1738, 36, 13, 768])\n",
      "encoded......\n",
      "4054\n",
      "1738\n",
      "F1 score... 0.842857142857143\n",
      "-------------------------------------------\n",
      "---------------- rep  2 -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wkhal001/envs/Twitter_crisis/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2143: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert embedding train shape torch.Size([4054, 36, 13, 768])\n",
      "Bert embedding test shape torch.Size([1738, 36, 13, 768])\n",
      "encoded......\n",
      "4054\n",
      "1738\n",
      "F1 score... 0.842857142857143\n",
      "-------------------------------------------\n",
      "---------------- rep  3 -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wkhal001/envs/Twitter_crisis/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2143: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert embedding train shape torch.Size([4054, 36, 13, 768])\n",
      "Bert embedding test shape torch.Size([1738, 36, 13, 768])\n",
      "encoded......\n",
      "4054\n",
      "1738\n",
      "F1 score... 0.842857142857143\n",
      "-------------------------------------------\n",
      "---------------- rep  4 -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wkhal001/envs/Twitter_crisis/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2143: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import transformers\n",
    "from transformers import AutoModel, BertTokenizerFast, BertModel, BertTokenizer\n",
    "\n",
    "# specify GPU\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "rep = 0\n",
    "svm_bert_dict = {}\n",
    "for i in range(10): \n",
    "    print('---------------- rep ',rep,'-------------')\n",
    "    \n",
    "    ###### Run BERT to get the train and test feature vectors ######\n",
    "    bert = BertModel.from_pretrained('bert-base-uncased',output_hidden_states = True)    \n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    max_seq= 36\n",
    "\n",
    "    ###### vectorize text using BERT          \n",
    "    max_seq_len = max_seq  \n",
    "    #tokenize and encode sequences in the training set\n",
    "    tokens_train = tokenizer.batch_encode_plus(\n",
    "        Train_X['text'].tolist(),\n",
    "        max_length = max_seq_len,\n",
    "        pad_to_max_length=True,\n",
    "        truncation=True,\n",
    "        return_token_type_ids=False\n",
    "    )\n",
    "\n",
    "    # tokenize and encode sequences in the validation set\n",
    "    tokens_test = tokenizer.batch_encode_plus(\n",
    "        Test_X['text'].tolist(),\n",
    "        max_length = max_seq_len,\n",
    "        pad_to_max_length=True,\n",
    "        truncation=True,\n",
    "        return_token_type_ids=False\n",
    "    )                                                                \n",
    "\n",
    "    # for train set\n",
    "    train_seq = torch.tensor(tokens_train['input_ids'])\n",
    "    train_mask = torch.tensor(tokens_train['attention_mask'])\n",
    "    train_y = torch.tensor(Train_Y.tolist())\n",
    "\n",
    "    # for validation set\n",
    "    test_seq = torch.tensor(tokens_test['input_ids'])\n",
    "    test_mask = torch.tensor(tokens_test['attention_mask'])\n",
    "    test_y = torch.tensor(Test_Y.tolist())\n",
    "\n",
    "    bert.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = bert(train_seq,train_mask)\n",
    "        hidden_states = outputs[2]\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs_test = bert(test_seq,test_mask)\n",
    "        hidden_states_test = outputs_test[2]\n",
    "\n",
    "    token_embeddings = torch.stack(hidden_states, dim=0)\n",
    "    token_embeddings = token_embeddings.permute(1,2,0,3)\n",
    "\n",
    "    token_embeddings_test = torch.stack(hidden_states_test, dim=0)\n",
    "    token_embeddings_test = token_embeddings_test.permute(1,2,0,3)\n",
    "\n",
    "    print('Bert embedding train shape',token_embeddings.size())\n",
    "    print('Bert embedding test shape',token_embeddings_test.size())\n",
    "\n",
    "    #### add the word vectors of the last 4 layers -- each token is concatenated in 3072 length vector    \n",
    "    Train_bert_SVM = []\n",
    "    for input_tweet in token_embeddings: \n",
    "        token_vecs_cat = []\n",
    "        for token in input_tweet:\n",
    "            cat_vec = torch.cat((token[-1], token[-2], token[-3], token[-4]), dim=0)   # 4 last hidden layers\n",
    "            #cat_vec = torch.sum(torch.stack([token[-1],token[-2],token[-3],token[-4]]), dim = 0)           # summing the 4 last hidden layers\n",
    "            # cat_vec = token[-1]\n",
    "            token_vecs_cat.append(cat_vec)\n",
    "\n",
    "        Train_bert_SVM.append(token_vecs_cat[0])\n",
    "\n",
    "\n",
    "    Test_bert_SVM = []\n",
    "    for input_tweet in token_embeddings_test: \n",
    "        token_vecs_cat = []\n",
    "        for token in input_tweet:\n",
    "            cat_vec_t = torch.cat((token[-1], token[-2], token[-3], token[-4]), dim=0)\n",
    "            #cat_vec_t = torch.sum(torch.stack([token[-1],token[-2],token[-3],token[-4]]), dim = 0)           # summing the 4 last hidden layers\n",
    "            #cat_vec_t = token[-1]\n",
    "            token_vecs_cat.append(cat_vec_t)\n",
    "\n",
    "        Test_bert_SVM.append(token_vecs_cat[0])\n",
    "\n",
    "    print('encoded......')\n",
    "    print(len(Train_bert_SVM))\n",
    "    print(len(Test_bert_SVM))\n",
    "\n",
    "    #### convert train and test data tensors into numpy array\n",
    "    ls_input_train = [e.numpy() for e in Train_bert_SVM]\n",
    "    ls_input_test = [e.numpy() for e in Test_bert_SVM]  \n",
    "    \n",
    "    ### train the classifier #######\n",
    "    SVM = SVC(C=15, kernel='rbf',degree=2 ,gamma=0.001)  \n",
    "    SVM.fit(ls_input_train,Train_Y)\n",
    "    \n",
    "    ## test the classifier #######\n",
    "    preds = SVM.predict(ls_input_test)\n",
    "    \n",
    "    ##### plot results #######\n",
    "    dict_r = classification_report(Test_Y, preds,output_dict = True)\n",
    "    print('F1 score...',dict_r['1']['f1-score'])\n",
    "    rep = rep + 1\n",
    "    print('-------------------------------------------')\n",
    "    \n",
    "    svm_bert_dict.update({rep:dict_r})\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Results by fine-tuned BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we train and evaluate fine-tuned BERT model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### Additional imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from transformers import AdamW\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "from Baseline_Models import Display_metrics,Display_classification_report,Confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import transformers\n",
    "from transformers import AutoModel, BertTokenizerFast\n",
    "\n",
    "# specify GPU\n",
    "device = torch.device(\"cuda\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### BERT architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we define BERT architecture in pytorch (I used BERT model from Huggingface) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT_Arch(nn.Module):\n",
    "\n",
    "    def __init__(self, bert, layers = None):\n",
    "      \n",
    "        super(BERT_Arch, self).__init__()\n",
    "\n",
    "        self.bert = bert \n",
    "      \n",
    "        # dropout layer\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "      \n",
    "        # relu activation function\n",
    "        self.relu =  nn.ReLU()\n",
    "    \n",
    "\n",
    "        self.fc1 = nn.Linear(768,2)\n",
    "        \n",
    "\n",
    "        #softmax activation function\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    #define the forward pass\n",
    "    def forward(self, sent_id, mask,layers = 2):\n",
    "\n",
    "        #pass the inputs to the model  \n",
    "        _, cls_hs = self.bert(sent_id, attention_mask=mask,return_dict=False)\n",
    "      \n",
    "        x = self.fc1(cls_hs)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "      \n",
    "        if layers == 2:\n",
    "            x = self.fc2(x)\n",
    "        \n",
    "        if layers == 3: \n",
    "            x = self.fc2(x)\n",
    "            x = self.fc3(x)\n",
    "        \n",
    "        if layers == 4: \n",
    "            x = self.fc2(x)\n",
    "            x = self.fc3(x)\n",
    "            x = self.fc4(x)\n",
    "            \n",
    "        if layers == 5: \n",
    "            x = self.fc2(x)\n",
    "            x = self.fc3(x)\n",
    "            x = self.fc4(x)\n",
    "            x = self.fc5(x)\n",
    "            \n",
    "        \n",
    "        # apply softmax activation\n",
    "        x = self.softmax(x)\n",
    "\n",
    "        return x  \n",
    "    \n",
    "    \n",
    "# function to train the model\n",
    "def train():\n",
    "      \n",
    "    model.train()\n",
    "\n",
    "    total_loss, total_accuracy = 0, 0\n",
    "  \n",
    "    # empty list to save model predictions\n",
    "    total_preds=[]\n",
    "  \n",
    "    # iterate over batches\n",
    "    for step,batch in enumerate(train_dataloader):\n",
    "    \n",
    "        # progress update after every 50 batches.\n",
    "        if step % 50 == 0 and not step == 0:\n",
    "              print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
    "\n",
    "        # push the batch to gpu\n",
    "        batch = [r.to(device) for r in batch]\n",
    " \n",
    "        sent_id, mask, labels = batch\n",
    "\n",
    "        # clear previously calculated gradients \n",
    "        model.zero_grad()        \n",
    "\n",
    "        # get model predictions for the current batch\n",
    "        preds = model(sent_id, mask,nb_layers)\n",
    "\n",
    "        # compute the loss between actual and predicted values\n",
    "        loss = cross_entropy(preds, labels)\n",
    "\n",
    "        # add on to the total loss\n",
    "        total_loss = total_loss + loss.item()\n",
    "\n",
    "        # backward pass to calculate the gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # model predictions are stored on GPU. So, push it to CPU\n",
    "        preds=preds.detach().cpu().numpy()\n",
    "\n",
    "        # append the model predictions\n",
    "        total_preds.append(preds)\n",
    "\n",
    "        # compute the training loss of the epoch\n",
    "        avg_loss = total_loss / len(train_dataloader)\n",
    "  \n",
    "    # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
    "    # reshape the predictions in form of (number of samples, no. of classes)\n",
    "    total_preds  = np.concatenate(total_preds, axis=0)\n",
    "\n",
    "    #returns the loss and predictions\n",
    "    return avg_loss, total_preds\n",
    "\n",
    "# function for evaluating the model\n",
    "def evaluate():\n",
    "  \n",
    "    print(\"\\nEvaluating...\")\n",
    "  \n",
    "    # deactivate dropout layers\n",
    "    model.eval()\n",
    "    total_loss, total_accuracy = 0, 0\n",
    "  \n",
    "    # empty list to save the model predictions\n",
    "    total_preds = []\n",
    "\n",
    "    # iterate over batches\n",
    "    for step,batch in enumerate(val_dataloader):\n",
    "    \n",
    "        # Progress update every 50 batches.\n",
    "        if step % 50 == 0 and not step == 0:\n",
    "      \n",
    "            # Calculate elapsed time in minutes.\n",
    "            #elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
    "\n",
    "        # push the batch to gpu\n",
    "        batch = [t.to(device) for t in batch]\n",
    "\n",
    "        sent_id, mask, labels = batch\n",
    "\n",
    "        # deactivate autograd\n",
    "        with torch.no_grad(): \n",
    "            # model predictions\n",
    "            preds = model(sent_id, mask,nb_layers)\n",
    "\n",
    "            # compute the validation loss between actual and predicted values\n",
    "            loss = cross_entropy(preds,labels)\n",
    "\n",
    "            total_loss = total_loss + loss.item()\n",
    "\n",
    "            preds = preds.detach().cpu().numpy()\n",
    "\n",
    "            total_preds.append(preds)\n",
    "\n",
    "    # compute the validation loss of the epoch\n",
    "    avg_loss = total_loss / len(val_dataloader) \n",
    "\n",
    "    # reshape the predictions in form of (number of samples, no. of classes)\n",
    "    total_preds  = np.concatenate(total_preds, axis=0)\n",
    "\n",
    "    return avg_loss, total_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>non_cleaned_text</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5667</th>\n",
       "      <td>If you want to figure out the road situation i...</td>\n",
       "      <td>want figure road situation area check harveyfl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>The Wall Street Journal: Houston flooding expe...</td>\n",
       "      <td>wall street journal houston flooding expected ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3312</th>\n",
       "      <td>@cinnamonfire8 oh and that white oak and houst...</td>\n",
       "      <td>cinnamonfire8 oh white oak houston ave floodin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5021</th>\n",
       "      <td>Guys, I'm south of the Conroe dam. Where is ev...</td>\n",
       "      <td>guys im south conroe dam everyone evacuating g...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5104</th>\n",
       "      <td>12:43pm.. flooding in Breaux Bridge (St. Marti...</td>\n",
       "      <td>1243pm flooding breaux bridge st martin parish...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Heavy Rain, Flooding Cause Concern Across Tamp...</td>\n",
       "      <td>heavy rain flooding cause concern across tampa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3755</th>\n",
       "      <td>The Wall Street Journal: Hurricane Harvey like...</td>\n",
       "      <td>wall street journal hurricane harvey likely sn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5438</th>\n",
       "      <td>Please DO NOT drive into the water if you can ...</td>\n",
       "      <td>please drive water see road please harvey</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5419</th>\n",
       "      <td>President Trump Tweets About 2016 Election and...</td>\n",
       "      <td>president trump tweets 2016 election border wa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194</th>\n",
       "      <td>@KHOUBlake11 #Houston: Dam opened, flooding do...</td>\n",
       "      <td>khoublake11 houston dam opened flooding downst...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4054 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       non_cleaned_text  \\\n",
       "5667  If you want to figure out the road situation i...   \n",
       "813   The Wall Street Journal: Houston flooding expe...   \n",
       "3312  @cinnamonfire8 oh and that white oak and houst...   \n",
       "5021  Guys, I'm south of the Conroe dam. Where is ev...   \n",
       "5104  12:43pm.. flooding in Breaux Bridge (St. Marti...   \n",
       "...                                                 ...   \n",
       "48    Heavy Rain, Flooding Cause Concern Across Tamp...   \n",
       "3755  The Wall Street Journal: Hurricane Harvey like...   \n",
       "5438  Please DO NOT drive into the water if you can ...   \n",
       "5419  President Trump Tweets About 2016 Election and...   \n",
       "1194  @KHOUBlake11 #Houston: Dam opened, flooding do...   \n",
       "\n",
       "                                                   text  label  \n",
       "5667  want figure road situation area check harveyfl...      0  \n",
       "813   wall street journal houston flooding expected ...      0  \n",
       "3312  cinnamonfire8 oh white oak houston ave floodin...      0  \n",
       "5021  guys im south conroe dam everyone evacuating g...      0  \n",
       "5104  1243pm flooding breaux bridge st martin parish...      0  \n",
       "...                                                 ...    ...  \n",
       "48    heavy rain flooding cause concern across tampa...      0  \n",
       "3755  wall street journal hurricane harvey likely sn...      0  \n",
       "5438          please drive water see road please harvey      0  \n",
       "5419  president trump tweets 2016 election border wa...      0  \n",
       "1194  khoublake11 houston dam opened flooding downst...      0  \n",
       "\n",
       "[4054 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>non_cleaned_text</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1094</th>\n",
       "      <td>Photos of flooding at Villas Dr./Golden Beach ...</td>\n",
       "      <td>photos flooding villas drgolden beach sent us ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1762</th>\n",
       "      <td>Hurricane Harvey videos | Fort Worth Star-Tele...</td>\n",
       "      <td>hurricane harvey videos fort worth startelegra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2034</th>\n",
       "      <td>11830 Greenspark Ln. - Awaiting Update. #Houst...</td>\n",
       "      <td>11830 greenspark ln awaiting update houston ha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2951</th>\n",
       "      <td>@ManBoobiees @LukeBryanSucks @klstorey Oh and ...</td>\n",
       "      <td>manboobiees lukebryansucks klstorey oh also ho...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5520</th>\n",
       "      <td>Guys, this storm is no joke ðŸ˜³#HurricaneHarvey ...</td>\n",
       "      <td>guys storm joke ðŸ˜³hurricaneharvey fl side effec...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4914</th>\n",
       "      <td>@jackmcme @matthaig1 Indeed, and sometimes dro...</td>\n",
       "      <td>jackmcme matthaig1 indeed sometimes drought fo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4737</th>\n",
       "      <td>My family is #blessed to have spent #Hurricane...</td>\n",
       "      <td>family blessed spent hurricaneharvey south for...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5435</th>\n",
       "      <td>HARVEY UPDATE: Williamson County officials mon...</td>\n",
       "      <td>harvey update williamson county officials moni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3007</th>\n",
       "      <td>Please continue to keep Houston in your though...</td>\n",
       "      <td>please continue keep houston thoughts amp pray...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>Houston, Texas freeway sign nearly submerged a...</td>\n",
       "      <td>houston texas freeway sign nearly submerged am...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1738 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       non_cleaned_text  \\\n",
       "1094  Photos of flooding at Villas Dr./Golden Beach ...   \n",
       "1762  Hurricane Harvey videos | Fort Worth Star-Tele...   \n",
       "2034  11830 Greenspark Ln. - Awaiting Update. #Houst...   \n",
       "2951  @ManBoobiees @LukeBryanSucks @klstorey Oh and ...   \n",
       "5520  Guys, this storm is no joke ðŸ˜³#HurricaneHarvey ...   \n",
       "...                                                 ...   \n",
       "4914  @jackmcme @matthaig1 Indeed, and sometimes dro...   \n",
       "4737  My family is #blessed to have spent #Hurricane...   \n",
       "5435  HARVEY UPDATE: Williamson County officials mon...   \n",
       "3007  Please continue to keep Houston in your though...   \n",
       "1258  Houston, Texas freeway sign nearly submerged a...   \n",
       "\n",
       "                                                   text  label  \n",
       "1094  photos flooding villas drgolden beach sent us ...      0  \n",
       "1762  hurricane harvey videos fort worth startelegra...      0  \n",
       "2034  11830 greenspark ln awaiting update houston ha...      0  \n",
       "2951  manboobiees lukebryansucks klstorey oh also ho...      0  \n",
       "5520  guys storm joke ðŸ˜³hurricaneharvey fl side effec...      0  \n",
       "...                                                 ...    ...  \n",
       "4914  jackmcme matthaig1 indeed sometimes drought fo...      0  \n",
       "4737  family blessed spent hurricaneharvey south for...      0  \n",
       "5435  harvey update williamson county officials moni...      0  \n",
       "3007  please continue keep houston thoughts amp pray...      0  \n",
       "1258  houston texas freeway sign nearly submerged am...      0  \n",
       "\n",
       "[1738 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### Fine-tuned BERT evaluation mode (Use best fine-tuned model weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, I used BERT weights produced by the best fine-tuned model (change the saved model path accordingly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERT is used in evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set:  4054\n",
      "testing set:  1738\n",
      "f1-score for class 1 ---> 0.8903225806451613\n",
      "Precision for class 1 ---> 0.8734177215189873\n",
      "Recall for class 1 ---> 0.9078947368421053\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f6db47469d0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "############################################################\n",
    "############### Test script ################################\n",
    "############################################################\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "%matplotlib inline\n",
    "\n",
    "Config_ls = {'lr':0.00002,'nb_epochs':20,'nb_layers':1,'max_seq':36,'batch_size':16}\n",
    "\n",
    "print(\"training set: \",str(len(Train_X)))\n",
    "print(\"testing set: \",str(len(Test_X)))\n",
    "\n",
    "##############################\n",
    "#### parameters ##############\n",
    "##############################\n",
    "learning_rate = Config_ls['lr']\n",
    "nb_epochs = Config_ls['nb_epochs']\n",
    "max_seq = Config_ls['max_seq']\n",
    "batch_size = Config_ls['batch_size']\n",
    "nb_layers =Config_ls['nb_layers']\n",
    "##############################\n",
    "##############################\n",
    "##############################\n",
    "\n",
    "# import BERT-base pretrained model\n",
    "bert = AutoModel.from_pretrained('bert-base-uncased')                #bert-base-uncased\n",
    "\n",
    "# Load the BERT tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')   #bert-base-uncased\n",
    "\n",
    "# freeze all the parameters\n",
    "for param in bert.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# pass the pre-trained BERT to our define architecture\n",
    "model = BERT_Arch(bert,nb_layers)\n",
    "\n",
    "# push the model to GPU\n",
    "model = model.to(device)\n",
    "\n",
    "### load pretrained model ########\n",
    "model.load_state_dict(torch.load(\"/home/wkhal001/Crisis-classification/scripts-rescue-detection/__comparison_new_experimental_design/Fine_tuned_bert/saved_weights_bert_7.pt\"))\n",
    "model.eval()\n",
    "\n",
    "# parameter 1\n",
    "max_seq_len = max_seq   ######### parameter 1 ###################\n",
    "\n",
    "# tokenize and encode sequences in the training set\n",
    "tokens_train = tokenizer.batch_encode_plus(\n",
    "        Train_X['text'].tolist(),\n",
    "        padding='max_length',\n",
    "        max_length = max_seq_len,\n",
    "        truncation=True,\n",
    "        return_token_type_ids=False\n",
    "    )\n",
    "\n",
    "# tokenize and encode sequences in the validation set\n",
    "tokens_test = tokenizer.batch_encode_plus(\n",
    "        Test_X['text'].tolist(),\n",
    "        padding='max_length',\n",
    "        max_length = max_seq_len,\n",
    "        truncation=True,\n",
    "        return_token_type_ids=False\n",
    "    )                                                                \n",
    "\n",
    "# for train set\n",
    "train_seq = torch.tensor(tokens_train['input_ids'])\n",
    "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
    "train_y = torch.tensor(Train_Y.tolist())\n",
    "\n",
    "# for test set\n",
    "test_seq = torch.tensor(tokens_test['input_ids'])\n",
    "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
    "test_y = torch.tensor(Test_Y.tolist())\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr = learning_rate )               ######### parameter 2 ###################\n",
    "\n",
    "#compute the class weights\n",
    "#class_wts = compute_class_weight('balanced', np.unique(Train_Y),Train_Y)     \n",
    "class_wts = compute_class_weight(class_weight = \"balanced\", classes= np.unique(Train_Y), y= Train_Y)\n",
    "\n",
    "# wrap tensors\n",
    "train_data = TensorDataset(train_seq, train_mask, train_y)               ######### parameter 3 ###################\n",
    "# sampler for sampling the data during training\n",
    "train_sampler = RandomSampler(train_data)\n",
    "# dataLoader for train set\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# wrap tensors\n",
    "val_data = TensorDataset(test_seq, test_mask, test_y)\n",
    "# sampler for sampling the data during training\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "# dataLoader for validation set\n",
    "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)\n",
    "\n",
    "# convert class weights to tensor\n",
    "weights= torch.tensor(class_wts,dtype=torch.float)\n",
    "weights = weights.to(device)\n",
    "\n",
    "# loss function\n",
    "cross_entropy = nn.NLLLoss(weight=weights)  # weight=weights                                              \n",
    "\n",
    "epochs = nb_epochs   ######### parameter 4 ###################\n",
    "\n",
    "\n",
    "#### test on the testing set #######  \n",
    "with torch.no_grad():\n",
    "    preds = model(test_seq.to(device), test_mask.to(device),nb_layers)\n",
    "    preds = preds.detach().cpu().numpy()\n",
    "    preds = np.argmax(preds, axis = 1)\n",
    "\n",
    "cr_dict = classification_report(Test_Y, preds,output_dict = True)\n",
    "f_score = f1_score(Test_Y, preds, labels=np.unique(preds),average='binary')\n",
    "print(\"f1-score for class 1 --->\",f_score)\n",
    "\n",
    "precision_score = cr_dict['1']['precision']\n",
    "print(\"Precision for class 1 --->\",precision_score)\n",
    "\n",
    "#recall_score = recall_score(test_y, preds, average='binary')   #micro  #binary\n",
    "recall_score = cr_dict['1']['recall']\n",
    "print(\"Recall for class 1 --->\",recall_score)\n",
    "\n",
    "\n",
    "#cm = confusion_matrix(Test_Y, preds, labels=SVM.classes_)\n",
    "cm = confusion_matrix(Test_Y, preds, labels=np.unique(Train_Y))\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=np.unique(Train_Y))\n",
    "\n",
    "#disp.figure_.savefig(img_path)\n",
    "disp.plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Fine-tuned BERT (training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, I train (fine-tune) BERT 10 times and save the weights at each iteration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "%matplotlib inline\n",
    "\n",
    "Config_ls = {'lr':0.00002,'nb_epochs':20,'nb_layers':1,'max_seq':36,'batch_size':16}\n",
    "\n",
    "rep = 1\n",
    "Save_reps = {'f1':[],'recall':[],'precision':[]}\n",
    "base_path_img = '/home/wkhal001/Crisis-classification/scripts-rescue-detection/__comparison_new_experimental_design/Fine_tuned_bert_2/'\n",
    "base_path_bert = '/home/wkhal001/Crisis-classification/scripts-rescue-detection/__comparison_new_experimental_design/Fine_tuned_bert_2/'\n",
    "for i in range(10):\n",
    "    print('-------------- rep ',str(rep),'---------------------')\n",
    "    \n",
    "    print(\"training set: \",str(len(Train_X)))\n",
    "    print(\"testing set: \",str(len(Test_X)))\n",
    "    \n",
    "    ##############################\n",
    "    #### parameters ##############\n",
    "    ##############################\n",
    "    learning_rate = Config_ls['lr']\n",
    "    nb_epochs = Config_ls['nb_epochs']\n",
    "    max_seq = Config_ls['max_seq']\n",
    "    batch_size = Config_ls['batch_size']\n",
    "    nb_layers =Config_ls['nb_layers']\n",
    "    ##############################\n",
    "    ##############################\n",
    "    ##############################\n",
    "\n",
    "    # import BERT-base pretrained model\n",
    "    bert = AutoModel.from_pretrained('bert-base-uncased')                #bert-base-uncased\n",
    "\n",
    "    # Load the BERT tokenizer\n",
    "    tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')   #bert-base-uncased\n",
    "\n",
    "    # freeze all the parameters\n",
    "    for param in bert.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "    # pass the pre-trained BERT to our define architecture\n",
    "    model = BERT_Arch(bert,nb_layers)\n",
    "\n",
    "    # push the model to GPU\n",
    "    model = model.to(device)\n",
    "    \n",
    "    \n",
    "    # parameter 1\n",
    "    max_seq_len = max_seq   ######### parameter 1 ###################\n",
    "\n",
    "    # tokenize and encode sequences in the training set\n",
    "    tokens_train = tokenizer.batch_encode_plus(\n",
    "            Train_X['text'].tolist(),\n",
    "            padding='max_length',\n",
    "            max_length = max_seq_len,\n",
    "            truncation=True,\n",
    "            return_token_type_ids=False\n",
    "        )\n",
    "\n",
    "    # tokenize and encode sequences in the validation set\n",
    "    tokens_test = tokenizer.batch_encode_plus(\n",
    "            Test_X['text'].tolist(),\n",
    "            padding='max_length',\n",
    "            max_length = max_seq_len,\n",
    "            truncation=True,\n",
    "            return_token_type_ids=False\n",
    "        )                                                                \n",
    "\n",
    "    # for train set\n",
    "    train_seq = torch.tensor(tokens_train['input_ids'])\n",
    "    train_mask = torch.tensor(tokens_train['attention_mask'])\n",
    "    train_y = torch.tensor(Train_Y.tolist())\n",
    "\n",
    "    # for test set\n",
    "    test_seq = torch.tensor(tokens_test['input_ids'])\n",
    "    test_mask = torch.tensor(tokens_test['attention_mask'])\n",
    "    test_y = torch.tensor(Test_Y.tolist())\n",
    "\n",
    "    optimizer = AdamW(model.parameters(), lr = learning_rate )               ######### parameter 2 ###################\n",
    "\n",
    "    #compute the class weights\n",
    "    #class_wts = compute_class_weight('balanced', np.unique(Train_Y),Train_Y)     \n",
    "    class_wts = compute_class_weight(class_weight = \"balanced\", classes= np.unique(Train_Y), y= Train_Y)\n",
    "\n",
    "    # wrap tensors\n",
    "    train_data = TensorDataset(train_seq, train_mask, train_y)               ######### parameter 3 ###################\n",
    "    # sampler for sampling the data during training\n",
    "    train_sampler = RandomSampler(train_data)\n",
    "    # dataLoader for train set\n",
    "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "    # wrap tensors\n",
    "    val_data = TensorDataset(test_seq, test_mask, test_y)\n",
    "    # sampler for sampling the data during training\n",
    "    val_sampler = SequentialSampler(val_data)\n",
    "    # dataLoader for validation set\n",
    "    val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)\n",
    "\n",
    "    # convert class weights to tensor\n",
    "    weights= torch.tensor(class_wts,dtype=torch.float)\n",
    "    weights = weights.to(device)\n",
    "\n",
    "    # loss function\n",
    "    cross_entropy = nn.NLLLoss(weight=weights)  # weight=weights                                              \n",
    "\n",
    "    epochs = nb_epochs   ######### parameter 4 ###################\n",
    "\n",
    "    # set initial loss to infinite\n",
    "    best_valid_loss = float('inf')\n",
    "\n",
    "    # empty lists to store training and validation loss of each epoch\n",
    "    train_losses=[]\n",
    "    valid_losses=[]\n",
    "\n",
    "    #for each epoch\n",
    "    model_save_path = \"/home/wkhal001/Crisis-classification/scripts-rescue-detection/__comparison_new_experimental_design/Fine_tuned_bert/saved_weights_bert.pt\"\n",
    "    model_save_path = base_path_bert + \"saved_weights_bert_\"+ str(rep)+\".pt\"\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
    "\n",
    "        #train model\n",
    "        train_loss, _ = train()\n",
    "\n",
    "        #evaluate model\n",
    "        valid_loss, _ = evaluate()\n",
    "\n",
    "        #save the best model\n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            torch.save(model.state_dict(), model_save_path)  \n",
    "            #saved_weights.pt\n",
    "\n",
    "            # append training and validation loss\n",
    "            train_losses.append(train_loss)\n",
    "            valid_losses.append(valid_loss)\n",
    "\n",
    "            print(f'\\nTraining Loss: {train_loss:.3f}')\n",
    "            print(f'Validation Loss: {valid_loss:.3f}')\n",
    "\n",
    "        \n",
    "    #### test on the testing set #######  \n",
    "    with torch.no_grad():\n",
    "        preds = model(test_seq.to(device), test_mask.to(device),nb_layers)\n",
    "        preds = preds.detach().cpu().numpy()\n",
    "        preds = np.argmax(preds, axis = 1)\n",
    "        \n",
    "    cr_dict = classification_report(Test_Y, preds,output_dict = True)\n",
    "    f_score = f1_score(Test_Y, preds, labels=np.unique(preds),average='binary')\n",
    "    print(\"f1-score for class 1 --->\",f_score)\n",
    "    Save_reps['f1'].append(f_score)\n",
    "\n",
    "    precision_score = cr_dict['1']['precision']\n",
    "    print(\"Precision for class 1 --->\",precision_score)\n",
    "    Save_reps['precision'].append(precision_score)\n",
    "\n",
    "    #recall_score = recall_score(test_y, preds, average='binary')   #micro  #binary\n",
    "    recall_score = cr_dict['1']['recall']\n",
    "    print(\"Recall for class 1 --->\",recall_score)\n",
    "    Save_reps['recall'].append(recall_score)\n",
    "    \n",
    "\n",
    "    #cm = confusion_matrix(Test_Y, preds, labels=SVM.classes_)\n",
    "    cm = confusion_matrix(Test_Y, preds, labels=np.unique(Train_Y))\n",
    "\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=np.unique(Train_Y))\n",
    "    img_path = base_path_img + 'confusion_matrix_re' + str(rep) + '.png'\n",
    "    \n",
    "    #disp.figure_.savefig(img_path)\n",
    "    disp.plot()\n",
    "    plt.savefig(img_path)\n",
    "    rep = rep + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# create a binary pickle file \n",
    "f = open(\"/home/wkhal001/Crisis-classification/scripts-rescue-detection/__comparison_new_experimental_design/Fine_tuned_bert/Saved_results_fine_tuned_bert.pkl\",\"wb\")\n",
    "pickle.dump(Save_reps,f)\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open a file, where you stored the pickled data\n",
    "file = open(\"/home/wkhal001/Crisis-classification/scripts-rescue-detection/__comparison_new_experimental_design/Fine_tuned_bert/Saved_results_fine_tuned_bert.pkl\", 'rb')\n",
    "\n",
    "# dump information to that file\n",
    "data = pickle.load(file)\n",
    "\n",
    "# close the file\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1': [0.8695652173913043,\n",
       "  0.8689655172413793,\n",
       "  0.8783783783783783,\n",
       "  0.8387096774193549,\n",
       "  0.8510638297872342,\n",
       "  0.8645161290322582,\n",
       "  0.8903225806451613,\n",
       "  0.8758169934640522,\n",
       "  0.8741721854304636,\n",
       "  0.8794326241134751],\n",
       " 'recall': [0.7894736842105263,\n",
       "  0.8289473684210527,\n",
       "  0.8552631578947368,\n",
       "  0.8552631578947368,\n",
       "  0.7894736842105263,\n",
       "  0.881578947368421,\n",
       "  0.9078947368421053,\n",
       "  0.881578947368421,\n",
       "  0.868421052631579,\n",
       "  0.8157894736842105],\n",
       " 'precision': [0.967741935483871,\n",
       "  0.9130434782608695,\n",
       "  0.9027777777777778,\n",
       "  0.8227848101265823,\n",
       "  0.9230769230769231,\n",
       "  0.8481012658227848,\n",
       "  0.8734177215189873,\n",
       "  0.8701298701298701,\n",
       "  0.88,\n",
       "  0.9538461538461539]}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of runs.... 10\n",
      "------------- F1 scores --------------------\n",
      "average (10 runs)  0.8690943132903062\n",
      "stdev (10 runs)  0.014848178440003015\n",
      "max (10 runs)  0.8903225806451613\n",
      "min (10 runs)  0.8387096774193549\n",
      "------------- recall scores --------------------\n",
      "average (10 runs)  0.8473684210526315\n",
      "stdev (10 runs)  0.040293628343353864\n",
      "max (10 runs)  0.9078947368421053\n",
      "min (10 runs)  0.7894736842105263\n",
      "------------- precision scores --------------------\n",
      "average (10 runs)  0.895491993604382\n",
      "stdev (10 runs)  0.04552173594107878\n",
      "max (10 runs)  0.967741935483871\n",
      "min (10 runs)  0.8227848101265823\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "\n",
    "print('number of runs....',len(data['f1']))\n",
    "\n",
    "print('------------- F1 scores --------------------')\n",
    "print('average (10 runs) ',statistics.mean(data['f1']))\n",
    "print('stdev (10 runs) ',statistics.stdev(data['f1']))\n",
    "print('max (10 runs) ',max(data['f1']))\n",
    "print('min (10 runs) ',min(data['f1']))\n",
    "\n",
    "print('------------- recall scores --------------------')\n",
    "print('average (10 runs) ',statistics.mean(data['recall']))\n",
    "print('stdev (10 runs) ',statistics.stdev(data['recall']))\n",
    "print('max (10 runs) ',max(data['recall']))\n",
    "print('min (10 runs) ',min(data['recall']))\n",
    "\n",
    "\n",
    "print('------------- precision scores --------------------')\n",
    "print('average (10 runs) ',statistics.mean(data['precision']))\n",
    "print('stdev (10 runs) ',statistics.stdev(data['precision']))\n",
    "print('max (10 runs) ',max(data['precision']))\n",
    "print('min (10 runs) ',min(data['precision']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Results by integrated model (using fine-tuned BERT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following code, I merged the fine-tuned BERT (best model obtained) with the logical features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### Logical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "ls_crisis_hashtags = ['SOSHouston','SOSHarvey','HelpHouston','harveysos','harveyrescue','sendhelp','HarveySOS','Rescue','rescue'\n",
    "                      ,'HarveyFlood','HARVEYHELP','Relief','PLEASEHELP','URGENT']\n",
    "\n",
    "def extract_hash_tags(sentence,ls_crisis_hashtags):\n",
    "    crisis_hashtag_found = False\n",
    "    for part in sentence.split():\n",
    "        if part.startswith('#'): \n",
    "            if part[1:] in ls_crisis_hashtags:\n",
    "                crisis_hashtag_found =True\n",
    "                \n",
    "    return crisis_hashtag_found\n",
    "\n",
    "#--------------------  Create filter 1 ---------------------------------------#\n",
    "# Feature 1.1 keywords with hurricane/flood\n",
    "rgx_f1_1 = \"\\\\b(Hurricane|HurricaneHarvey|Harvey2017|HARVEYHELP|HarveyStorm|harveyhouston|houstonflood|houstonfloods|houstonflooding|texasflood|texasfloods|texasflooding|harveyflood|harveyflooding|HurricaneFlood|HurricaneSOS)\\\\b\"\n",
    "\n",
    "# Feature 1.2 keywords with situation descriptions\n",
    "rgx_f1_2 = \"\\\\b(stranded|stuck|trapped|traps?|trapping|roofs?|rooftop|injured|hurt)\\\\b\"\n",
    "\n",
    "# Feature 1.3: contain both the following two keyword groups (ignore case):\n",
    "# group 1: names of cities and towns near Houston\n",
    "# group 2: flood related keywords. e.g. flood, flooding\n",
    "rgx_f1_3a = \"\\\\b(Houston|Texas|Galveston|Lake\\\\sJackson|Pasadena|League\\\\sCity|DICKINSON|Pearland|Missouri\\\\sCity|Sugar\\\\sLand|Richmond|Rosenberg|Alvin|Baytown|Fresno|Mont\\\\sBelvieu|Humble|Woodlands|Spring|Tomball|Cypress|Brookshire\\\\sKaty|FRIENDSWOOD)\\\\b\"\n",
    "rgx_f1_3b = \"\\\\b(flood|floods|flooding|flooded)\\\\b\"\n",
    "\n",
    "\n",
    "#-------------------- added filter 1: hashtags ---------------------------------------#\n",
    "#Testing_set_comparison['f1_4'] = Testing_set_comparison.apply(lambda row:1 if extract_hash_tags(row['non_cleaned_text'],ls_crisis_hashtags) == True else 0,axis=1)\n",
    "\n",
    "\n",
    "#------------------ Create filter 2: Requesting rescue ------------------------#\n",
    "rgx_f2 = \"\\\\b(rescue|rescues|rescuing|rescued|helps?|helping|WaterRescue|WaterRescueNeeded|aid|assistance|boats?|HarveyRescue|HarveySOS|HurricaneRescue|FloodRescue|HurricaneSOS|HarveyRelief)\\\\b\"\n",
    "\n",
    "# ------ Create filter 3: address description-----------------------------------#\n",
    "address_pattern = \"(\\\\b\\\\d+\\\\s+(#?[A-z]+\\\\.?(-[A-z]+)?\\\\s+){1,3}\\\\b(#@#|ANNEX|ANEX|ANNX|ANX|#@#|ARCADE|ARC|#@#|AVENUE|AV|AVE|AVEN|AVENU|AVN|AVNUE|#@#|BAYOU|BAYOO|BYU|BAYOU|#@#|BEACH|BCH|BEACH|#@#|BEND|BND|#@#|BLUFF|BLF|BLUF|BLUFFS|BLFS|#@#|BOTTOM|BOT|BTM|BOTTM|#@#|BOULEVARD|BLVD|BOUL|BOULV|#@#|BRANCH|BR|BRNCH|#@#|BRIDGE|BRDGE|BRG|#@#|BROOK|BRK|BROOKS|BRKS|#@#|BURG|BG|BURGS|BGS|#@#|BYPASS|BYP|BYPA|BYPAS|BYPS|#@#|CAMP|CP|CMP|#@#|CANYON|CANYN|CYN|CNYN|#@#|CAPE|CPE|#@#|CAUSEWAY|CSWY|CAUSWA|CSWY|#@#|CENTER|CEN|CTR|CENT|CENTR|CENTRE|CNTER|CNTR|CENTERS|CTRS|#@#|CIRCLE|CIR|CIRC|CIRCL|CRCL|CRCLE|CIRCLES|CIRS|#@#|CLIFF|CLF|CLIFFS|CLFS|CLIFFS|#@#|CLUB|CLB|#@#|COMMON|CMN|COMMONS|CMNS|#@#|CORNER|COR|CORNERS|CORS|#@#|COURSE|CRSE|#@#|COURT|CT|COURTS|CTS|#@#|COVE|CV|COVES|COVES|CVS|#@#|CREEK|CRK|#@#|CRESCENT|CRES|CRSENT|CRSNT|CREST|CRST|CR|#@#|CROSSING|CRSSNG|XING|#@#|CROSSROAD|XRD|CROSSROADS|XRDS|#@#|CURVE|CURV|#@#|DALE|DL|#@#|#DAM#|#DM#|#@#|DIVIDE|DIV|DV|DIVIDE|DVD|#@#|DRIVE|DR|DRIV|DRV|DRIVES|DRS|#@#|ESTATE|EST|ESTATES|ESTS|#@#|EXPRESSWAY|EXP|EXPY|EXPR|EXPRESS|EXPW|#@#|EXTENSION|EXT|EXTN|EXTNSN|EXTENSIONS|EXTS|#@#|FALL|FALLS|FLS|#@#|FERRY|FRY|FRRY|FRY|#@#|FIELD|FLD|FIELDS|FLDS|#@#|FLAT|FLT|FLATS|FLTS|#@#|FORD|FRD|FORDS|FRDS|#@#|FOREST|FRST|FORESTS|FRST|#@#|FORGE|FORG|FRG|FORGES|FRGS|#@#|FORK|FRK|FORKS|FRKS|#@#|FORT|FT|FRT|#@#|FREEWAY|FWY|FREEWY|FRWAY|FRWY|FWY|#@#|GARDEN|GDN|GRDN|GARDENS|GDNS|GRDNS|#@#|GATEWAY|GTWY|GATEWY|GATWAY|GTWAY|GTWY|#@#|GLEN|GLN|GLENS|GLNS|#@#|GREEN|GRN|GREENS|GRNS|#@#|GROVE|GROV|GRV|GROVES|GRVS|#@#|HARBOR|HARB|HBR|HARBR|HRBOR|HARBORS|HBRS|#@#|HAVEN|HVN|#@#|HEIGHTS|HT|HTS|#@#|HIGHWAY|HWY|HIWAY|HIWY|HWAY|HWY|#@#|HILL|HL|HILLS|HLS|#@#|HOLLOW|HLLW|HOLW|HOLLOWS|HOLWS|#@#|INLET|INLT|#@#|ISLAND|#IS#|ISLND|ISLANDS|ISS|ISLNDS|#@#|ISLE|ISLES|#@#|JUNCTION|JCT|JCTION|JCTN|JUNCTN|JUNCTON|JUNCTIONS|JCTNS|JCTS|JUNCTIONS|#@#|KEY|KY|KEYS|KYS|#@#|KNOLL|KNL|KNOL|KNOLLS|KNLS|#@#|LAKE|LK|LAKES|LKS|#@#|LAND|LANDING|LNDG|LNDNG|#@#|LANE|LN|#@#|LIGHT|LGT|LIGHTS|LGTS|#@#|LOAF|LF|#@#|LOCK|LCK|LOCKS|LCKS|#@#|LODGE|LDG|LDGE|#@#|LOOP|LOOPS|#@#|MALL|#@#|MANOR|MNR|MANORS|MNRS|#@#|MEADOW|MDW|MEADOWS|MDWS|#@#|MEWS|#@#|MILL|ML|MILLS|MLS|#@#|MISSION|MISSN|MSN|MSSN|#@#|MOTORWAY|MTWY|#@#|MOUNT|MNT|MT|MOUNTAIN|MNTAIN|MTN|MNTN|MOUNTIN|MTIN|MOUNTAINS|MNTNS|MTNS|#@#|NECK|NCK|#@#|ORCHARD|ORCH|ORCHRD|#@#|OVAL|OVL|#@#|OVERPASS|OPAS|#@#|PARK|PRK|PARKS|#@#|PARKWAY|PARKWY|PKWAY|PKWY|PKY|PARKWAYS|PKWYS|#@#|PASS|PASSAGE|PSGE|#@#|#PATH#|#PATHS#|#@#|PIKE|PIKES|#@#|PINE|PNE|PINES|PNES|#@#|PLACE|PL|#@#|PLAIN|PLN|PLAINS|PLNS|#@#|PLAZA|PLZ|PLZA|#@#|#POINT#|PT|#POINTS#|PTS|#@#|PORT|PRT|PORTS|PRTS|#@#|PRAIRIE|PR|PRR|#@#|RADIAL|RAD|RADL|RADIEL|RADL|#@#|RAMP|#@#|RANCH|RNCH|RANCHES|RNCHS|#@#|RAPID|RPD|RAPIDS|RPDS|#@#|REST|RST|#@#|RIDGE|RDG|RDGE|RIDGES|RDGS|#@#|RIVER|RIV|RVR|RIVR|#@#|ROAD|RD|ROADS|RDS|#@#|ROUTE|RTE|#@#|ROW|#@#|RUE|#@#|#RUN#|#@#|SHOAL|SHL|SHL|SHOALS|SHLS|#@#|SHORE|SHOAR|SHR|SHORES|SHOARS|SHRS|#@#|SKYWAY|SKWY|#@#|SPRING|SPG|SPNG|SPRINGS|SPGS|SPNGS|#@#|SPUR|SPURS|#@#|SQUARE|SQ|SQR|SQRE|SQU|SQUARES|SQRS|#@#|STATION|STA|STATN|STN|#@#|STRAVENUE|STRA|STRAV|STRAVEN|STRAVN|STRVN|STRVNUE|#@#|STREAM|STRM|STREME|#@#|STREET|ST|STRT|STR|STREETS|STS|#@#|SUMMIT|SMT|SUMIT|SUMITT|SUMMIT|#@#|TERRACE|TER|TERR|#@#|THROUGHWAY|TRWY|#@#|TRACE|TRCE|TRACES|TRCE|#@#|TRACK|TRAK|TRACKS|TRAK|TRK|TRKS|#@#|TRAFFICWAY|TRFY|#@#|TRAIL|TRL|TRAILS|TRL|TRLS|#@#|TRAILER|TRLR|TRLRS|#@#|TUNNEL|TUNL|TUNLS|TUNNELS|TUNNL|#@#|TURNPIKE|TRNPK|TPKE|TURNPK|#@#|UNDERPASS|UPAS|#@#|UNION|UN|UNIONS|UNS|#@#|VALLEY|VLY|VALLY|VLLY|VLY|VALLEYS|VLYS|#@#|VIADUCT|VDCT|#VIA#|VIADCT|#@#|VIEW|VW|VIEWS|VWS|#@#|VILLAGE|VILL|VLG|VILLG|VILLIAGE|VILLAGES|VLGS|#@#|VILLE|VL|#@#|VISTA|VIS|VIST|VST|VSTA|#@#|#WALK#|#WALKS#|#@#|#WALL#|#@#|#WAY#|WY|#WAYS#|#@#|#WELL#|WL|WELLS|WLS|#@#)\\\\.?\\\\b|#@#)|(\\\\b\\\\d+\\\\s+(AVENUE|AV|AVE|AVEN|AVENU|AVN|AVNUE|#@#|HIGHWAY|HWY|HIWAY|HIWY|HWAY|#@#|ROAD|RD|ROADS|RDS|#@#|ROUTE|RTE|#@#|STREET|ST|STRT|STR|STREETS|STS|#@#)\\\\.?\\\\s+([A-z]|\\\\d+)\\\\b)\"\n",
    "non_address_pattern = \"\\\\b\\\\d+\\\\s+(am|pm|hrs?|hours?|mins?|minutes?|seconds?|#@#|days?|months?|mon|yr|yrs|years?|#@#|ft|feet|foot|in|inch(es)?|meters?|miles?|#@#|pounds?|pnd|ounce|oz|kg|kilograms?|grams?|tons?|#@#|gallons?|liters?|cubes?|volumes?|quarts?|bottles?|cups?|#@#|per|per\\\\s+cent|percent|degrees?|times?|#@#|dollars?|USD|GBP|hundreds?|thousands?|millions?|billions?|trillions?|#@#|from|to|at|and|or|were|are|Fan\\\\sClub|live|hurricane|exit|entrance|#@#|rescued|donation|people|patients|seniors|elderly|women|children|clergy|#@#)\\\\.?\\\\s+(#?[A-z]+\\\\.?(-[A-z]+)?\\\\s+){0,2}\\\\b(#@#|ANNEX|ANEX|ANNX|ANX|#@#|ARCADE|ARC|#@#|AVENUE|AV|AVE|AVEN|AVENU|AVN|AVNUE|#@#|BAYOU|BAYOO|BYU|BAYOU|#@#|BEACH|BCH|BEACH|#@#|BEND|BND|#@#|BLUFF|BLF|BLUF|BLUFFS|BLFS|#@#|BOTTOM|BOT|BTM|BOTTM|#@#|BOULEVARD|BLVD|BOUL|BOULV|#@#|BRANCH|BR|BRNCH|#@#|BRIDGE|BRDGE|BRG|#@#|BROOK|BRK|BROOKS|BRKS|#@#|BURG|BG|BURGS|BGS|#@#|BYPASS|BYP|BYPA|BYPAS|BYPS|#@#|CAMP|CP|CMP|#@#|CANYON|CANYN|CYN|CNYN|#@#|CAPE|CPE|#@#|CAUSEWAY|CSWY|CAUSWA|CSWY|#@#|CENTER|CEN|CTR|CENT|CENTR|CENTRE|CNTER|CNTR|CENTERS|CTRS|#@#|CIRCLE|CIR|CIRC|CIRCL|CRCL|CRCLE|CIRCLES|CIRS|#@#|CLIFF|CLF|CLIFFS|CLFS|CLIFFS|#@#|CLUB|CLB|#@#|COMMON|CMN|COMMONS|CMNS|#@#|CORNER|COR|CORNERS|CORS|#@#|COURSE|CRSE|#@#|COURT|CT|COURTS|CTS|#@#|COVE|CV|COVES|COVES|CVS|#@#|CREEK|CRK|#@#|CRESCENT|CRES|CRSENT|CRSNT|CREST|CRST|CR|#@#|CROSSING|CRSSNG|XING|#@#|CROSSROAD|XRD|CROSSROADS|XRDS|#@#|CURVE|CURV|#@#|DALE|DL|#@#|#DAM#|DM|#@#|DIVIDE|DIV|DV|DIVIDE|DVD|#@#|DRIVE|DR|DRIV|DRV|DRIVES|DRS|#@#|ESTATE|EST|ESTATES|ESTS|#@#|EXPRESSWAY|EXP|EXPY|EXPR|EXPRESS|EXPW|#@#|EXTENSION|EXT|EXTN|EXTNSN|EXTENSIONS|EXTS|#@#|FALL|FALLS|FLS|#@#|FERRY|FRY|FRRY|FRY|#@#|FIELD|FLD|FIELDS|FLDS|#@#|FLAT|FLT|FLATS|FLTS|#@#|FORD|FRD|FORDS|FRDS|#@#|FOREST|FRST|FORESTS|FRST|#@#|FORGE|FORG|FRG|FORGES|FRGS|#@#|FORK|FRK|FORKS|FRKS|#@#|FORT|FT|FRT|#@#|FREEWAY|FWY|FREEWY|FRWAY|FRWY|FWY|#@#|GARDEN|GDN|GRDN|GARDENS|GDNS|GRDNS|#@#|GATEWAY|GTWY|GATEWY|GATWAY|GTWAY|GTWY|#@#|GLEN|GLN|GLENS|GLNS|#@#|GREEN|GRN|GREENS|GRNS|#@#|GROVE|GROV|GRV|GROVES|GRVS|#@#|HARBOR|HARB|HBR|HARBR|HRBOR|HARBORS|HBRS|#@#|HAVEN|HVN|#@#|HEIGHTS|HT|HTS|#@#|HIGHWAY|HWY|HIWAY|HIWY|HWAY|HWY|#@#|HILL|HL|HILLS|HLS|#@#|HOLLOW|HLLW|HOLW|HOLLOWS|HOLWS|#@#|INLET|INLT|#@#|ISLAND|#IS#|ISLND|ISLANDS|ISS|ISLNDS|#@#|ISLE|ISLES|#@#|JUNCTION|JCT|JCTION|JCTN|JUNCTN|JUNCTON|JUNCTIONS|JCTNS|JCTS|JUNCTIONS|#@#|KEY|KY|KEYS|KYS|#@#|KNOLL|KNL|KNOL|KNOLLS|KNLS|#@#|LAKE|LK|LAKES|LKS|#@#|LAND|LANDING|LNDG|LNDNG|#@#|LANE|LN|#@#|LIGHT|LGT|LIGHTS|LGTS|#@#|LOAF|LF|#@#|LOCK|LCK|LOCKS|LCKS|#@#|LODGE|LDG|LDGE|#@#|LOOP|LOOPS|#@#|MALL|#@#|MANOR|MNR|MANORS|MNRS|#@#|MEADOW|MDW|MEADOWS|MDWS|#@#|MEWS|#@#|MILL|ML|MILLS|MLS|#@#|MISSION|MISSN|MSN|MSSN|#@#|MOTORWAY|MTWY|#@#|MOUNT|MNT|MT|MOUNTAIN|MNTAIN|MTN|MNTN|MOUNTIN|MTIN|MOUNTAINS|MNTNS|MTNS|#@#|NECK|NCK|#@#|ORCHARD|ORCH|ORCHRD|#@#|OVAL|OVL|#@#|OVERPASS|OPAS|#@#|PARK|PRK|PARKS|#@#|PARKWAY|PARKWY|PKWAY|PKWY|PKY|PARKWAYS|PKWYS|#@#|PASS|PASSAGE|PSGE|#@#|#PATH#|#PATHS#|#@#|PIKE|PIKES|#@#|PINE|PNE|PINES|PNES|#@#|PLACE|PL|#@#|PLAIN|PLN|PLAINS|PLNS|#@#|PLAZA|PLZ|PLZA|#@#|#POINT#|PT|#POINTS#|PTS|#@#|PORT|PRT|PORTS|PRTS|#@#|PRAIRIE|PR|PRR|#@#|RADIAL|RAD|RADL|RADIEL|RADL|#@#|RAMP|#@#|RANCH|RNCH|RANCHES|RNCHS|#@#|RAPID|RPD|RAPIDS|RPDS|#@#|REST|RST|#@#|RIDGE|RDG|RDGE|RIDGES|RDGS|#@#|RIVER|RIV|RVR|RIVR|#@#|ROAD|RD|ROADS|RDS|#@#|ROUTE|RTE|#@#|ROW|#@#|RUE|#@#|#RUN#|#@#|SHOAL|SHL|SHL|SHOALS|SHLS|#@#|SHORE|SHOAR|SHR|SHORES|SHOARS|SHRS|#@#|SKYWAY|SKWY|#@#|SPRING|SPG|SPNG|SPRINGS|SPGS|SPNGS|#@#|SPUR|SPURS|#@#|SQUARE|SQ|SQR|SQRE|SQU|SQUARES|SQRS|#@#|STATION|STA|STATN|STN|#@#|STRAVENUE|STRA|STRAV|STRAVEN|STRAVN|STRVN|STRVNUE|#@#|STREAM|STRM|STREME|#@#|STREET|ST|STRT|STR|STREETS|STS|#@#|SUMMIT|SMT|SUMIT|SUMITT|SUMMIT|#@#|TERRACE|TER|TERR|#@#|THROUGHWAY|TRWY|#@#|TRACE|TRCE|TRACES|TRCE|#@#|TRACK|TRAK|TRACKS|TRAK|TRK|TRKS|#@#|TRAFFICWAY|TRFY|#@#|TRAIL|TRL|TRAILS|TRL|TRLS|#@#|TRAILER|TRLR|TRLRS|#@#|TUNNEL|TUNL|TUNLS|TUNNELS|TUNNL|#@#|TURNPIKE|TRNPK|TPKE|TURNPK|#@#|UNDERPASS|UPAS|#@#|UNION|UN|UNIONS|UNS|#@#|VALLEY|VLY|VALLY|VLLY|VLY|VALLEYS|VLYS|#@#|VIADUCT|VDCT|#VIA#|VIADCT|#@#|VIEW|VW|VIEWS|VWS|#@#|VILLAGE|VILL|VLG|VILLG|VILLIAGE|VILLAGES|VLGS|#@#|VILLE|VL|#@#|VISTA|VIS|VIST|VST|VSTA|#@#|#WALK#|#WALKS#|#@#|#WALL#|#@#|#WAY#|WY|#WAYS#|#@#|#WELL#|WL|WELLS|WLS|#@#)\\\\.?\\\\b\"\n",
    "\n",
    "# ------ Create filter 4: with key words of tweets about political -------#\n",
    "rgx_f4 = \"\\\\b(realDonaldTrump|Trump|DonaldTrump|BarackObama|Obama|Election|Election2016|vote|republicans|republican|democrats|democrat|GOP|dems|immigrant|immigrants|climate\\\\s?change|gas\\\\s?prices|ICE|buzzfeed(news)?|tedcruz|SenTedCruz)\\\\b\"\n",
    "# all tweets about ICE and buzzfeed are polical ones\n",
    "\n",
    "# ------ Create filter 5: with key words of tweets about offering helps -------#\n",
    "rgx_f5 = \"\\\\b(donate|donating|donated|donations|Charity|Charities|church|shelters?|sheltering|(we|I)\\\\s+can\\\\s+help|open\\\\s+for\\\\s+helps?|drop\\\\s+off|HELP\\\\sthe\\\\s#?AmericanRedCross)\\\\b\"\n",
    "\n",
    "# ------ Create filter 6: with key words of tweets about commercial -------#\n",
    "rgx_f6 = \"\\\\$\\\\d+(.\\\\d{0,2})?|\\\\$\\\\$+|\\\\b(sales|for\\\\ssale|dollors|hundreds?|thousands?|millions?|billions?|trillions?|[A-z]*market)\\\\b\"\n",
    "# 2 regex, one  for market; one for open;\n",
    "\n",
    "\n",
    "# ------ Create filter 7: with key words of tweets of newsreport -------#\n",
    "rgx_f7 = \"#BREAKING:\\\\s+|\\\\b(Press\\\\sConference|Live\\\\svideo\\\\sfeed|Live\\\\sStream|County\\\\sUpdate:|National\\\\s+Hurricane\\\\s+Center|Tropical\\\\s+Storm\\\\s+Harvey|MANDATORY\\\\s+EVACUATION|After\\\\s+Hurricane\\\\s+Harvey|Ahead\\\\s+of\\\\s+Hurricane\\\\s+Harvey|like\\\\s+a\\\\s+river|6\\\\s+mil\\\\s+people|High\\\\s+call\\\\s+volume|Epic\\\\s+flooding|cameras?|webcam|\\\\bFM\\\\s+\\\\d+|News\\\\s+in\\\\s+the\\\\s+#?DMV)\\\\b\"\n",
    "# SOS tweet not likely use \"Tropical Storm Harvey\" or \"National Hurricane Center\"\n",
    "# typically used by news\n",
    "\n",
    "\n",
    "# ------ Create filter 8: rescue status update --------------#\n",
    "rgx_f8 = \"-\\\\sAwaiting\\\\sUpdates?\\\\b|-\\\\sRescued!\\\\s|\\\\b(Ha(ve|s)\\\\sBeen\\\\sRescued)\\\\b\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### Training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>non_cleaned_text</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>If you want to figure out the road situation i...</td>\n",
       "      <td>want figure road situation area check harveyfl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Wall Street Journal: Houston flooding expe...</td>\n",
       "      <td>wall street journal houston flooding expected ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@cinnamonfire8 oh and that white oak and houst...</td>\n",
       "      <td>cinnamonfire8 oh white oak houston ave floodin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Guys, I'm south of the Conroe dam. Where is ev...</td>\n",
       "      <td>guys im south conroe dam everyone evacuating g...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12:43pm.. flooding in Breaux Bridge (St. Marti...</td>\n",
       "      <td>1243pm flooding breaux bridge st martin parish...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4934</th>\n",
       "      <td>please help my friend in a wheelchair flooded ...</td>\n",
       "      <td>please help friend wheelchair flooded home plz...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4935</th>\n",
       "      <td>@HCSOTexas @HoustonPolice Elderly couple await...</td>\n",
       "      <td>hcsotexas houstonpolice elderly couple awaitin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4936</th>\n",
       "      <td>Life threatening situation!!!  9231 Oak knoll ...</td>\n",
       "      <td>life threatening situation 9231 oak knoll rd h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4937</th>\n",
       "      <td>@TrillChino09 A family of 6 adults and 4 kids ...</td>\n",
       "      <td>trillchino09 family 6 adults 4 kids need boat ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4938</th>\n",
       "      <td>@RedCross @USNationalGuard @USCG #CajunNavy 34...</td>\n",
       "      <td>redcross usnationalguard uscg cajunnavy 3406 o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4939 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       non_cleaned_text  \\\n",
       "0     If you want to figure out the road situation i...   \n",
       "1     The Wall Street Journal: Houston flooding expe...   \n",
       "2     @cinnamonfire8 oh and that white oak and houst...   \n",
       "3     Guys, I'm south of the Conroe dam. Where is ev...   \n",
       "4     12:43pm.. flooding in Breaux Bridge (St. Marti...   \n",
       "...                                                 ...   \n",
       "4934  please help my friend in a wheelchair flooded ...   \n",
       "4935  @HCSOTexas @HoustonPolice Elderly couple await...   \n",
       "4936  Life threatening situation!!!  9231 Oak knoll ...   \n",
       "4937  @TrillChino09 A family of 6 adults and 4 kids ...   \n",
       "4938  @RedCross @USNationalGuard @USCG #CajunNavy 34...   \n",
       "\n",
       "                                                   text  label  \n",
       "0     want figure road situation area check harveyfl...      0  \n",
       "1     wall street journal houston flooding expected ...      0  \n",
       "2     cinnamonfire8 oh white oak houston ave floodin...      0  \n",
       "3     guys im south conroe dam everyone evacuating g...      0  \n",
       "4     1243pm flooding breaux bridge st martin parish...      0  \n",
       "...                                                 ...    ...  \n",
       "4934  please help friend wheelchair flooded home plz...      1  \n",
       "4935  hcsotexas houstonpolice elderly couple awaitin...      1  \n",
       "4936  life threatening situation 9231 oak knoll rd h...      1  \n",
       "4937  trillchino09 family 6 adults 4 kids need boat ...      1  \n",
       "4938  redcross usnationalguard uscg cajunnavy 3406 o...      1  \n",
       "\n",
       "[4939 rows x 3 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>non_cleaned_text</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1094</th>\n",
       "      <td>Photos of flooding at Villas Dr./Golden Beach ...</td>\n",
       "      <td>photos flooding villas drgolden beach sent us ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1762</th>\n",
       "      <td>Hurricane Harvey videos | Fort Worth Star-Tele...</td>\n",
       "      <td>hurricane harvey videos fort worth startelegra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2034</th>\n",
       "      <td>11830 Greenspark Ln. - Awaiting Update. #Houst...</td>\n",
       "      <td>11830 greenspark ln awaiting update houston ha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2951</th>\n",
       "      <td>@ManBoobiees @LukeBryanSucks @klstorey Oh and ...</td>\n",
       "      <td>manboobiees lukebryansucks klstorey oh also ho...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5520</th>\n",
       "      <td>Guys, this storm is no joke ðŸ˜³#HurricaneHarvey ...</td>\n",
       "      <td>guys storm joke ðŸ˜³hurricaneharvey fl side effec...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4914</th>\n",
       "      <td>@jackmcme @matthaig1 Indeed, and sometimes dro...</td>\n",
       "      <td>jackmcme matthaig1 indeed sometimes drought fo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4737</th>\n",
       "      <td>My family is #blessed to have spent #Hurricane...</td>\n",
       "      <td>family blessed spent hurricaneharvey south for...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5435</th>\n",
       "      <td>HARVEY UPDATE: Williamson County officials mon...</td>\n",
       "      <td>harvey update williamson county officials moni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3007</th>\n",
       "      <td>Please continue to keep Houston in your though...</td>\n",
       "      <td>please continue keep houston thoughts amp pray...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>Houston, Texas freeway sign nearly submerged a...</td>\n",
       "      <td>houston texas freeway sign nearly submerged am...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1738 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       non_cleaned_text  \\\n",
       "1094  Photos of flooding at Villas Dr./Golden Beach ...   \n",
       "1762  Hurricane Harvey videos | Fort Worth Star-Tele...   \n",
       "2034  11830 Greenspark Ln. - Awaiting Update. #Houst...   \n",
       "2951  @ManBoobiees @LukeBryanSucks @klstorey Oh and ...   \n",
       "5520  Guys, this storm is no joke ðŸ˜³#HurricaneHarvey ...   \n",
       "...                                                 ...   \n",
       "4914  @jackmcme @matthaig1 Indeed, and sometimes dro...   \n",
       "4737  My family is #blessed to have spent #Hurricane...   \n",
       "5435  HARVEY UPDATE: Williamson County officials mon...   \n",
       "3007  Please continue to keep Houston in your though...   \n",
       "1258  Houston, Texas freeway sign nearly submerged a...   \n",
       "\n",
       "                                                   text  label  \n",
       "1094  photos flooding villas drgolden beach sent us ...      0  \n",
       "1762  hurricane harvey videos fort worth startelegra...      0  \n",
       "2034  11830 greenspark ln awaiting update houston ha...      0  \n",
       "2951  manboobiees lukebryansucks klstorey oh also ho...      0  \n",
       "5520  guys storm joke ðŸ˜³hurricaneharvey fl side effec...      0  \n",
       "...                                                 ...    ...  \n",
       "4914  jackmcme matthaig1 indeed sometimes drought fo...      0  \n",
       "4737  family blessed spent hurricaneharvey south for...      0  \n",
       "5435  harvey update williamson county officials moni...      0  \n",
       "3007  please continue keep houston thoughts amp pray...      0  \n",
       "1258  houston texas freeway sign nearly submerged am...      0  \n",
       "\n",
       "[1738 rows x 3 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_integrated = Train_X['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_integrated_non_cleaned = Train_X['non_cleaned_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_integrated = Test_X['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_integrated_non_cleaned = Test_X['non_cleaned_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Logical features calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logical_evaluation_address(x,y):\n",
    "    if x == 1:\n",
    "        if y == 0:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def logical_evaluation_final(x,y):\n",
    "    if x == 1:\n",
    "        if y == 0:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "train_logical_features = []\n",
    "for v1,v2 in zip(train_data_integrated.items(),train_data_integrated_non_cleaned.items()):    \n",
    "    if re.findall(rgx_f1_1,v1[1],re.IGNORECASE):\n",
    "        f1_1 =1\n",
    "    else:\n",
    "        f1_1=0\n",
    "        \n",
    "    if re.findall(rgx_f1_2,v1[1],re.IGNORECASE):\n",
    "        f1_2=1\n",
    "    else:\n",
    "        f1_2=0\n",
    "        \n",
    "    if extract_hash_tags(v2[1],ls_crisis_hashtags) == True:\n",
    "        f1_4 =1\n",
    "    else: \n",
    "        f1_4=0       \n",
    "        \n",
    "    if re.findall(rgx_f2,v1[1],re.IGNORECASE):\n",
    "        f2=1\n",
    "    else:\n",
    "        f2=0\n",
    "    \n",
    "    if re.findall(address_pattern,v1[1],re.IGNORECASE):\n",
    "        f3_1=1\n",
    "    else:\n",
    "        f3_1=0\n",
    "        \n",
    "    if re.findall(non_address_pattern,v1[1],re.IGNORECASE):\n",
    "        f3_2=1\n",
    "    else:\n",
    "        f3_2=0        \n",
    "        \n",
    "    if re.findall(rgx_f4,v1[1],re.IGNORECASE):\n",
    "        f4=1\n",
    "    else:\n",
    "        f4=0\n",
    "    \n",
    "    if re.findall(rgx_f5,v1[1],re.IGNORECASE):\n",
    "        f5=1\n",
    "    else:\n",
    "        f5=0\n",
    "    \n",
    "    if re.findall(rgx_f6,v1[1],re.IGNORECASE):\n",
    "        f6=1\n",
    "    else:\n",
    "        f6=0\n",
    "    \n",
    "    if re.findall(rgx_f7,v1[1],re.IGNORECASE):\n",
    "        f7=1\n",
    "    else:\n",
    "        f7=0\n",
    "     \n",
    "    if re.findall(rgx_f8,v1[1],re.IGNORECASE):\n",
    "        f8=1\n",
    "    else:\n",
    "        f8=0\n",
    "    \n",
    "    ## create a feature vector for training set ###\n",
    "    train_logical_features.append([f1_1,f1_2,f1_4,f2,f3_1,f3_2,f4,f5,f6,f7,f8])\n",
    "        \n",
    "test_logical_features = []\n",
    "for v1,v2 in zip(test_data_integrated.items(),test_data_integrated_non_cleaned.items()):      \n",
    "    \n",
    "    if re.findall(rgx_f1_1,v1[1],re.IGNORECASE):\n",
    "        f1_1 =1\n",
    "    else:\n",
    "        f1_1=0\n",
    "        \n",
    "    if re.findall(rgx_f1_2,v1[1],re.IGNORECASE):\n",
    "        f1_2=1\n",
    "    else:\n",
    "        f1_2=0\n",
    "        \n",
    "    if extract_hash_tags(v2[1],ls_crisis_hashtags) == True:\n",
    "        f1_4 =1\n",
    "    else: \n",
    "        f1_4=0     \n",
    "        \n",
    "        \n",
    "    if re.findall(rgx_f2,v1[1],re.IGNORECASE):\n",
    "        f2=1\n",
    "    else:\n",
    "        f2=0\n",
    "    \n",
    "    if re.findall(address_pattern,v1[1],re.IGNORECASE):\n",
    "        f3_1=1\n",
    "    else:\n",
    "        f3_1=0\n",
    "        \n",
    "    if re.findall(non_address_pattern,v1[1],re.IGNORECASE):\n",
    "        f3_2=1\n",
    "    else:\n",
    "        f3_2=0        \n",
    "        \n",
    "    if re.findall(rgx_f4,v1[1],re.IGNORECASE):\n",
    "        f4=1\n",
    "    else:\n",
    "        f4=0\n",
    "    \n",
    "    if re.findall(rgx_f5,v1[1],re.IGNORECASE):\n",
    "        f5=1\n",
    "    else:\n",
    "        f5=0\n",
    "    \n",
    "    if re.findall(rgx_f6,v1[1],re.IGNORECASE):\n",
    "        f6=1\n",
    "    else:\n",
    "        f6=0\n",
    "    \n",
    "    if re.findall(rgx_f7,v1[1],re.IGNORECASE):\n",
    "        f7=1\n",
    "    else:\n",
    "        f7=0\n",
    "     \n",
    "    if re.findall(rgx_f8,v1[1],re.IGNORECASE):\n",
    "        f8=1\n",
    "    else:\n",
    "        f8=0\n",
    "    \n",
    "    ## create test feature vector ###\n",
    "    test_logical_features.append([f1_1,f1_2,f1_4,f2,f3_1,f3_2,f4,f5,f6,f7,f8])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length logical train features... 4939\n",
      "Length logical test features... 1738\n",
      "Length logical vector (train)... 11\n",
      "Length logical vector (test)... 11\n"
     ]
    }
   ],
   "source": [
    "###### calculate logical feature vectors #########\n",
    "print('Length logical train features...',len(train_logical_features))\n",
    "print('Length logical test features...',len(test_logical_features))\n",
    "print('Length logical vector (train)...',len(train_logical_features[0]))\n",
    "print('Length logical vector (test)...',len(test_logical_features[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### Bert architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## BERT model architecture #####\n",
    "class BERT_Arch(nn.Module):\n",
    "\n",
    "    def __init__(self, bert, layers = None):\n",
    "      \n",
    "        super(BERT_Arch, self).__init__()\n",
    "\n",
    "        self.bert = bert \n",
    "      \n",
    "        # dropout layer\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "      \n",
    "        # relu activation function\n",
    "        self.relu =  nn.ReLU()\n",
    "    \n",
    "        # add the output layers here\n",
    "        if layers ==1:    ##### change  base: 768       large: 1024\n",
    "            # dense layer 1\n",
    "            self.fc1 = nn.Linear(768,2)\n",
    "        \n",
    "        if layers == 2:\n",
    "            # dense layer 1\n",
    "            self.fc1 = nn.Linear(768,512)\n",
    "            # dense layer 2 (Output layer)\n",
    "            self.fc2 = nn.Linear(512,2)\n",
    "        \n",
    "        if layers == 3: \n",
    "            # dense layer 1\n",
    "            self.fc1 = nn.Linear(768,1024)   ##### change \n",
    "            #dense layer 3\n",
    "            self.fc2 = nn.Linear(1024,32)\n",
    "            # dense layer 2 (Output layer)\n",
    "            self.fc3 = nn.Linear(32,2)        \n",
    "        \n",
    "        \n",
    "        if layers == 4: \n",
    "            self.fc1 = nn.Linear(768,1024)   ##### change \n",
    "            self.fc2 = nn.Linear(1024,256)\n",
    "            self.fc3 = nn.Linear(256,32)\n",
    "            self.fc4 = nn.Linear(32,2)\n",
    "\n",
    "        if layers == 5: \n",
    "            self.fc1 = nn.Linear(768,1024)   ##### change \n",
    "            self.fc3 = nn.Linear(1024,512)\n",
    "            self.fc4 = nn.Linear(512,256)\n",
    "            self.fc5 = nn.Linear(256,32)\n",
    "            # dense layer 2 (Output layer)\n",
    "            self.fc2 = nn.Linear(32,2)\n",
    "\n",
    "        #softmax activation function\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    #define the forward pass\n",
    "    def forward(self, sent_id, mask,layers = 2):\n",
    "\n",
    "        #pass the inputs to the model  \n",
    "        _, cls_hs = self.bert(sent_id, attention_mask=mask,return_dict=False)\n",
    "      \n",
    "        x = self.fc1(cls_hs)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "      \n",
    "        if layers == 2:\n",
    "            x = self.fc2(x)\n",
    "        \n",
    "        if layers == 3: \n",
    "            x = self.fc2(x)\n",
    "            x = self.fc3(x)\n",
    "        \n",
    "        if layers == 4: \n",
    "            x = self.fc2(x)\n",
    "            x = self.fc3(x)\n",
    "            x = self.fc4(x)\n",
    "            \n",
    "        if layers == 5: \n",
    "            x = self.fc2(x)\n",
    "            x = self.fc3(x)\n",
    "            x = self.fc4(x)\n",
    "            x = self.fc5(x)\n",
    "            \n",
    "        \n",
    "        # apply softmax activation\n",
    "        x = self.softmax(x)\n",
    "\n",
    "        return x  \n",
    "    \n",
    "    \n",
    "# function to train the model\n",
    "def train():\n",
    "      \n",
    "    model.train()\n",
    "\n",
    "    total_loss, total_accuracy = 0, 0\n",
    "  \n",
    "    # empty list to save model predictions\n",
    "    total_preds=[]\n",
    "  \n",
    "    # iterate over batches\n",
    "    for step,batch in enumerate(train_dataloader):\n",
    "    \n",
    "        # progress update after every 50 batches.\n",
    "        if step % 50 == 0 and not step == 0:\n",
    "              print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
    "\n",
    "        # push the batch to gpu\n",
    "        batch = [r.to(device) for r in batch]\n",
    " \n",
    "        sent_id, mask, labels = batch\n",
    "\n",
    "        # clear previously calculated gradients \n",
    "        model.zero_grad()        \n",
    "\n",
    "        # get model predictions for the current batch\n",
    "        preds = model(sent_id, mask,nb_layers)\n",
    "\n",
    "        # compute the loss between actual and predicted values\n",
    "        loss = cross_entropy(preds, labels)\n",
    "\n",
    "        # add on to the total loss\n",
    "        total_loss = total_loss + loss.item()\n",
    "\n",
    "        # backward pass to calculate the gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # model predictions are stored on GPU. So, push it to CPU\n",
    "        preds=preds.detach().cpu().numpy()\n",
    "\n",
    "        # append the model predictions\n",
    "        total_preds.append(preds)\n",
    "\n",
    "        # compute the training loss of the epoch\n",
    "        avg_loss = total_loss / len(train_dataloader)\n",
    "  \n",
    "    # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
    "    # reshape the predictions in form of (number of samples, no. of classes)\n",
    "    total_preds  = np.concatenate(total_preds, axis=0)\n",
    "\n",
    "    #returns the loss and predictions\n",
    "    return avg_loss, total_preds\n",
    "\n",
    "# function for evaluating the model\n",
    "def evaluate():\n",
    "  \n",
    "    print(\"\\nEvaluating...\")\n",
    "  \n",
    "    # deactivate dropout layers\n",
    "    model.eval()\n",
    "    total_loss, total_accuracy = 0, 0\n",
    "  \n",
    "    # empty list to save the model predictions\n",
    "    total_preds = []\n",
    "\n",
    "    # iterate over batches\n",
    "    for step,batch in enumerate(val_dataloader):\n",
    "    \n",
    "        # Progress update every 50 batches.\n",
    "        if step % 50 == 0 and not step == 0:\n",
    "      \n",
    "            # Calculate elapsed time in minutes.\n",
    "            #elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
    "\n",
    "        # push the batch to gpu\n",
    "        batch = [t.to(device) for t in batch]\n",
    "\n",
    "        sent_id, mask, labels = batch\n",
    "\n",
    "        # deactivate autograd\n",
    "        with torch.no_grad(): \n",
    "            # model predictions\n",
    "            preds = model(sent_id, mask,nb_layers)\n",
    "\n",
    "            # compute the validation loss between actual and predicted values\n",
    "            loss = cross_entropy(preds,labels)\n",
    "\n",
    "            total_loss = total_loss + loss.item()\n",
    "\n",
    "            preds = preds.detach().cpu().numpy()\n",
    "\n",
    "            total_preds.append(preds)\n",
    "\n",
    "    # compute the validation loss of the epoch\n",
    "    avg_loss = total_loss / len(val_dataloader) \n",
    "\n",
    "    # reshape the predictions in form of (number of samples, no. of classes)\n",
    "    total_preds  = np.concatenate(total_preds, axis=0)\n",
    "\n",
    "    return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import BERT-base pretrained model\n",
    "bert = AutoModel.from_pretrained('bert-base-uncased')                #bert-base-uncased\n",
    "\n",
    "# Load the BERT tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')   #bert-base-uncased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_layers = 1\n",
    "\n",
    "# freeze all the parameters\n",
    "for param in bert.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# pass the pre-trained BERT to our define architecture\n",
    "model = BERT_Arch(bert,nb_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BERT_Arch(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (relu): ReLU()\n",
       "  (fc1): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (softmax): LogSoftmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"/home/wkhal001/Crisis-classification/scripts-rescue-detection/__comparison_new_experimental_design/Fine_tuned_bert/saved_weights_bert_7.pt\"))\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### Calculate input features from BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "%matplotlib inline\n",
    "\n",
    "# parameter 1\n",
    "max_seq_len = 36   ######### parameter 1 ###################\n",
    "\n",
    "# tokenize and encode sequences in the training set\n",
    "tokens_train = tokenizer.batch_encode_plus(\n",
    "            Train_X['text'].tolist(),\n",
    "            padding='max_length',\n",
    "            max_length = max_seq_len,\n",
    "            truncation=True,\n",
    "            return_token_type_ids=False\n",
    "        )\n",
    "\n",
    "# tokenize and encode sequences in the validation set\n",
    "tokens_test = tokenizer.batch_encode_plus(\n",
    "        Test_X['text'].tolist(),\n",
    "        padding='max_length',\n",
    "        max_length = max_seq_len,\n",
    "        truncation=True,\n",
    "        return_token_type_ids=False\n",
    "    )                                                                \n",
    "\n",
    "# for train set\n",
    "train_seq = torch.tensor(tokens_train['input_ids'])\n",
    "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
    "train_y = torch.tensor(Train_Y.tolist())\n",
    "\n",
    "# for test set\n",
    "test_seq = torch.tensor(tokens_test['input_ids'])\n",
    "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
    "test_y = torch.tensor(Test_Y.tolist())\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model.bert(train_seq,train_mask)\n",
    "    \n",
    "with torch.no_grad():\n",
    "    outputs_test = model.bert(test_seq,test_mask)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4939, 768])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### convert train and test data tensors into numpy array\n",
    "ls_input_train = [e.numpy() for e in outputs[1]]\n",
    "ls_input_test = [e.numpy() for e in outputs_test[1]]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length training data (bert) 4939\n",
      "Length testing data (bert) 1738\n",
      "Length training vectors (bert) 768\n",
      "Length testing vectors (bert) 768\n"
     ]
    }
   ],
   "source": [
    "print('Length training data (bert)',len(ls_input_train))\n",
    "print('Length testing data (bert)',len(ls_input_test))\n",
    "print('Length training vectors (bert)',len(ls_input_train[0]))\n",
    "print('Length testing vectors (bert)',len(ls_input_test[0]))\n",
    "\n",
    "# print('Length training data (logical variant 2)',len(Logical_train_new))\n",
    "# print('Length training vector (logical variant 2)',len(Logical_train_new[0]))\n",
    "# print('Length testing data (logical variant 2)',len(Logical_test_new))\n",
    "# print('Length testing vector (logical variant 2)',len(Logical_test_new[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### Build integrated model using SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers.merge import concatenate\n",
    "\n",
    "#### create Keras neural network with both inputs ###\n",
    "input_bert = Input(shape=(768,))\n",
    "input_logical = Input(shape=(11,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length input BERT.... 768\n",
      "Length input Logical.... 11\n",
      "Total samples training input BERT.... 4054\n",
      "Total samples training input Logical.... 4054\n"
     ]
    }
   ],
   "source": [
    "print('Length input BERT....',len(ls_input_train[0]))\n",
    "print('Length input Logical....',len(train_logical_features[0]))\n",
    "\n",
    "print('Total samples training input BERT....',len(ls_input_train))\n",
    "print('Total samples training input Logical....',len(train_logical_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### create training BERT/SVM data set ###########\n",
    "SVM_training = []\n",
    "for e1,e2 in zip(ls_input_train,train_logical_features): \n",
    "    SVM_training.append(np.concatenate([e1,e2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "779"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(SVM_training[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_testing = []\n",
    "for e1,e2 in zip(ls_input_test,test_logical_features): \n",
    "    SVM_testing.append(np.concatenate([e1,e2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "779"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(SVM_testing[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "F1 score... 0.8961038961038961\n",
      "Recall... 0.9078947368421053\n",
      "Precision... 0.8846153846153846\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "### train the classifier #######\n",
    "SVM = SVC(C=15, kernel='rbf',degree=2 ,gamma=0.001)  \n",
    "SVM.fit(SVM_training,Train_Y)\n",
    "\n",
    "## test the classifier #######\n",
    "preds = SVM.predict(SVM_testing)\n",
    "\n",
    "##### plot results #######\n",
    "dict_r = classification_report(Test_Y, preds,output_dict = True)\n",
    "print('-------------------------------------------')\n",
    "print('F1 score...',dict_r['1']['f1-score'])\n",
    "print('Recall...',dict_r['1']['recall'])\n",
    "print('Precision...',dict_r['1']['precision'])\n",
    "print('-------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "F1 score... 0.8961038961038961\n",
      "Recall... 0.9078947368421053\n",
      "Precision... 0.8846153846153846\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "### train the classifier #######\n",
    "SVM = SVC(C=15, kernel='rbf',degree=2 ,gamma=0.001)  \n",
    "SVM.fit(ls_input_train,Train_Y)\n",
    "\n",
    "## test the classifier #######\n",
    "preds = SVM.predict(ls_input_test)\n",
    "\n",
    "##### plot results #######\n",
    "dict_r = classification_report(Test_Y, preds,output_dict = True)\n",
    "print('-------------------------------------------')\n",
    "print('F1 score...',dict_r['1']['f1-score'])\n",
    "print('Recall...',dict_r['1']['recall'])\n",
    "print('Precision...',dict_r['1']['precision'])\n",
    "print('-------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "F1 score... 0.29213483146067415\n",
      "Recall... 0.17105263157894737\n",
      "Precision... 1.0\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "### train the classifier #######\n",
    "SVM = SVC(C=15, kernel='rbf',degree=2 ,gamma=0.001)  \n",
    "SVM.fit(train_logical_features,Train_Y)\n",
    "\n",
    "## test the classifier #######\n",
    "preds = SVM.predict(test_logical_features)\n",
    "\n",
    "##### plot results #######\n",
    "dict_r = classification_report(Test_Y, preds,output_dict = True)\n",
    "print('-------------------------------------------')\n",
    "print('F1 score...',dict_r['1']['f1-score'])\n",
    "print('Recall...',dict_r['1']['recall'])\n",
    "print('Precision...',dict_r['1']['precision'])\n",
    "print('-------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Build integrated model (expanded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, I resized the logical vector by copying each bit 5 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers.merge import concatenate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_list(l=[]):\n",
    "    l2 = [[i]*5 for i in l]\n",
    "    l3 = []\n",
    "    for j in l2:\n",
    "        l3 = l3 + j\n",
    "    return(l3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_logical_features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_logical_loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_logical_features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "############ Tranform logical vector ###########\n",
    "################################################\n",
    "expanded_train_logical = []\n",
    "for e in train_logical_features: #logical_train_loc #train_logical_features #train_logical_loc\n",
    "    expanded_e = expand_list(e)\n",
    "    expanded_train_logical.append(expanded_e)   \n",
    "    \n",
    "#train_logical_loc\n",
    "#test_logical_loc  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "############ Transform testing logical vector ###########\n",
    "########################################################## \n",
    "expanded_test_logical = []\n",
    "for e in test_logical_features: #logical_test_loc   #test_logical_features\n",
    "    expanded_e = expand_list(e)\n",
    "    expanded_test_logical.append(expanded_e)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(expanded_train_logical[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(expanded_test_logical[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hybrid model: BERT output + resized logical (in Keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "#### create Keras neural network with both inputs ###\n",
    "input_bert = Input(shape=(768,))\n",
    "input_logical = Input(shape=(60,)) #55\n",
    "\n",
    "def create_hybrid_model(): \n",
    "    # the first branch operates on the first input\n",
    "    x = Dense(256, activation=\"relu\")(input_bert)\n",
    "    x = Dense(64, activation=\"relu\")(x)\n",
    "    x = Model(inputs=input_bert, outputs=x)\n",
    "    \n",
    "    # # the second branch opreates on the second input\n",
    "    #y = Dense(32, activation=\"relu\")(input_logical)\n",
    "    #y = Dense(5, activation=\"relu\")(y)\n",
    "    #y = Model(inputs=input_logical, outputs=y)\n",
    "\n",
    "    # combine the output of the two branches\n",
    "    combined = concatenate([x.output, input_logical]) ##y.output\n",
    "\n",
    "    # apply a FC layer and then a regression prediction on the\n",
    "    # combined outputs\n",
    "    z1 = Dense(100, activation=\"softmax\")(combined) #,kernel_regularizer=regularizers.L2(l2=1e-4)\n",
    "    z1 = Dense(64, activation=\"softmax\")(z1)\n",
    "    z1 = Dense(32, activation=\"softmax\")(z1)\n",
    "    z = Dense(2, activation=\"softmax\")(z1)\n",
    "\n",
    "    # our model will accept the inputs of the two branches and then output a single value\n",
    "    model = Model(inputs=[x.input,input_logical], outputs=z) ##y.input\n",
    "    \n",
    "    return(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 768)]        0           []                               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 256)          196864      ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 64)           16448       ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 60)]         0           []                               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 124)          0           ['dense_1[0][0]',                \n",
      "                                                                  'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 100)          12500       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 64)           6464        ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 32)           2080        ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 2)            66          ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 234,422\n",
      "Trainable params: 234,422\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1 =create_hybrid_model()\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dot_img_file = '/home/wkhal001/Crisis-classification/scripts-rescue-detection/__comparison_new_experimental_design/Integrated_model_test/Plot_integrated.png'\n",
    "#tf.keras.utils.plot_model(model1, to_file=dot_img_file, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "%matplotlib inline\n",
    "\n",
    "########## run the model multiple times #########\n",
    "nb_reps = 10\n",
    "save_results = {'f1':[],'recall':[],'precision':[]}\n",
    "base_path_img = ''\n",
    "\n",
    "base_path_img = '/home/wkhal001/Crisis-classification/scripts-rescue-detection/__comparison_new_experimental_design/Integrated_model_test/Run_regularizer/'\n",
    "\n",
    "iteration = 1\n",
    "for i in range(nb_reps): \n",
    "    print('------------- iteration ',str(iteration),'----------------------')\n",
    "    model =create_hybrid_model()\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(0.001),\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(), #BinaryCrossentropy(), SparseCategoricalCrossentropy() #keras.losses.SparseCategoricalCrossentropy()\n",
    "        metrics=[keras.metrics.SparseCategoricalCrossentropy()], #keras.metrics.SparseCategoricalAccuracy()\n",
    "    )\n",
    "    \n",
    "    Train_hybrid_bert = np.array(ls_input_train)\n",
    "    Train_hybrid_logical = np.array(expanded_train_logical)\n",
    "    Train_hybrid_Y = np.array(Train_Y)\n",
    "\n",
    "    history = model.fit(x=[Train_hybrid_bert,Train_hybrid_logical], y=Train_hybrid_Y, batch_size=16, epochs=100,verbose=0) \n",
    "    \n",
    "    Test_hybrid_bert = np.array(ls_input_test)\n",
    "    Test_hybrid_logical = np.array(expanded_test_logical)\n",
    "    Test_hybrid_Y = np.array(Test_Y)\n",
    "\n",
    "    predictions = model.predict([Test_hybrid_bert,Test_hybrid_logical])\n",
    "    preds = np.argmax(predictions, axis=1)\n",
    "    dict_r = classification_report(Test_Y, preds, output_dict = True)\n",
    "    print(dict_r)\n",
    "\n",
    "    f1 = f1_score(Test_hybrid_Y, preds, average='binary')    \n",
    "    print('F1 score (class 1)....',f1)\n",
    "    \n",
    "    save_results['f1'].append(dict_r['1']['f1-score'])\n",
    "    save_results['recall'].append(dict_r['1']['recall']) \n",
    "    save_results['precision'].append(dict_r['1']['precision'])\n",
    "\n",
    "    cm = confusion_matrix(Test_Y, preds, labels=np.unique(Test_Y))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=np.unique(Test_Y))\n",
    "    img_path = base_path_img + 'confusion_matrix_re' + str(iteration) + '.png'\n",
    "    iteration = iteration + 1\n",
    "    \n",
    "    #disp.figure_.savefig(img_path)\n",
    "    disp.plot()\n",
    "    plt.savefig(img_path)\n",
    "    \n",
    "    print('------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8903225806451613,\n",
       " 0.9019607843137255,\n",
       " 0.8834355828220859,\n",
       " 0.8947368421052632,\n",
       " 0.8834355828220859,\n",
       " 0.8961038961038961,\n",
       " 0.8961038961038961,\n",
       " 0.8903225806451613,\n",
       " 0.9019607843137255,\n",
       " 0.8903225806451613]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_results['f1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9078947368421053,\n",
       " 0.9078947368421053,\n",
       " 0.9473684210526315,\n",
       " 0.8947368421052632,\n",
       " 0.9473684210526315,\n",
       " 0.9078947368421053,\n",
       " 0.9078947368421053,\n",
       " 0.9078947368421053,\n",
       " 0.9078947368421053,\n",
       " 0.9078947368421053]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_results['recall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8734177215189873,\n",
       " 0.8961038961038961,\n",
       " 0.8275862068965517,\n",
       " 0.8947368421052632,\n",
       " 0.8275862068965517,\n",
       " 0.8846153846153846,\n",
       " 0.8846153846153846,\n",
       " 0.8734177215189873,\n",
       " 0.8961038961038961,\n",
       " 0.8734177215189873]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_results['precision']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "#create a binary pickle file \n",
    "f = open(\"/home/wkhal001/Crisis-classification/scripts-rescue-detection/__comparison_new_experimental_design/Integrated_model_test/Run_NER/results_ner_variant2.pkl\",\"wb\")\n",
    "pickle.dump(save_results,f)\n",
    "f.close()\n",
    "\n",
    "# # open a file, where you stored the pickled data\n",
    "# file = open(\"/home/wkhal001/Crisis-classification/scripts-rescue-detection/__comparison_new_experimental_design/Integrated_model_test/Run_NER/Testing_runs_results_ner_variant2.pkl\", 'rb')\n",
    "\n",
    "# # # dump information to that file\n",
    "# save_results = pickle.load(file)\n",
    "\n",
    "# # # close the file\n",
    "# file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of runs.... 10\n",
      "------------- F1 scores --------------------\n",
      "average (10 runs)  0.8928705110520162\n",
      "stdev (10 runs)  0.006558882652261629\n",
      "max (10 runs)  0.9019607843137255\n",
      "min (10 runs)  0.8834355828220859\n",
      "------------- recall scores --------------------\n",
      "average (10 runs)  0.9144736842105263\n",
      "stdev (10 runs)  0.01781587369437707\n",
      "max (10 runs)  0.9473684210526315\n",
      "min (10 runs)  0.8947368421052632\n",
      "------------- precision scores --------------------\n",
      "average (10 runs)  0.873160098189389\n",
      "stdev (10 runs)  0.025679643953443073\n",
      "max (10 runs)  0.8961038961038961\n",
      "min (10 runs)  0.8275862068965517\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "\n",
    "print('number of runs....',len(save_results['f1']))\n",
    "\n",
    "print('------------- F1 scores --------------------')\n",
    "print('average (10 runs) ',statistics.mean(save_results['f1']))\n",
    "print('stdev (10 runs) ',statistics.stdev(save_results['f1']))\n",
    "print('max (10 runs) ',max(save_results['f1']))\n",
    "print('min (10 runs) ',min(save_results['f1']))\n",
    "\n",
    "print('------------- recall scores --------------------')\n",
    "print('average (10 runs) ',statistics.mean(save_results['recall']))\n",
    "print('stdev (10 runs) ',statistics.stdev(save_results['recall']))\n",
    "print('max (10 runs) ',max(save_results['recall']))\n",
    "print('min (10 runs) ',min(save_results['recall']))\n",
    "\n",
    "\n",
    "print('------------- precision scores --------------------')\n",
    "print('average (10 runs) ',statistics.mean(save_results['precision']))\n",
    "print('stdev (10 runs) ',statistics.stdev(save_results['precision']))\n",
    "print('max (10 runs) ',max(save_results['precision']))\n",
    "print('min (10 runs) ',min(save_results['precision']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Build integrated model (location and person features are added)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers.merge import concatenate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Logical_train_new[0]\n",
    "#Logical_test_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Logical_train_new[0][11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### only add the location feature #############\n",
    "Logical_train_loc = Logical_train_new[:,0:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Expand logical features ##################\n",
    "def expand_list(l=[]):\n",
    "    l2 = [[i]*5 for i in l]\n",
    "    l3 = []\n",
    "    for j in l2:\n",
    "        l3 = l3 + j\n",
    "    return(l3)\n",
    "\n",
    "##########################################################\n",
    "############ Transform training logical vector ###########\n",
    "##########################################################\n",
    "expanded_train_logical = []\n",
    "for e in Logical_train_new:\n",
    "    expanded_e = expand_list(e)\n",
    "    expanded_train_logical.append(expanded_e) \n",
    "    \n",
    "##########################################################\n",
    "############ Transform testing logical vector ###########\n",
    "##########################################################  \n",
    "expanded_test_logical = []\n",
    "for e in Logical_test_new:\n",
    "    expanded_e = expand_list(e)\n",
    "    expanded_test_logical.append(expanded_e)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_40\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 768)]        0           []                               \n",
      "                                                                                                  \n",
      " dense_65 (Dense)               (None, 128)          98432       ['input_5[0][0]']                \n",
      "                                                                                                  \n",
      " dense_66 (Dense)               (None, 64)           8256        ['dense_65[0][0]']               \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)           [(None, 65)]         0           []                               \n",
      "                                                                                                  \n",
      " concatenate_13 (Concatenate)   (None, 129)          0           ['dense_66[0][0]',               \n",
      "                                                                  'input_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense_67 (Dense)               (None, 64)           8320        ['concatenate_13[0][0]']         \n",
      "                                                                                                  \n",
      " dense_68 (Dense)               (None, 2)            130         ['dense_67[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 115,138\n",
      "Trainable params: 115,138\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#### create Keras neural network with both inputs ###\n",
    "input_bert = Input(shape=(768,))\n",
    "input_logical = Input(shape=(65,))\n",
    "\n",
    "def create_hybrid_model_NER_2(): \n",
    "    # the first branch operates on the first input\n",
    "    x = Dense(128, activation=\"relu\")(input_bert)\n",
    "    x = Dense(64, activation=\"relu\")(x)\n",
    "    x = Model(inputs=input_bert, outputs=x)\n",
    "    \n",
    "    # # the second branch opreates on the second input\n",
    "    #y = Dense(10, activation=\"relu\")(input_logical)\n",
    "    #y = Dense(5, activation=\"relu\")(y)\n",
    "    #y = Model(inputs=input_logical, outputs=y)\n",
    "\n",
    "    # combine the output of the two branches\n",
    "    #combined = concatenate([x.output, y.output])\n",
    "    combined = concatenate([x.output,input_logical])\n",
    "\n",
    "    # apply a FC layer and then a regression prediction on the\n",
    "    # combined outputs\n",
    "    z1 = Dense(64, activation=\"softmax\")(combined)\n",
    "    z = Dense(2, activation=\"softmax\")(z1)\n",
    "\n",
    "    # our model will accept the inputs of the two branches and then output a single value\n",
    "    model = Model(inputs=[x.input,input_logical], outputs=z)\n",
    "    \n",
    "    return(model)\n",
    "\n",
    "model_ner2 =create_hybrid_model_NER_2()\n",
    "model_ner2.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------- iteration  1 ----------------------\n",
      "{'0': {'precision': 0.9957805907172996, 'recall': 0.9939831528279182, 'f1-score': 0.9948810599217104, 'support': 1662}, '1': {'precision': 0.8734177215189873, 'recall': 0.9078947368421053, 'f1-score': 0.8903225806451613, 'support': 76}, 'accuracy': 0.9902186421173763, 'macro avg': {'precision': 0.9345991561181435, 'recall': 0.9509389448350117, 'f1-score': 0.9426018202834359, 'support': 1738}, 'weighted avg': {'precision': 0.9904298553553481, 'recall': 0.9902186421173763, 'f1-score': 0.9903088824619765, 'support': 1738}}\n",
      "F1 score (class 1).... 0.8903225806451613\n",
      "------------------------------------------------------------------\n",
      "------------- iteration  2 ----------------------\n",
      "{'0': {'precision': 0.9957805907172996, 'recall': 0.9939831528279182, 'f1-score': 0.9948810599217104, 'support': 1662}, '1': {'precision': 0.8734177215189873, 'recall': 0.9078947368421053, 'f1-score': 0.8903225806451613, 'support': 76}, 'accuracy': 0.9902186421173763, 'macro avg': {'precision': 0.9345991561181435, 'recall': 0.9509389448350117, 'f1-score': 0.9426018202834359, 'support': 1738}, 'weighted avg': {'precision': 0.9904298553553481, 'recall': 0.9902186421173763, 'f1-score': 0.9903088824619765, 'support': 1738}}\n",
      "F1 score (class 1).... 0.8903225806451613\n",
      "------------------------------------------------------------------\n",
      "------------- iteration  3 ----------------------\n",
      "{'0': {'precision': 0.9957805907172996, 'recall': 0.9939831528279182, 'f1-score': 0.9948810599217104, 'support': 1662}, '1': {'precision': 0.8734177215189873, 'recall': 0.9078947368421053, 'f1-score': 0.8903225806451613, 'support': 76}, 'accuracy': 0.9902186421173763, 'macro avg': {'precision': 0.9345991561181435, 'recall': 0.9509389448350117, 'f1-score': 0.9426018202834359, 'support': 1738}, 'weighted avg': {'precision': 0.9904298553553481, 'recall': 0.9902186421173763, 'f1-score': 0.9903088824619765, 'support': 1738}}\n",
      "F1 score (class 1).... 0.8903225806451613\n",
      "------------------------------------------------------------------\n",
      "------------- iteration  4 ----------------------\n",
      "{'0': {'precision': 0.9957831325301205, 'recall': 0.9945848375451264, 'f1-score': 0.9951836243226972, 'support': 1662}, '1': {'precision': 0.8846153846153846, 'recall': 0.9078947368421053, 'f1-score': 0.8961038961038961, 'support': 76}, 'accuracy': 0.9907940161104718, 'macro avg': {'precision': 0.9401992585727525, 'recall': 0.9512397871936158, 'f1-score': 0.9456437602132967, 'support': 1738}, 'weighted avg': {'precision': 0.9909219421725142, 'recall': 0.9907940161104718, 'f1-score': 0.990851024009332, 'support': 1738}}\n",
      "F1 score (class 1).... 0.8961038961038961\n",
      "------------------------------------------------------------------\n",
      "------------- iteration  5 ----------------------\n",
      "{'0': {'precision': 0.9957805907172996, 'recall': 0.9939831528279182, 'f1-score': 0.9948810599217104, 'support': 1662}, '1': {'precision': 0.8734177215189873, 'recall': 0.9078947368421053, 'f1-score': 0.8903225806451613, 'support': 76}, 'accuracy': 0.9902186421173763, 'macro avg': {'precision': 0.9345991561181435, 'recall': 0.9509389448350117, 'f1-score': 0.9426018202834359, 'support': 1738}, 'weighted avg': {'precision': 0.9904298553553481, 'recall': 0.9902186421173763, 'f1-score': 0.9903088824619765, 'support': 1738}}\n",
      "F1 score (class 1).... 0.8903225806451613\n",
      "------------------------------------------------------------------\n",
      "------------- iteration  6 ----------------------\n",
      "{'0': {'precision': 0.9957805907172996, 'recall': 0.9939831528279182, 'f1-score': 0.9948810599217104, 'support': 1662}, '1': {'precision': 0.8734177215189873, 'recall': 0.9078947368421053, 'f1-score': 0.8903225806451613, 'support': 76}, 'accuracy': 0.9902186421173763, 'macro avg': {'precision': 0.9345991561181435, 'recall': 0.9509389448350117, 'f1-score': 0.9426018202834359, 'support': 1738}, 'weighted avg': {'precision': 0.9904298553553481, 'recall': 0.9902186421173763, 'f1-score': 0.9903088824619765, 'support': 1738}}\n",
      "F1 score (class 1).... 0.8903225806451613\n",
      "------------------------------------------------------------------\n",
      "------------- iteration  7 ----------------------\n",
      "{'0': {'precision': 0.9957805907172996, 'recall': 0.9939831528279182, 'f1-score': 0.9948810599217104, 'support': 1662}, '1': {'precision': 0.8734177215189873, 'recall': 0.9078947368421053, 'f1-score': 0.8903225806451613, 'support': 76}, 'accuracy': 0.9902186421173763, 'macro avg': {'precision': 0.9345991561181435, 'recall': 0.9509389448350117, 'f1-score': 0.9426018202834359, 'support': 1738}, 'weighted avg': {'precision': 0.9904298553553481, 'recall': 0.9902186421173763, 'f1-score': 0.9903088824619765, 'support': 1738}}\n",
      "F1 score (class 1).... 0.8903225806451613\n",
      "------------------------------------------------------------------\n",
      "------------- iteration  8 ----------------------\n",
      "{'0': {'precision': 0.9957805907172996, 'recall': 0.9939831528279182, 'f1-score': 0.9948810599217104, 'support': 1662}, '1': {'precision': 0.8734177215189873, 'recall': 0.9078947368421053, 'f1-score': 0.8903225806451613, 'support': 76}, 'accuracy': 0.9902186421173763, 'macro avg': {'precision': 0.9345991561181435, 'recall': 0.9509389448350117, 'f1-score': 0.9426018202834359, 'support': 1738}, 'weighted avg': {'precision': 0.9904298553553481, 'recall': 0.9902186421173763, 'f1-score': 0.9903088824619765, 'support': 1738}}\n",
      "F1 score (class 1).... 0.8903225806451613\n",
      "------------------------------------------------------------------\n",
      "------------- iteration  9 ----------------------\n",
      "{'0': {'precision': 0.9963811821471653, 'recall': 0.9939831528279182, 'f1-score': 0.9951807228915662, 'support': 1662}, '1': {'precision': 0.875, 'recall': 0.9210526315789473, 'f1-score': 0.8974358974358975, 'support': 76}, 'accuracy': 0.9907940161104718, 'macro avg': {'precision': 0.9356905910735827, 'recall': 0.9575178922034328, 'f1-score': 0.9463083101637318, 'support': 1738}, 'weighted avg': {'precision': 0.9910733744123065, 'recall': 0.9907940161104718, 'f1-score': 0.9909064957715255, 'support': 1738}}\n",
      "F1 score (class 1).... 0.8974358974358975\n",
      "------------------------------------------------------------------\n",
      "------------- iteration  10 ----------------------\n",
      "{'0': {'precision': 0.9957805907172996, 'recall': 0.9939831528279182, 'f1-score': 0.9948810599217104, 'support': 1662}, '1': {'precision': 0.8734177215189873, 'recall': 0.9078947368421053, 'f1-score': 0.8903225806451613, 'support': 76}, 'accuracy': 0.9902186421173763, 'macro avg': {'precision': 0.9345991561181435, 'recall': 0.9509389448350117, 'f1-score': 0.9426018202834359, 'support': 1738}, 'weighted avg': {'precision': 0.9904298553553481, 'recall': 0.9902186421173763, 'f1-score': 0.9903088824619765, 'support': 1738}}\n",
      "F1 score (class 1).... 0.8903225806451613\n",
      "------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT8AAAEGCAYAAAAT05LOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAdzklEQVR4nO3de5xXVb3/8debAUYRUQhRBBRM1JBKEwkrO5YpdPkFXSzMTj6KDmqYnu6Sv9/Pc+zwy05XPYUdUhPLJEoLuolKmdlRES+JYARKwgAKiCJ4AWbm8/tj77Gv41z2HubL9zvf/X762I/Ze+3LWhvkM2vvtfZaigjMzIqmV6ULYGZWCQ5+ZlZIDn5mVkgOfmZWSA5+ZlZIvStdgFKDB9XFyBF9Kl0My+FvD/WrdBEshxd5jl2xU3tyjYlv2y+e2tqU6dj7Htq5KCIm7Ul+5VJVwW/kiD4sWTSi0sWwHCYeelyli2A53BOL9/gaT21tYsmiwzIdWzd01eA9zrBMqir4mVn1C6CZ5koXY485+JlZLkGwO7I99lYzN3iYWW7NGf/rjKRrJG2S9HCr9E9LWilpuaT/LEmfKWl1um9iSfoJkpal+66Q1Ol7TQc/M8slCJoi25LBtcDLGkQkvQ2YDLwuIo4FvpGmjwGmAsem58yWVJeediUwHRidLp02sjj4mVluzUSmpTMRcQewtVXyecBlEbEzPWZTmj4ZmBcROyNiDbAaGC9pKDAgIu6KZLCC64ApneXt4GdmuQTQRGRagMGSlpYs0zNkcRRwsqR7JP1R0olp+jBgXclxDWnasHS9dXqH3OBhZrllqdWltkTEuJyX7w0MBCYAJwLzJR0BtPUeLzpI7zQTM7PMAthd3qHwGoCb0kfYJZKagcFpemlH4OHAhjR9eBvpHfJjr5nlEhkfeZuy1w5b+yXwdgBJRwF9gS3AQmCqpHpJo0gaNpZExEZgu6QJaSvvx4AFnWXimp+Z5RPQ1E0VP0k3AKeQvBtsAC4BrgGuSbu/7ALOTmuByyXNB1YAjcCMiJc6HJ5H0nK8L/C7dOmQg5+Z5ZJ84dFN14o4s51dH23n+FnArDbSlwJj8+Tt4GdmOYmmNtsYehYHPzPLJWnwcPAzs4JJ+vk5+JlZATW75mdmReOan5kVUiCaaqCLsIOfmeXmx14zK5xA7Iq6zg+scg5+ZpZL0snZj71mVkBu8DCzwokQTeGan5kVULNrfmZWNEmDR88PHT3/Dsxsr3KDh5kVVpP7+ZlZ0fgLDzMrrGa39ppZ0SQDG/T84Nfz78DM9qpA7I66TEtnJF0jaVM6X0frfZ+XFJIGl6TNlLRa0kpJE0vST5C0LN13RTqRUYcc/Mwslwhoil6ZlgyuBSa1TpQ0AjgNWFuSNgaYChybnjNbUkuEvRKYTjKj2+i2rtmag5+Z5SSaMy6diYg7gK1t7Po28EVePvn4ZGBeROyMiDXAamC8pKHAgIi4K53l7TpgSmd5+52fmeUSkOfztsGSlpZsz4mIOR2dIOm9wPqI+Eurp9dhwN0l2w1p2u50vXV6hxz8zCy3HA0eWyJiXNaDJfUDLgZOb2t3G2nRQXqHHPzMLJdA5RzM9NXAKKCl1jccuF/SeJIa3YiSY4cDG9L04W2kd8jv/Mwsl2Tqyt6ZltzXjlgWEUMiYmREjCQJbG+IiCeAhcBUSfWSRpE0bCyJiI3AdkkT0lbejwELOsvLwc/MckomLc+ydHol6QbgLuBoSQ2SprV3bEQsB+YDK4CbgRkR0ZTuPg+4iqQR5FHgd53l7cdeM8sl6L4vPCLizE72j2y1PQuY1cZxS4GxefJ28DOz3DySs5kVToT8ba+ZFU/S4OHZ28yscDyHh5kVUNLg4Xd+ZlZAtTCklYOfmeVS5i889hoHPzPLzRMYmVnhRMDuZgc/MyuY5LHXwc/MCshfeBTUNz8zgntuG8CBgxuZ84eVL6UvuHowC384mF69gzee+iyf/D8beWJdX/7ln45h+BE7ATjmhOe48GsNvPi8mHXOSDb8vZ5edcGE055l2sUbK3VLhfXZb63lje/YzjNbenPO248GYP8DG/ny9x/n4OG7eLKhL7POOZwd2/xPpUWtdHUpa91V0qR0opHVki4qZ1570+kf3sqs6x97WdqDf+7P/yw6gCsXr+QHt6/kg+dtfmnf0MN3cuVtK7nytpVc+LV/DDj7gXM3c/Wf/srsW/7G8nv3497f77/X7sESt/x0EBefNeplaR86fxMP3NmfT7zlNTxwZ38+fP6mCpWuWiWPvVmWala20qUTi3wPeCcwBjgznYCkx3vthOfYf2DTy9J+fd2r+PD5T9K3PhlA9sDBjR1eY59+wXFv3gFAn77B6Ne+wOaNfcpTYGvXw/f0Z/vTL6/VnTTxWW6bPwiA2+YP4qRJz1aiaFWtu+bwqKRyhubxwOqIeCwidgHzSCYgqUnrH92Hh+/pzwXvHs3n338kKx/c96V9T6zty6dOO4rPv/9Ilt2z3yvO3bGtjrtvHcDxb9mxN4ts7Rg4eDdbNyW/iLZu6sOBr+r4F1nRJK29dZmWalbOFxnDgHUl2w3AG1sfJGk6yZRzHDas575XaWpKgtjlv17Fygf7Meuckcy9+xEGDdnNj+9dwYBBTax6aF/+7eOjmHP7X9lv/+bkvEb46qcOZ/K0LQw9fFeF78Ksc7XSybmcNb9Mk4pExJyIGBcR4w56VXX/pujI4KG7efO7tiHBMcc/T69esG1rHX3rgwGDkkfk0a97gUNH7mL9Y/UvnfedL4xg2KidvP9fNrd3advLnt7Sh0FDdgMwaMhunnmq5/5SLhc/9nasvclGatKbJm3jwTv7A9DwaD27d4kDBjXxzFN1NKWvBzc+3pf1a/pyyGFJDe/arx3Cc9vrOPfS9ZUqtrXh7lsG8I4PJVPJvuNDW7lr0YAKl6i6tLT2Zlk6I+kaSZskPVyS9nVJf5X0kKRfSDqwZN/MtAF1paSJJeknSFqW7rtCrea8bEs5f6XdC4xOJxpZTzLT+kfKmN9e89XzDuehu/qzbWtvzjphDP/8uSeYOHUr3/rsCKa/7Wj69Am+cPlaJFh2d3+u+/oh1PWGul7BBZc1MGBgE5s39OGGyw9hxJEvMuP0pIvFez++mXee1db8zVYuF81+nNedtIMDBjXy46Ur+NE3D+an3x3Cxd9/nElTt7JpfdLVxV6uG1tyrwW+SzLReItbgZkR0Sjpa8BM4Etpg+lU4FjgUOA2SUel83hcSfL67G7gt8AkOpnHo2zBLy34+cAioA64Jp2ApMebeeXjbaZ/6btrX5F28ru3cfK7t70i/aBDd7Now4PdXTTL6bJPtR3YLvrwq/dySXqOCNHYfXN43CFpZKu0W0o27wY+mK5PBuZFxE5gjaTVwHhJfwcGRMRdAJKuA6ZQqeAHEBG/JYnCZlZDcjR4DJa0tGR7TkTMyZHVJ4CfpuvDSIJhi4Y0bXe63jq9Q36Ta2a55PzCY0tEjOtKPpIuBhqB61uS2ilOpsbV1hz8zCy3cnd1kXQ28B7g1IhoCWTtNaI2pOut0ztU3d+fmFnVaenn1x2tvW2RNAn4EvDeiHi+ZNdCYKqk+rQhdTSwJCI2AtslTUhbeT8GLOgsH9f8zCy37urDJ+kG4BSSd4MNwCUkrbv1wK1pj5W7I+LciFguaT6wguRxeEba0gtwHknL8b4kDR0dNnaAg5+Z5RQBjd00mGlEnNlG8tUdHD8LmNVG+lJgbJ68HfzMLLda+LzNwc/McqmVb3sd/Mwst3DwM7MiqvZBC7Jw8DOzXCL8zs/MCkk0eepKMysiv/Mzs8KpldnbHPzMLJ9I3vv1dA5+ZpabW3vNrHDCDR5mVlR+7DWzQnJrr5kVToSDn5kVlLu6mFkh+Z2fmRVOIJproLW359+Bme11kXHpjKRrJG2S9HBJ2iBJt0palf4cWLJvpqTVklZKmliSfoKkZem+K9K5PDrk4Gdm+aQNHlmWDK4FJrVKuwhYHBGjgcXpNpLGAFOBY9NzZkuqS8+5EphOMqnR6Dau+QoOfmaWXzdV/SLiDmBrq+TJwNx0fS4wpSR9XkTsjIg1wGpgvKShwICIuCud5vK6knPa5Xd+ZpZbmbu6HJxOR0lEbJQ0JE0fBtxdclxDmrY7XW+d3qF2g5+k/6KD2B0RF3R2cTOrPQE0N2cOfoMlLS3ZnhMRc7qYdVuZRgfpHeqo5re0g31mVlQBZK/5bYmIcTlzeFLS0LTWNxTYlKY3ACNKjhsObEjTh7eR3qF2g19EzC3dlrRfRDyXsfBmVsPK3M9vIXA2cFn6c0FJ+k8kfQs4lKRhY0lENEnaLmkCcA/wMeC/Osuk0wYPSSdJWgE8km6/XtLsLtyQmdWKbmrwkHQDcBdwtKQGSdNIgt5pklYBp6XbRMRyYD6wArgZmBERTemlzgOuImkEeRT4XWd5Z2nw+A4wkSTqEhF/kfTWDOeZWU3K3I2lUxFxZju7Tm3n+FnArDbSlwJj8+SdqbU3Ita16jPY1N6xZlYABfm8bZ2kNwEhqS9wAekjsJkVUEBkb+2tWlk6OZ8LzCDpN7MeOC7dNrPCUsalenVa84uILcBZe6EsZtZT1MBjb5bW3iMk/UrS5vQD5AWSjtgbhTOzKtVdIxtUUJbH3p+QNC8PJelb8zPghnIWysyqWEsn5yxLFcsS/BQRP4qIxnT5MVUf082snCKyLdWso297B6Wrf5B0ETCPJOh9GPjNXiibmVWrGmjt7ajB4z5e/tHwOSX7AvhKuQplZtVNVV6ry6Kjb3tH7c2CmFkP0QMaM7LI9IWHpLHAGGCflrSIuK5chTKzalb9jRlZdBr8JF0CnEIS/H4LvBO4k2S0VDMrohqo+WVp7f0gyUfGT0TEx4HXA/VlLZWZVbfmjEsVy/LY+0JENEtqlDSAZGBBd3I2K6p8g5lWrSzBb6mkA4EfkLQA7wCWlLNQZlbdarq1t0VEfCpd/b6km0lmSXqovMUys6pWy8FP0hs62hcR95enSGZm5ddRze+bHewL4O3dXBb+9lA/Jh56XHdf1sqo1/77V7oIloN2dM9U3TX92BsRb9ubBTGzHiLots/bJH0G+GR61WXAx4F+wE+BkcDfgQ9FxNPp8TOBaSSjyV8QEYu6mnf3/Bows2LphiGtJA0jGRl+XESMBeqAqcBFwOKIGA0sTreRNCbdfywwCZgtqa6rt+DgZ2a5KbItGfQG9pXUm6TGtwGYDLRMnTsXmJKuTwbmRcTOiFhDMlPb+K7eg4OfmeWXveY3WNLSkmX6S5eIWA98A1gLbAS2RcQtwMERsTE9ZiMwJD1lGLCupBQNaVqXZPm8TSTD2B8REZdKOgw4JCLc18+sqLI3eGyJiHFt7ZA0kKQ2Nwp4BviZpI92cK22XjR2ueklS81vNnAS0DK/5nbge13N0Mx6tqyPvBkee98BrImIzRGxG7gJeBPwpKShAOnPTenxDcCIkvOHkzwmd0mW4PfGiJgBvAiQtrr07WqGZlYDmpVt6dhaYIKkfukT5qkk0+IuBM5OjzkbWJCuLwSmSqqXNAoYzR58bZbl87bdaYtKAEg6iKr/ZNnMyqk7+vlFxD2Sfg7cDzQCDwBzgP7AfEnTSALkGenxyyXNB1akx8+IiKau5p8l+F0B/AIYImkWySgv/7urGZpZDeimTs4RcQlwSavknSS1wLaOnwXM6o68s3zbe72k+9LCCJgSEY90R+Zm1gNl78ZS1bK09h4GPA/8qjQtItaWs2BmVsWKEPxIZmprmchoH5Jm6ZUkvazNrIBUA2/9szz2vrZ0Ox3t5Zx2Djcz6xEyTWBUKiLul3RiOQpjZj1EER57JX22ZLMX8AZgc9lKZGbVrSgNHkDpgG2NJO8AbyxPccysR6j14Jd2bu4fEV/YS+Uxs56gloOfpN4R0djRcPZmVjyi9lt7l5C833tQ0kLgZ8BzLTsj4qYyl83MqlGB3vkNAp4imbOjpb9fkIzAYGZFVOPBb0ja0vsw/wh6LWrg1s2sy2ogAnQU/OpIRlfo1gEEzaznq/XH3o0RceleK4mZ9Rw1Hvy6Z246M6stUfutvW2Op2VmVtM1v4jYujcLYmY9Ry288/PUlWaWXzdMWg4g6UBJP5f0V0mPSDpJ0iBJt0palf4cWHL8TEmrJa2UNHFPbsHBz8zyyRr4stUOLwdujohjgNeTTGB0EbA4IkYDi9NtJI0BppKMJToJmJ1+gtslDn5mlovonqkrJQ0A3gpcDRARuyLiGZK5fOemh80FpqTrk4F5EbEzItYAq4HxXb0PBz8zyy1H8BssaWnJMr3kMkeQDI/3Q0kPSLpK0n7AwRGxESD9OSQ9fhiwruT8hjStS3IPZmpmlqO1d0tEjGtnX2+S8QM+nU5jeTnpI247uvWDC9f8zCy/7nnn1wA0RMQ96fbPSYLhk5KGAqQ/N5UcP6Lk/OHAhq7egoOfmeWT8ZG3s3d+EfEEsE7S0WnSqSQTki8Ezk7TzgYWpOsLgamS6iWNAkaTjD7VJX7sNbP8uq+f36eB6yX1BR4DPk5SKZsvaRqwFjgDICKWS5pPEiAbgRkR0dTVjB38zCy37vq8LSIeBNp6J9jmF2YRMQuY1R15O/iZWW618IWHg5+Z5ZO9A3NVc/Azs/wc/MysaFq+8OjpHPzMLDc19/zo5+BnZvn4nZ+ZFZUfe82smBz8zKyIXPMzs2Jy8DOzwinA7G1mZq/gfn5mVlzR86Ofg5+Z5eaan3Vo+Ktf5Mvff/yl7UMO28WPvn4Iv7jqoAqWylrbb/9G/vU/VnH4Uc8TAd/+8mh2vtCLT//7o+zTr4lN6+v5z88fzfPP+Z8L4E7OnZF0DfAeYFNEjC1XPtWs4dF9+NRpySC1vXoF19+/gj//7oAKl8paO/fix1j6p4HMuvA19O7TTP0+zfy/Hz7MVV8bxbJ7D+D0DzzBBz65nh9dfnili1o1aqHBo5zD2F9LMremAcedvIONj/dl0/q+lS6Klei3XyNjT9zGop8fDEDj7l48t703w0e9wLJ7BwBw/58H8pbTt1SymFVHzdmWala24BcRdwBby3X9nuaUyU9z+y8Hdn6g7VWHjHiRbVv78NmvruK7v3iAC/9jFfX7NvH3v/VjwqnJ/74nT9rC4KG7KlzSKhIkDR5ZlipW8QmMJE1vmdNzNzsrXZyy6N2nmQmnP8sdv/Ijb7Wp6x0cOWYHv7lhKOe/73hefKEXH5rewLcvHs3/+shGrrjxAfbdr4nGXW3Nmlhc3TGB0UvXkurSeXt/nW4PknSrpFXpz4Elx86UtFrSSkkT9+QeKh78ImJORIyLiHF9qK90ccrixLdvZ/WyfXlmS59KF8Va2fJEPVueqGflQ/sDcOfNgzlyzA4aHuvHxdPGcsEHjuePvzmIjev2qXBJq0z3TF3Z4kLgkZLti4DFETEaWJxuI2kMMBU4luSV2mxJdV29hYoHvyI4ZcozfuStUk9v6cvmJ+oZNup5AI476RnWPtqPAwYlj7lSMPW8tfx23iGVLGZVaenk3B01P0nDgXcDV5UkTwbmputzgSkl6fMiYmdErAFWA+O7eh9uuy+z+n2becPJ27n8i8MrXRRrx5VfOYIvfuNv9OnTzMZ1+/DtmUdx6pQnec9HNgLwP7cO5pYbD65wKatIRJ7BTAdLWlqyPSci5pRsfwf4IrB/SdrBEbExySo2ShqSpg8D7i45riFN65JydnW5ATiF5OYbgEsi4upy5Vetdr7QizPGFrKnT4/x2F/7c+EHjntZ2oLrhrHgui7/u6p92R9pt0REW1NTIqmlK9x9kk7JcK22Xrx2uVWlbMEvIs4s17XNrLK66QuPNwPvlfQuYB9ggKQfA09KGprW+oYCm9LjG4ARJecPBzZ0NXO/8zOzfAJojmxLR5eJmBkRwyNiJElDxu8j4qPAQuDs9LCzgQXp+kJgqqR6SaOA0cCSrt6G3/mZWX7l7cJ3GTBf0jRgLXAGQEQslzQfWAE0AjMioqmrmTj4mVlu3T2wQUTcDtyerj8FnNrOcbOAWd2Rp4OfmeXmqSvNrHg8qouZFVHSybnnRz8HPzPLr8pHbMnCwc/McnPNz8yKx+/8zKyYcn3bW7Uc/MwsPz/2mlnheNJyMyss1/zMrJB6fuxz8DOz/NTc8597HfzMLJ/AnZzNrHhEuJOzmRWUg5+ZFZKDn5kVTo288/McHmaWm5qbMy0dXkMaIekPkh6RtFzShWn6IEm3SlqV/hxYcs5MSaslrZQ0cU/uwcHPzHKK5LE3y9KxRuBzEfEaYAIwQ9IY4CJgcUSMBhan26T7pgLHApOA2ZLqunoXDn5mlk/QLcEvIjZGxP3p+nbgEZJJyCcDc9PD5gJT0vXJwLyI2BkRa4DVwPiu3oaDn5nl15xxgcGSlpYs09u6nKSRwPHAPcDBEbERkgAJDEkPGwasKzmtIU3rEjd4mFluOfr5bYmIcR1eS+oP3Aj8a0Q8K6ndQ9tI63Kzs2t+ZpZf97zzQ1IfksB3fUTclCY/KWloun8osClNbwBGlJw+HNjQ1Vtw8DOzfCKgqTnb0gElVbyrgUci4lsluxYCZ6frZwMLStKnSqqXNAoYDSzp6m34sdfM8uueTs5vBv4ZWCbpwTTty8BlwHxJ04C1wBlJlrFc0nxgBUlL8YyIaOpq5g5+ZpZfNwS/iLiTtt/jAZzazjmzgFl7nDkOfmaWVwCew8PMiicgev73bQ5+ZpZP0GljRk/g4Gdm+XlUFzMrJAc/MyuebB2Yq52Dn5nlE4AnMDKzQnLNz8yKJ9zaa2YFFBDu52dmheQvPMyskPzOz8wKJ8KtvWZWUK75mVnxBNHU5WH0qoaDn5nl4yGtzKyw3NXFzIomgHDNz8wKJzyYqZkVVC00eCiqqMla0mbg8UqXowwGA1sqXQjLpVb/zg6PiIP25AKSbib588liS0RM2pP8yqWqgl+tkrS0s1nrrbr476z2edJyMyskBz8zKyQHv71jTqULYLn576zG+Z2fmRWSa35mVkgOfmZWSA5+ZSRpkqSVklZLuqjS5bHOSbpG0iZJD1e6LFZeDn5lIqkO+B7wTmAMcKakMZUtlWVwLVCVnXKtezn4lc94YHVEPBYRu4B5wOQKl8k6ERF3AFsrXQ4rPwe/8hkGrCvZbkjTzKwKOPiVj9pIc78isyrh4Fc+DcCIku3hwIYKlcXMWnHwK597gdGSRknqC0wFFla4TGaWcvArk4hoBM4HFgGPAPMjYnllS2WdkXQDcBdwtKQGSdMqXSYrD3/eZmaF5JqfmRWSg5+ZFZKDn5kVkoOfmRWSg5+ZFZKDXw8iqUnSg5IelvQzSf324FrXSvpgun5VR4MuSDpF0pu6kMffJb1ilq/20lsdsyNnXv8m6fN5y2jF5eDXs7wQEcdFxFhgF3Bu6c50JJncIuKTEbGig0NOAXIHP7Nq5uDXc/0JODKtlf1B0k+AZZLqJH1d0r2SHpJ0DoAS35W0QtJvgCEtF5J0u6Rx6fokSfdL+oukxZJGkgTZz6S1zpMlHSTpxjSPeyW9OT33VZJukfSApP+m7e+bX0bSLyXdJ2m5pOmt9n0zLctiSQelaa+WdHN6zp8kHdMtf5pWOL0rXQDLT1JvknECb06TxgNjI2JNGkC2RcSJkuqBP0u6BTgeOBp4LXAwsAK4ptV1DwJ+ALw1vdagiNgq6fvAjoj4RnrcT4BvR8Sdkg4j+YrlNcAlwJ0RcamkdwMvC2bt+ESax77AvZJujIingP2A+yPic5L+b3rt80kmFjo3IlZJeiMwG3h7F/4YreAc/HqWfSU9mK7/Cbia5HF0SUSsSdNPB17X8j4POAAYDbwVuCEimoANkn7fxvUnAHe0XCsi2hvX7h3AGOmlit0ASfunebw/Pfc3kp7OcE8XSHpfuj4iLetTQDPw0zT9x8BNkvqn9/uzkrzrM+Rh9goOfj3LCxFxXGlCGgSeK00CPh0Ri1od9y46H1JLGY6B5HXJSRHxQhtlyfy9pKRTSALpSRHxvKTbgX3aOTzSfJ9p/Wdg1hV+51d7FgHnSeoDIOkoSfsBdwBT03eCQ4G3tXHuXcA/SRqVnjsoTd8O7F9y3C0kj6Ckxx2Xrt4BnJWmvRMY2ElZDwCeTgPfMSQ1zxa9gJba60dIHqefBdZIOiPNQ5Je30keZm1y8Ks9V5G8z7s/nYTnv0lq+L8AVgHLgCuBP7Y+MSI2k7ynu0nSX/jHY+evgPe1NHgAFwDj0gaVFfyj1fnfgbdKup/k8XttJ2W9Gegt6SHgK8DdJfueA46VdB/JO71L0/SzgGlp+ZbjqQGsizyqi5kVkmt+ZlZIDn5mVkgOfmZWSA5+ZlZIDn5mVkgOfmZWSA5+ZlZI/x9Jruh3Ct4FkwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "%matplotlib inline\n",
    "\n",
    "########## run the model multiple times #########\n",
    "nb_reps = 10\n",
    "save_results = {'f1':[],'recall':[],'precision':[]}\n",
    "base_path_img = ''\n",
    "\n",
    "base_path_img = '/home/wkhal001/Crisis-classification/scripts-rescue-detection/__comparison_new_experimental_design/Integrated_model_test/Run7/'\n",
    "\n",
    "iteration = 1\n",
    "for i in range(nb_reps): \n",
    "    print('------------- iteration ',str(iteration),'----------------------')\n",
    "    model =create_hybrid_model_NER_2()\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(0.001),\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(), #BinaryCrossentropy(), SparseCategoricalCrossentropy() #keras.losses.SparseCategoricalCrossentropy()\n",
    "        metrics=[keras.metrics.SparseCategoricalCrossentropy()], #keras.metrics.SparseCategoricalAccuracy()\n",
    "    )\n",
    "    \n",
    "    Train_hybrid_bert = np.array(ls_input_train)\n",
    "    Train_hybrid_logical = np.array(expanded_train_logical)\n",
    "    Train_hybrid_Y = np.array(Train_Y)\n",
    "\n",
    "    history = model.fit(x=[Train_hybrid_bert,Train_hybrid_logical], y=Train_hybrid_Y, batch_size=16, epochs=100,verbose=0) \n",
    "    \n",
    "    Test_hybrid_bert = np.array(ls_input_test)\n",
    "    Test_hybrid_logical = np.array(expanded_test_logical)\n",
    "    Test_hybrid_Y = np.array(Test_Y)\n",
    "\n",
    "    predictions = model.predict([Test_hybrid_bert,Test_hybrid_logical])\n",
    "    preds = np.argmax(predictions, axis=1)\n",
    "    dict_r = classification_report(Test_Y, preds, output_dict = True)\n",
    "    print(dict_r)\n",
    "\n",
    "    f1 = f1_score(Test_hybrid_Y, preds, average='binary')    \n",
    "    print('F1 score (class 1)....',f1)\n",
    "    \n",
    "    save_results['f1'].append(dict_r['1']['f1-score'])\n",
    "    save_results['recall'].append(dict_r['1']['recall']) \n",
    "    save_results['precision'].append(dict_r['1']['precision'])\n",
    "\n",
    "    cm = confusion_matrix(Test_Y, preds, labels=np.unique(Test_Y))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=np.unique(Test_Y))\n",
    "    img_path = base_path_img + 'confusion_matrix_re' + str(iteration) + '.png'\n",
    "    iteration = iteration + 1\n",
    "    \n",
    "    #disp.figure_.savefig(img_path)\n",
    "    disp.plot()\n",
    "    plt.savefig(img_path)\n",
    "    \n",
    "    print('------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### Build integrated model (NN layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers.merge import concatenate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hybrid_model(): #### suggested hybrid model: fine-tuned bert model + logical features\n",
    "    \n",
    "    # the first branch operates on the first input\n",
    "    x = Dense(100, activation=\"relu\")(input_bert)\n",
    "    #x = Dense(11, activation=\"relu\")(x)\n",
    "    x = Dense(5, activation=\"relu\")(x)\n",
    "    x = Model(inputs=input_bert, outputs=x)\n",
    "\n",
    "    # # the second branch opreates on the second input\n",
    "    y = Dense(11, activation=\"relu\")(input_logical)\n",
    "    y = Dense(5, activation=\"relu\")(y)\n",
    "    y = Model(inputs=input_logical, outputs=y)\n",
    "\n",
    "    # combine the output of the two branches\n",
    "    combined = concatenate([x.output, input_logical])\n",
    "\n",
    "    # apply a FC layer and then a regression prediction on the\n",
    "    # combined outputs\n",
    "    z1 = Dense(10, activation=\"relu\")(combined)\n",
    "    z2 = Dense(5, activation=\"relu\")(z1)\n",
    "    z = Dense(2, activation=\"softmax\")(z2)\n",
    "\n",
    "    # our model will accept the inputs of the two branches and then output a single value\n",
    "    model = Model(inputs=[x.input, input_logical], outputs=z)\n",
    "    \n",
    "    return(model)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 =create_hybrid_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 768)]        0           []                               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 100)          76900       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 5)            505         ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 11)]         0           []                               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 16)           0           ['dense_1[0][0]',                \n",
      "                                                                  'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 10)           170         ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 5)            55          ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 2)            12          ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 77,642\n",
      "Trainable params: 77,642\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------- iteration  1 ----------------------\n",
      "{'0': {'precision': 0.9939831528279182, 'recall': 0.9939831528279182, 'f1-score': 0.9939831528279182, 'support': 1662}, '1': {'precision': 0.868421052631579, 'recall': 0.868421052631579, 'f1-score': 0.868421052631579, 'support': 76}, 'accuracy': 0.9884925201380897, 'macro avg': {'precision': 0.9312021027297486, 'recall': 0.9312021027297486, 'f1-score': 0.9312021027297486, 'support': 1738}, 'weighted avg': {'precision': 0.9884925201380897, 'recall': 0.9884925201380897, 'f1-score': 0.9884925201380897, 'support': 1738}}\n",
      "F1 score (class 1).... 0.868421052631579\n",
      "------------------------------------------------------------------\n",
      "------------- iteration  2 ----------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "%matplotlib inline\n",
    "\n",
    "########## run the model multiple times #########\n",
    "nb_reps = 10\n",
    "save_results = {'f1':[],'recall':[],'precision':[]}\n",
    "base_path_img = ''\n",
    "\n",
    "## Run 3: architecture with 2 hidden layers on top (10 and 5)\n",
    "## Run4: archutecture with best fine-tuned BERT and optuna architecture\n",
    "base_path_img = '/home/wkhal001/Crisis-classification/scripts-rescue-detection/__comparison_new_experimental_design/Integrated_model_test/Run5/'\n",
    "\n",
    "iteration = 1\n",
    "for i in range(nb_reps): \n",
    "    print('------------- iteration ',str(iteration),'----------------------')\n",
    "    model =create_hybrid_model()\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(0.001),\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(), #BinaryCrossentropy(), SparseCategoricalCrossentropy() #keras.losses.SparseCategoricalCrossentropy()\n",
    "        metrics=[keras.metrics.SparseCategoricalCrossentropy()], #keras.metrics.SparseCategoricalAccuracy()\n",
    "    )\n",
    "    \n",
    "    Train_hybrid_bert = np.array(ls_input_train)\n",
    "    Train_hybrid_logical = np.array(train_logical_features)\n",
    "    Train_hybrid_Y = np.array(Train_Y)\n",
    "\n",
    "    history = model.fit(x=[Train_hybrid_bert,Train_hybrid_logical], y=Train_hybrid_Y, batch_size=8, epochs=100,verbose=0) \n",
    "    \n",
    "    Test_hybrid_bert = np.array(ls_input_test)\n",
    "    Test_hybrid_logical = np.array(test_logical_features)\n",
    "    Test_hybrid_Y = np.array(Test_Y)\n",
    "\n",
    "    predictions = model.predict([Test_hybrid_bert,Test_hybrid_logical])\n",
    "    preds = np.argmax(predictions, axis=1)\n",
    "    dict_r = classification_report(Test_Y, preds, output_dict = True)\n",
    "    print(dict_r)\n",
    "\n",
    "    f1 = f1_score(Test_hybrid_Y, preds, average='binary')    \n",
    "    print('F1 score (class 1)....',f1)\n",
    "    \n",
    "    save_results['f1'].append(dict_r['1']['f1-score'])\n",
    "    save_results['recall'].append(dict_r['1']['recall']) \n",
    "    save_results['precision'].append(dict_r['1']['precision'])\n",
    "\n",
    "    #cm = confusion_matrix(Test_Y, preds, labels=SVM.classes_)\n",
    "    cm = confusion_matrix(Test_Y, preds, labels=np.unique(Test_Y))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=np.unique(Test_Y))\n",
    "    img_path = base_path_img + 'confusion_matrix_re' + str(iteration) + '.png'\n",
    "    iteration = iteration + 1\n",
    "    \n",
    "    #disp.figure_.savefig(img_path)\n",
    "    disp.plot()\n",
    "    plt.savefig(img_path)\n",
    "    \n",
    "    print('------------------------------------------------------------------')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1': [0.868421052631579,\n",
       "  0.8859060402684564,\n",
       "  0.8947368421052632,\n",
       "  0.8947368421052632,\n",
       "  0.9006622516556291,\n",
       "  0.8961038961038961,\n",
       "  0.8961038961038961,\n",
       "  0.8590604026845637,\n",
       "  0.8859060402684564,\n",
       "  0.8758169934640522],\n",
       " 'recall': [0.868421052631579,\n",
       "  0.868421052631579,\n",
       "  0.8947368421052632,\n",
       "  0.8947368421052632,\n",
       "  0.8947368421052632,\n",
       "  0.9078947368421053,\n",
       "  0.9078947368421053,\n",
       "  0.8421052631578947,\n",
       "  0.868421052631579,\n",
       "  0.881578947368421],\n",
       " 'precision': [0.868421052631579,\n",
       "  0.9041095890410958,\n",
       "  0.8947368421052632,\n",
       "  0.8947368421052632,\n",
       "  0.9066666666666666,\n",
       "  0.8846153846153846,\n",
       "  0.8846153846153846,\n",
       "  0.8767123287671232,\n",
       "  0.9041095890410958,\n",
       "  0.8701298701298701]}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# create a binary pickle file \n",
    "f = open(\"/home/wkhal001/Crisis-classification/scripts-rescue-detection/__comparison_new_experimental_design/Integrated_model_test/Run5/Testing_runs_results.pkl\",\"wb\")\n",
    "pickle.dump(save_results,f)\n",
    "f.close()\n",
    "\n",
    "# open a file, where you stored the pickled data\n",
    "# file = open(\"/home/wkhal001/Crisis-classification/scripts-rescue-detection/__comparison_new_experimental_design/Fine_tuned_bert/Saved_results_fine_tuned_bert.pkl\", 'rb')\n",
    "\n",
    "# # dump information to that file\n",
    "# data = pickle.load(file)\n",
    "\n",
    "# # close the file\n",
    "# file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of runs.... 10\n",
      "------------- F1 scores --------------------\n",
      "average (10 runs)  0.8857454257391055\n",
      "stdev (10 runs)  0.013782631457519219\n",
      "max (10 runs)  0.9006622516556291\n",
      "min (10 runs)  0.8590604026845637\n",
      "------------- recall scores --------------------\n",
      "average (10 runs)  0.8828947368421053\n",
      "stdev (10 runs)  0.02098857212983405\n",
      "max (10 runs)  0.9078947368421053\n",
      "min (10 runs)  0.8421052631578947\n",
      "------------- precision scores --------------------\n",
      "average (10 runs)  0.8888853549718726\n",
      "stdev (10 runs)  0.014155537579675723\n",
      "max (10 runs)  0.9066666666666666\n",
      "min (10 runs)  0.868421052631579\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "\n",
    "print('number of runs....',len(save_results['f1']))\n",
    "\n",
    "print('------------- F1 scores --------------------')\n",
    "print('average (10 runs) ',statistics.mean(save_results['f1']))\n",
    "print('stdev (10 runs) ',statistics.stdev(save_results['f1']))\n",
    "print('max (10 runs) ',max(save_results['f1']))\n",
    "print('min (10 runs) ',min(save_results['f1']))\n",
    "\n",
    "print('------------- recall scores --------------------')\n",
    "print('average (10 runs) ',statistics.mean(save_results['recall']))\n",
    "print('stdev (10 runs) ',statistics.stdev(save_results['recall']))\n",
    "print('max (10 runs) ',max(save_results['recall']))\n",
    "print('min (10 runs) ',min(save_results['recall']))\n",
    "\n",
    "\n",
    "print('------------- precision scores --------------------')\n",
    "print('average (10 runs) ',statistics.mean(save_results['precision']))\n",
    "print('stdev (10 runs) ',statistics.stdev(save_results['precision']))\n",
    "print('max (10 runs) ',max(save_results['precision']))\n",
    "print('min (10 runs) ',min(save_results['precision']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Results by integrated model using pretrained Google BERT and optuna architecture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "ls_crisis_hashtags = ['SOSHouston','SOSHarvey','HelpHouston','harveysos','harveyrescue','sendhelp','HarveySOS','Rescue','rescue'\n",
    "                      ,'HarveyFlood','HARVEYHELP','Relief','PLEASEHELP','URGENT']\n",
    "\n",
    "def extract_hash_tags(sentence,ls_crisis_hashtags):\n",
    "    crisis_hashtag_found = False\n",
    "    for part in sentence.split():\n",
    "        if part.startswith('#'): \n",
    "            if part[1:] in ls_crisis_hashtags:\n",
    "                crisis_hashtag_found =True\n",
    "                \n",
    "    return crisis_hashtag_found\n",
    "\n",
    "#--------------------  Create filter 1 ---------------------------------------#\n",
    "# Feature 1.1 keywords with hurricane/flood\n",
    "rgx_f1_1 = \"\\\\b(Hurricane|HurricaneHarvey|Harvey2017|HARVEYHELP|HarveyStorm|harveyhouston|houstonflood|houstonfloods|houstonflooding|texasflood|texasfloods|texasflooding|harveyflood|harveyflooding|HurricaneFlood|HurricaneSOS)\\\\b\"\n",
    "\n",
    "# Feature 1.2 keywords with situation descriptions\n",
    "rgx_f1_2 = \"\\\\b(stranded|stuck|trapped|traps?|trapping|roofs?|rooftop|injured|hurt)\\\\b\"\n",
    "\n",
    "# Feature 1.3: contain both the following two keyword groups (ignore case):\n",
    "# group 1: names of cities and towns near Houston\n",
    "# group 2: flood related keywords. e.g. flood, flooding\n",
    "rgx_f1_3a = \"\\\\b(Houston|Texas|Galveston|Lake\\\\sJackson|Pasadena|League\\\\sCity|DICKINSON|Pearland|Missouri\\\\sCity|Sugar\\\\sLand|Richmond|Rosenberg|Alvin|Baytown|Fresno|Mont\\\\sBelvieu|Humble|Woodlands|Spring|Tomball|Cypress|Brookshire\\\\sKaty|FRIENDSWOOD)\\\\b\"\n",
    "rgx_f1_3b = \"\\\\b(flood|floods|flooding|flooded)\\\\b\"\n",
    "\n",
    "\n",
    "#-------------------- added filter 1: hashtags ---------------------------------------#\n",
    "#Testing_set_comparison['f1_4'] = Testing_set_comparison.apply(lambda row:1 if extract_hash_tags(row['non_cleaned_text'],ls_crisis_hashtags) == True else 0,axis=1)\n",
    "\n",
    "\n",
    "#------------------ Create filter 2: Requesting rescue ------------------------#\n",
    "rgx_f2 = \"\\\\b(rescue|rescues|rescuing|rescued|helps?|helping|WaterRescue|WaterRescueNeeded|aid|assistance|boats?|HarveyRescue|HarveySOS|HurricaneRescue|FloodRescue|HurricaneSOS|HarveyRelief)\\\\b\"\n",
    "\n",
    "# ------ Create filter 3: address description-----------------------------------#\n",
    "address_pattern = \"(\\\\b\\\\d+\\\\s+(#?[A-z]+\\\\.?(-[A-z]+)?\\\\s+){1,3}\\\\b(#@#|ANNEX|ANEX|ANNX|ANX|#@#|ARCADE|ARC|#@#|AVENUE|AV|AVE|AVEN|AVENU|AVN|AVNUE|#@#|BAYOU|BAYOO|BYU|BAYOU|#@#|BEACH|BCH|BEACH|#@#|BEND|BND|#@#|BLUFF|BLF|BLUF|BLUFFS|BLFS|#@#|BOTTOM|BOT|BTM|BOTTM|#@#|BOULEVARD|BLVD|BOUL|BOULV|#@#|BRANCH|BR|BRNCH|#@#|BRIDGE|BRDGE|BRG|#@#|BROOK|BRK|BROOKS|BRKS|#@#|BURG|BG|BURGS|BGS|#@#|BYPASS|BYP|BYPA|BYPAS|BYPS|#@#|CAMP|CP|CMP|#@#|CANYON|CANYN|CYN|CNYN|#@#|CAPE|CPE|#@#|CAUSEWAY|CSWY|CAUSWA|CSWY|#@#|CENTER|CEN|CTR|CENT|CENTR|CENTRE|CNTER|CNTR|CENTERS|CTRS|#@#|CIRCLE|CIR|CIRC|CIRCL|CRCL|CRCLE|CIRCLES|CIRS|#@#|CLIFF|CLF|CLIFFS|CLFS|CLIFFS|#@#|CLUB|CLB|#@#|COMMON|CMN|COMMONS|CMNS|#@#|CORNER|COR|CORNERS|CORS|#@#|COURSE|CRSE|#@#|COURT|CT|COURTS|CTS|#@#|COVE|CV|COVES|COVES|CVS|#@#|CREEK|CRK|#@#|CRESCENT|CRES|CRSENT|CRSNT|CREST|CRST|CR|#@#|CROSSING|CRSSNG|XING|#@#|CROSSROAD|XRD|CROSSROADS|XRDS|#@#|CURVE|CURV|#@#|DALE|DL|#@#|#DAM#|#DM#|#@#|DIVIDE|DIV|DV|DIVIDE|DVD|#@#|DRIVE|DR|DRIV|DRV|DRIVES|DRS|#@#|ESTATE|EST|ESTATES|ESTS|#@#|EXPRESSWAY|EXP|EXPY|EXPR|EXPRESS|EXPW|#@#|EXTENSION|EXT|EXTN|EXTNSN|EXTENSIONS|EXTS|#@#|FALL|FALLS|FLS|#@#|FERRY|FRY|FRRY|FRY|#@#|FIELD|FLD|FIELDS|FLDS|#@#|FLAT|FLT|FLATS|FLTS|#@#|FORD|FRD|FORDS|FRDS|#@#|FOREST|FRST|FORESTS|FRST|#@#|FORGE|FORG|FRG|FORGES|FRGS|#@#|FORK|FRK|FORKS|FRKS|#@#|FORT|FT|FRT|#@#|FREEWAY|FWY|FREEWY|FRWAY|FRWY|FWY|#@#|GARDEN|GDN|GRDN|GARDENS|GDNS|GRDNS|#@#|GATEWAY|GTWY|GATEWY|GATWAY|GTWAY|GTWY|#@#|GLEN|GLN|GLENS|GLNS|#@#|GREEN|GRN|GREENS|GRNS|#@#|GROVE|GROV|GRV|GROVES|GRVS|#@#|HARBOR|HARB|HBR|HARBR|HRBOR|HARBORS|HBRS|#@#|HAVEN|HVN|#@#|HEIGHTS|HT|HTS|#@#|HIGHWAY|HWY|HIWAY|HIWY|HWAY|HWY|#@#|HILL|HL|HILLS|HLS|#@#|HOLLOW|HLLW|HOLW|HOLLOWS|HOLWS|#@#|INLET|INLT|#@#|ISLAND|#IS#|ISLND|ISLANDS|ISS|ISLNDS|#@#|ISLE|ISLES|#@#|JUNCTION|JCT|JCTION|JCTN|JUNCTN|JUNCTON|JUNCTIONS|JCTNS|JCTS|JUNCTIONS|#@#|KEY|KY|KEYS|KYS|#@#|KNOLL|KNL|KNOL|KNOLLS|KNLS|#@#|LAKE|LK|LAKES|LKS|#@#|LAND|LANDING|LNDG|LNDNG|#@#|LANE|LN|#@#|LIGHT|LGT|LIGHTS|LGTS|#@#|LOAF|LF|#@#|LOCK|LCK|LOCKS|LCKS|#@#|LODGE|LDG|LDGE|#@#|LOOP|LOOPS|#@#|MALL|#@#|MANOR|MNR|MANORS|MNRS|#@#|MEADOW|MDW|MEADOWS|MDWS|#@#|MEWS|#@#|MILL|ML|MILLS|MLS|#@#|MISSION|MISSN|MSN|MSSN|#@#|MOTORWAY|MTWY|#@#|MOUNT|MNT|MT|MOUNTAIN|MNTAIN|MTN|MNTN|MOUNTIN|MTIN|MOUNTAINS|MNTNS|MTNS|#@#|NECK|NCK|#@#|ORCHARD|ORCH|ORCHRD|#@#|OVAL|OVL|#@#|OVERPASS|OPAS|#@#|PARK|PRK|PARKS|#@#|PARKWAY|PARKWY|PKWAY|PKWY|PKY|PARKWAYS|PKWYS|#@#|PASS|PASSAGE|PSGE|#@#|#PATH#|#PATHS#|#@#|PIKE|PIKES|#@#|PINE|PNE|PINES|PNES|#@#|PLACE|PL|#@#|PLAIN|PLN|PLAINS|PLNS|#@#|PLAZA|PLZ|PLZA|#@#|#POINT#|PT|#POINTS#|PTS|#@#|PORT|PRT|PORTS|PRTS|#@#|PRAIRIE|PR|PRR|#@#|RADIAL|RAD|RADL|RADIEL|RADL|#@#|RAMP|#@#|RANCH|RNCH|RANCHES|RNCHS|#@#|RAPID|RPD|RAPIDS|RPDS|#@#|REST|RST|#@#|RIDGE|RDG|RDGE|RIDGES|RDGS|#@#|RIVER|RIV|RVR|RIVR|#@#|ROAD|RD|ROADS|RDS|#@#|ROUTE|RTE|#@#|ROW|#@#|RUE|#@#|#RUN#|#@#|SHOAL|SHL|SHL|SHOALS|SHLS|#@#|SHORE|SHOAR|SHR|SHORES|SHOARS|SHRS|#@#|SKYWAY|SKWY|#@#|SPRING|SPG|SPNG|SPRINGS|SPGS|SPNGS|#@#|SPUR|SPURS|#@#|SQUARE|SQ|SQR|SQRE|SQU|SQUARES|SQRS|#@#|STATION|STA|STATN|STN|#@#|STRAVENUE|STRA|STRAV|STRAVEN|STRAVN|STRVN|STRVNUE|#@#|STREAM|STRM|STREME|#@#|STREET|ST|STRT|STR|STREETS|STS|#@#|SUMMIT|SMT|SUMIT|SUMITT|SUMMIT|#@#|TERRACE|TER|TERR|#@#|THROUGHWAY|TRWY|#@#|TRACE|TRCE|TRACES|TRCE|#@#|TRACK|TRAK|TRACKS|TRAK|TRK|TRKS|#@#|TRAFFICWAY|TRFY|#@#|TRAIL|TRL|TRAILS|TRL|TRLS|#@#|TRAILER|TRLR|TRLRS|#@#|TUNNEL|TUNL|TUNLS|TUNNELS|TUNNL|#@#|TURNPIKE|TRNPK|TPKE|TURNPK|#@#|UNDERPASS|UPAS|#@#|UNION|UN|UNIONS|UNS|#@#|VALLEY|VLY|VALLY|VLLY|VLY|VALLEYS|VLYS|#@#|VIADUCT|VDCT|#VIA#|VIADCT|#@#|VIEW|VW|VIEWS|VWS|#@#|VILLAGE|VILL|VLG|VILLG|VILLIAGE|VILLAGES|VLGS|#@#|VILLE|VL|#@#|VISTA|VIS|VIST|VST|VSTA|#@#|#WALK#|#WALKS#|#@#|#WALL#|#@#|#WAY#|WY|#WAYS#|#@#|#WELL#|WL|WELLS|WLS|#@#)\\\\.?\\\\b|#@#)|(\\\\b\\\\d+\\\\s+(AVENUE|AV|AVE|AVEN|AVENU|AVN|AVNUE|#@#|HIGHWAY|HWY|HIWAY|HIWY|HWAY|#@#|ROAD|RD|ROADS|RDS|#@#|ROUTE|RTE|#@#|STREET|ST|STRT|STR|STREETS|STS|#@#)\\\\.?\\\\s+([A-z]|\\\\d+)\\\\b)\"\n",
    "non_address_pattern = \"\\\\b\\\\d+\\\\s+(am|pm|hrs?|hours?|mins?|minutes?|seconds?|#@#|days?|months?|mon|yr|yrs|years?|#@#|ft|feet|foot|in|inch(es)?|meters?|miles?|#@#|pounds?|pnd|ounce|oz|kg|kilograms?|grams?|tons?|#@#|gallons?|liters?|cubes?|volumes?|quarts?|bottles?|cups?|#@#|per|per\\\\s+cent|percent|degrees?|times?|#@#|dollars?|USD|GBP|hundreds?|thousands?|millions?|billions?|trillions?|#@#|from|to|at|and|or|were|are|Fan\\\\sClub|live|hurricane|exit|entrance|#@#|rescued|donation|people|patients|seniors|elderly|women|children|clergy|#@#)\\\\.?\\\\s+(#?[A-z]+\\\\.?(-[A-z]+)?\\\\s+){0,2}\\\\b(#@#|ANNEX|ANEX|ANNX|ANX|#@#|ARCADE|ARC|#@#|AVENUE|AV|AVE|AVEN|AVENU|AVN|AVNUE|#@#|BAYOU|BAYOO|BYU|BAYOU|#@#|BEACH|BCH|BEACH|#@#|BEND|BND|#@#|BLUFF|BLF|BLUF|BLUFFS|BLFS|#@#|BOTTOM|BOT|BTM|BOTTM|#@#|BOULEVARD|BLVD|BOUL|BOULV|#@#|BRANCH|BR|BRNCH|#@#|BRIDGE|BRDGE|BRG|#@#|BROOK|BRK|BROOKS|BRKS|#@#|BURG|BG|BURGS|BGS|#@#|BYPASS|BYP|BYPA|BYPAS|BYPS|#@#|CAMP|CP|CMP|#@#|CANYON|CANYN|CYN|CNYN|#@#|CAPE|CPE|#@#|CAUSEWAY|CSWY|CAUSWA|CSWY|#@#|CENTER|CEN|CTR|CENT|CENTR|CENTRE|CNTER|CNTR|CENTERS|CTRS|#@#|CIRCLE|CIR|CIRC|CIRCL|CRCL|CRCLE|CIRCLES|CIRS|#@#|CLIFF|CLF|CLIFFS|CLFS|CLIFFS|#@#|CLUB|CLB|#@#|COMMON|CMN|COMMONS|CMNS|#@#|CORNER|COR|CORNERS|CORS|#@#|COURSE|CRSE|#@#|COURT|CT|COURTS|CTS|#@#|COVE|CV|COVES|COVES|CVS|#@#|CREEK|CRK|#@#|CRESCENT|CRES|CRSENT|CRSNT|CREST|CRST|CR|#@#|CROSSING|CRSSNG|XING|#@#|CROSSROAD|XRD|CROSSROADS|XRDS|#@#|CURVE|CURV|#@#|DALE|DL|#@#|#DAM#|DM|#@#|DIVIDE|DIV|DV|DIVIDE|DVD|#@#|DRIVE|DR|DRIV|DRV|DRIVES|DRS|#@#|ESTATE|EST|ESTATES|ESTS|#@#|EXPRESSWAY|EXP|EXPY|EXPR|EXPRESS|EXPW|#@#|EXTENSION|EXT|EXTN|EXTNSN|EXTENSIONS|EXTS|#@#|FALL|FALLS|FLS|#@#|FERRY|FRY|FRRY|FRY|#@#|FIELD|FLD|FIELDS|FLDS|#@#|FLAT|FLT|FLATS|FLTS|#@#|FORD|FRD|FORDS|FRDS|#@#|FOREST|FRST|FORESTS|FRST|#@#|FORGE|FORG|FRG|FORGES|FRGS|#@#|FORK|FRK|FORKS|FRKS|#@#|FORT|FT|FRT|#@#|FREEWAY|FWY|FREEWY|FRWAY|FRWY|FWY|#@#|GARDEN|GDN|GRDN|GARDENS|GDNS|GRDNS|#@#|GATEWAY|GTWY|GATEWY|GATWAY|GTWAY|GTWY|#@#|GLEN|GLN|GLENS|GLNS|#@#|GREEN|GRN|GREENS|GRNS|#@#|GROVE|GROV|GRV|GROVES|GRVS|#@#|HARBOR|HARB|HBR|HARBR|HRBOR|HARBORS|HBRS|#@#|HAVEN|HVN|#@#|HEIGHTS|HT|HTS|#@#|HIGHWAY|HWY|HIWAY|HIWY|HWAY|HWY|#@#|HILL|HL|HILLS|HLS|#@#|HOLLOW|HLLW|HOLW|HOLLOWS|HOLWS|#@#|INLET|INLT|#@#|ISLAND|#IS#|ISLND|ISLANDS|ISS|ISLNDS|#@#|ISLE|ISLES|#@#|JUNCTION|JCT|JCTION|JCTN|JUNCTN|JUNCTON|JUNCTIONS|JCTNS|JCTS|JUNCTIONS|#@#|KEY|KY|KEYS|KYS|#@#|KNOLL|KNL|KNOL|KNOLLS|KNLS|#@#|LAKE|LK|LAKES|LKS|#@#|LAND|LANDING|LNDG|LNDNG|#@#|LANE|LN|#@#|LIGHT|LGT|LIGHTS|LGTS|#@#|LOAF|LF|#@#|LOCK|LCK|LOCKS|LCKS|#@#|LODGE|LDG|LDGE|#@#|LOOP|LOOPS|#@#|MALL|#@#|MANOR|MNR|MANORS|MNRS|#@#|MEADOW|MDW|MEADOWS|MDWS|#@#|MEWS|#@#|MILL|ML|MILLS|MLS|#@#|MISSION|MISSN|MSN|MSSN|#@#|MOTORWAY|MTWY|#@#|MOUNT|MNT|MT|MOUNTAIN|MNTAIN|MTN|MNTN|MOUNTIN|MTIN|MOUNTAINS|MNTNS|MTNS|#@#|NECK|NCK|#@#|ORCHARD|ORCH|ORCHRD|#@#|OVAL|OVL|#@#|OVERPASS|OPAS|#@#|PARK|PRK|PARKS|#@#|PARKWAY|PARKWY|PKWAY|PKWY|PKY|PARKWAYS|PKWYS|#@#|PASS|PASSAGE|PSGE|#@#|#PATH#|#PATHS#|#@#|PIKE|PIKES|#@#|PINE|PNE|PINES|PNES|#@#|PLACE|PL|#@#|PLAIN|PLN|PLAINS|PLNS|#@#|PLAZA|PLZ|PLZA|#@#|#POINT#|PT|#POINTS#|PTS|#@#|PORT|PRT|PORTS|PRTS|#@#|PRAIRIE|PR|PRR|#@#|RADIAL|RAD|RADL|RADIEL|RADL|#@#|RAMP|#@#|RANCH|RNCH|RANCHES|RNCHS|#@#|RAPID|RPD|RAPIDS|RPDS|#@#|REST|RST|#@#|RIDGE|RDG|RDGE|RIDGES|RDGS|#@#|RIVER|RIV|RVR|RIVR|#@#|ROAD|RD|ROADS|RDS|#@#|ROUTE|RTE|#@#|ROW|#@#|RUE|#@#|#RUN#|#@#|SHOAL|SHL|SHL|SHOALS|SHLS|#@#|SHORE|SHOAR|SHR|SHORES|SHOARS|SHRS|#@#|SKYWAY|SKWY|#@#|SPRING|SPG|SPNG|SPRINGS|SPGS|SPNGS|#@#|SPUR|SPURS|#@#|SQUARE|SQ|SQR|SQRE|SQU|SQUARES|SQRS|#@#|STATION|STA|STATN|STN|#@#|STRAVENUE|STRA|STRAV|STRAVEN|STRAVN|STRVN|STRVNUE|#@#|STREAM|STRM|STREME|#@#|STREET|ST|STRT|STR|STREETS|STS|#@#|SUMMIT|SMT|SUMIT|SUMITT|SUMMIT|#@#|TERRACE|TER|TERR|#@#|THROUGHWAY|TRWY|#@#|TRACE|TRCE|TRACES|TRCE|#@#|TRACK|TRAK|TRACKS|TRAK|TRK|TRKS|#@#|TRAFFICWAY|TRFY|#@#|TRAIL|TRL|TRAILS|TRL|TRLS|#@#|TRAILER|TRLR|TRLRS|#@#|TUNNEL|TUNL|TUNLS|TUNNELS|TUNNL|#@#|TURNPIKE|TRNPK|TPKE|TURNPK|#@#|UNDERPASS|UPAS|#@#|UNION|UN|UNIONS|UNS|#@#|VALLEY|VLY|VALLY|VLLY|VLY|VALLEYS|VLYS|#@#|VIADUCT|VDCT|#VIA#|VIADCT|#@#|VIEW|VW|VIEWS|VWS|#@#|VILLAGE|VILL|VLG|VILLG|VILLIAGE|VILLAGES|VLGS|#@#|VILLE|VL|#@#|VISTA|VIS|VIST|VST|VSTA|#@#|#WALK#|#WALKS#|#@#|#WALL#|#@#|#WAY#|WY|#WAYS#|#@#|#WELL#|WL|WELLS|WLS|#@#)\\\\.?\\\\b\"\n",
    "\n",
    "# ------ Create filter 4: with key words of tweets about political -------#\n",
    "rgx_f4 = \"\\\\b(realDonaldTrump|Trump|DonaldTrump|BarackObama|Obama|Election|Election2016|vote|republicans|republican|democrats|democrat|GOP|dems|immigrant|immigrants|climate\\\\s?change|gas\\\\s?prices|ICE|buzzfeed(news)?|tedcruz|SenTedCruz)\\\\b\"\n",
    "# all tweets about ICE and buzzfeed are polical ones\n",
    "\n",
    "# ------ Create filter 5: with key words of tweets about offering helps -------#\n",
    "rgx_f5 = \"\\\\b(donate|donating|donated|donations|Charity|Charities|church|shelters?|sheltering|(we|I)\\\\s+can\\\\s+help|open\\\\s+for\\\\s+helps?|drop\\\\s+off|HELP\\\\sthe\\\\s#?AmericanRedCross)\\\\b\"\n",
    "\n",
    "# ------ Create filter 6: with key words of tweets about commercial -------#\n",
    "rgx_f6 = \"\\\\$\\\\d+(.\\\\d{0,2})?|\\\\$\\\\$+|\\\\b(sales|for\\\\ssale|dollors|hundreds?|thousands?|millions?|billions?|trillions?|[A-z]*market)\\\\b\"\n",
    "# 2 regex, one  for market; one for open;\n",
    "\n",
    "\n",
    "# ------ Create filter 7: with key words of tweets of newsreport -------#\n",
    "rgx_f7 = \"#BREAKING:\\\\s+|\\\\b(Press\\\\sConference|Live\\\\svideo\\\\sfeed|Live\\\\sStream|County\\\\sUpdate:|National\\\\s+Hurricane\\\\s+Center|Tropical\\\\s+Storm\\\\s+Harvey|MANDATORY\\\\s+EVACUATION|After\\\\s+Hurricane\\\\s+Harvey|Ahead\\\\s+of\\\\s+Hurricane\\\\s+Harvey|like\\\\s+a\\\\s+river|6\\\\s+mil\\\\s+people|High\\\\s+call\\\\s+volume|Epic\\\\s+flooding|cameras?|webcam|\\\\bFM\\\\s+\\\\d+|News\\\\s+in\\\\s+the\\\\s+#?DMV)\\\\b\"\n",
    "# SOS tweet not likely use \"Tropical Storm Harvey\" or \"National Hurricane Center\"\n",
    "# typically used by news\n",
    "\n",
    "\n",
    "# ------ Create filter 8: rescue status update --------------#\n",
    "rgx_f8 = \"-\\\\sAwaiting\\\\sUpdates?\\\\b|-\\\\sRescued!\\\\s|\\\\b(Ha(ve|s)\\\\sBeen\\\\sRescued)\\\\b\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>non_cleaned_text</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5667</th>\n",
       "      <td>If you want to figure out the road situation i...</td>\n",
       "      <td>want figure road situation area check harveyfl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>The Wall Street Journal: Houston flooding expe...</td>\n",
       "      <td>wall street journal houston flooding expected ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3312</th>\n",
       "      <td>@cinnamonfire8 oh and that white oak and houst...</td>\n",
       "      <td>cinnamonfire8 oh white oak houston ave floodin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5021</th>\n",
       "      <td>Guys, I'm south of the Conroe dam. Where is ev...</td>\n",
       "      <td>guys im south conroe dam everyone evacuating g...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5104</th>\n",
       "      <td>12:43pm.. flooding in Breaux Bridge (St. Marti...</td>\n",
       "      <td>1243pm flooding breaux bridge st martin parish...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Heavy Rain, Flooding Cause Concern Across Tamp...</td>\n",
       "      <td>heavy rain flooding cause concern across tampa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3755</th>\n",
       "      <td>The Wall Street Journal: Hurricane Harvey like...</td>\n",
       "      <td>wall street journal hurricane harvey likely sn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5438</th>\n",
       "      <td>Please DO NOT drive into the water if you can ...</td>\n",
       "      <td>please drive water see road please harvey</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5419</th>\n",
       "      <td>President Trump Tweets About 2016 Election and...</td>\n",
       "      <td>president trump tweets 2016 election border wa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194</th>\n",
       "      <td>@KHOUBlake11 #Houston: Dam opened, flooding do...</td>\n",
       "      <td>khoublake11 houston dam opened flooding downst...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4054 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       non_cleaned_text  \\\n",
       "5667  If you want to figure out the road situation i...   \n",
       "813   The Wall Street Journal: Houston flooding expe...   \n",
       "3312  @cinnamonfire8 oh and that white oak and houst...   \n",
       "5021  Guys, I'm south of the Conroe dam. Where is ev...   \n",
       "5104  12:43pm.. flooding in Breaux Bridge (St. Marti...   \n",
       "...                                                 ...   \n",
       "48    Heavy Rain, Flooding Cause Concern Across Tamp...   \n",
       "3755  The Wall Street Journal: Hurricane Harvey like...   \n",
       "5438  Please DO NOT drive into the water if you can ...   \n",
       "5419  President Trump Tweets About 2016 Election and...   \n",
       "1194  @KHOUBlake11 #Houston: Dam opened, flooding do...   \n",
       "\n",
       "                                                   text  label  \n",
       "5667  want figure road situation area check harveyfl...      0  \n",
       "813   wall street journal houston flooding expected ...      0  \n",
       "3312  cinnamonfire8 oh white oak houston ave floodin...      0  \n",
       "5021  guys im south conroe dam everyone evacuating g...      0  \n",
       "5104  1243pm flooding breaux bridge st martin parish...      0  \n",
       "...                                                 ...    ...  \n",
       "48    heavy rain flooding cause concern across tampa...      0  \n",
       "3755  wall street journal hurricane harvey likely sn...      0  \n",
       "5438          please drive water see road please harvey      0  \n",
       "5419  president trump tweets 2016 election border wa...      0  \n",
       "1194  khoublake11 houston dam opened flooding downst...      0  \n",
       "\n",
       "[4054 rows x 3 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>non_cleaned_text</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1094</th>\n",
       "      <td>Photos of flooding at Villas Dr./Golden Beach ...</td>\n",
       "      <td>photos flooding villas drgolden beach sent us ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1762</th>\n",
       "      <td>Hurricane Harvey videos | Fort Worth Star-Tele...</td>\n",
       "      <td>hurricane harvey videos fort worth startelegra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2034</th>\n",
       "      <td>11830 Greenspark Ln. - Awaiting Update. #Houst...</td>\n",
       "      <td>11830 greenspark ln awaiting update houston ha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2951</th>\n",
       "      <td>@ManBoobiees @LukeBryanSucks @klstorey Oh and ...</td>\n",
       "      <td>manboobiees lukebryansucks klstorey oh also ho...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5520</th>\n",
       "      <td>Guys, this storm is no joke ðŸ˜³#HurricaneHarvey ...</td>\n",
       "      <td>guys storm joke ðŸ˜³hurricaneharvey fl side effec...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4914</th>\n",
       "      <td>@jackmcme @matthaig1 Indeed, and sometimes dro...</td>\n",
       "      <td>jackmcme matthaig1 indeed sometimes drought fo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4737</th>\n",
       "      <td>My family is #blessed to have spent #Hurricane...</td>\n",
       "      <td>family blessed spent hurricaneharvey south for...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5435</th>\n",
       "      <td>HARVEY UPDATE: Williamson County officials mon...</td>\n",
       "      <td>harvey update williamson county officials moni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3007</th>\n",
       "      <td>Please continue to keep Houston in your though...</td>\n",
       "      <td>please continue keep houston thoughts amp pray...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>Houston, Texas freeway sign nearly submerged a...</td>\n",
       "      <td>houston texas freeway sign nearly submerged am...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1738 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       non_cleaned_text  \\\n",
       "1094  Photos of flooding at Villas Dr./Golden Beach ...   \n",
       "1762  Hurricane Harvey videos | Fort Worth Star-Tele...   \n",
       "2034  11830 Greenspark Ln. - Awaiting Update. #Houst...   \n",
       "2951  @ManBoobiees @LukeBryanSucks @klstorey Oh and ...   \n",
       "5520  Guys, this storm is no joke ðŸ˜³#HurricaneHarvey ...   \n",
       "...                                                 ...   \n",
       "4914  @jackmcme @matthaig1 Indeed, and sometimes dro...   \n",
       "4737  My family is #blessed to have spent #Hurricane...   \n",
       "5435  HARVEY UPDATE: Williamson County officials mon...   \n",
       "3007  Please continue to keep Houston in your though...   \n",
       "1258  Houston, Texas freeway sign nearly submerged a...   \n",
       "\n",
       "                                                   text  label  \n",
       "1094  photos flooding villas drgolden beach sent us ...      0  \n",
       "1762  hurricane harvey videos fort worth startelegra...      0  \n",
       "2034  11830 greenspark ln awaiting update houston ha...      0  \n",
       "2951  manboobiees lukebryansucks klstorey oh also ho...      0  \n",
       "5520  guys storm joke ðŸ˜³hurricaneharvey fl side effec...      0  \n",
       "...                                                 ...    ...  \n",
       "4914  jackmcme matthaig1 indeed sometimes drought fo...      0  \n",
       "4737  family blessed spent hurricaneharvey south for...      0  \n",
       "5435  harvey update williamson county officials moni...      0  \n",
       "3007  please continue keep houston thoughts amp pray...      0  \n",
       "1258  houston texas freeway sign nearly submerged am...      0  \n",
       "\n",
       "[1738 rows x 3 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_integrated = Train_X['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_integrated_non_cleaned = Train_X['non_cleaned_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_integrated = Test_X['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_integrated_non_cleaned = Test_X['non_cleaned_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logical_evaluation_address(x,y):\n",
    "    if x == 1:\n",
    "        if y == 0:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def logical_evaluation_final(x,y):\n",
    "    if x == 1:\n",
    "        if y == 0:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "train_logical_features = []\n",
    "for v1,v2 in zip(train_data_integrated.items(),train_data_integrated_non_cleaned.items()):    \n",
    "    if re.findall(rgx_f1_1,v1[1],re.IGNORECASE):\n",
    "        f1_1 =1\n",
    "    else:\n",
    "        f1_1=0\n",
    "        \n",
    "    if re.findall(rgx_f1_2,v1[1],re.IGNORECASE):\n",
    "        f1_2=1\n",
    "    else:\n",
    "        f1_2=0\n",
    "        \n",
    "    if extract_hash_tags(v2[1],ls_crisis_hashtags) == True:\n",
    "        f1_4 =1\n",
    "    else: \n",
    "        f1_4=0       \n",
    "        \n",
    "    if re.findall(rgx_f2,v1[1],re.IGNORECASE):\n",
    "        f2=1\n",
    "    else:\n",
    "        f2=0\n",
    "    \n",
    "    if re.findall(address_pattern,v1[1],re.IGNORECASE):\n",
    "        f3_1=1\n",
    "    else:\n",
    "        f3_1=0\n",
    "        \n",
    "    if re.findall(non_address_pattern,v1[1],re.IGNORECASE):\n",
    "        f3_2=1\n",
    "    else:\n",
    "        f3_2=0        \n",
    "        \n",
    "    if re.findall(rgx_f4,v1[1],re.IGNORECASE):\n",
    "        f4=1\n",
    "    else:\n",
    "        f4=0\n",
    "    \n",
    "    if re.findall(rgx_f5,v1[1],re.IGNORECASE):\n",
    "        f5=1\n",
    "    else:\n",
    "        f5=0\n",
    "    \n",
    "    if re.findall(rgx_f6,v1[1],re.IGNORECASE):\n",
    "        f6=1\n",
    "    else:\n",
    "        f6=0\n",
    "    \n",
    "    if re.findall(rgx_f7,v1[1],re.IGNORECASE):\n",
    "        f7=1\n",
    "    else:\n",
    "        f7=0\n",
    "     \n",
    "    if re.findall(rgx_f8,v1[1],re.IGNORECASE):\n",
    "        f8=1\n",
    "    else:\n",
    "        f8=0\n",
    "    \n",
    "    ## create a feature vector for training set ###\n",
    "    train_logical_features.append([f1_1,f1_2,f1_4,f2,f3_1,f3_2,f4,f5,f6,f7,f8])\n",
    "        \n",
    "test_logical_features = []\n",
    "for v1,v2 in zip(test_data_integrated.items(),test_data_integrated_non_cleaned.items()):      \n",
    "    \n",
    "    if re.findall(rgx_f1_1,v1[1],re.IGNORECASE):\n",
    "        f1_1 =1\n",
    "    else:\n",
    "        f1_1=0\n",
    "        \n",
    "    if re.findall(rgx_f1_2,v1[1],re.IGNORECASE):\n",
    "        f1_2=1\n",
    "    else:\n",
    "        f1_2=0\n",
    "        \n",
    "    if extract_hash_tags(v2[1],ls_crisis_hashtags) == True:\n",
    "        f1_4 =1\n",
    "    else: \n",
    "        f1_4=0     \n",
    "        \n",
    "        \n",
    "    if re.findall(rgx_f2,v1[1],re.IGNORECASE):\n",
    "        f2=1\n",
    "    else:\n",
    "        f2=0\n",
    "    \n",
    "    if re.findall(address_pattern,v1[1],re.IGNORECASE):\n",
    "        f3_1=1\n",
    "    else:\n",
    "        f3_1=0\n",
    "        \n",
    "    if re.findall(non_address_pattern,v1[1],re.IGNORECASE):\n",
    "        f3_2=1\n",
    "    else:\n",
    "        f3_2=0        \n",
    "        \n",
    "    if re.findall(rgx_f4,v1[1],re.IGNORECASE):\n",
    "        f4=1\n",
    "    else:\n",
    "        f4=0\n",
    "    \n",
    "    if re.findall(rgx_f5,v1[1],re.IGNORECASE):\n",
    "        f5=1\n",
    "    else:\n",
    "        f5=0\n",
    "    \n",
    "    if re.findall(rgx_f6,v1[1],re.IGNORECASE):\n",
    "        f6=1\n",
    "    else:\n",
    "        f6=0\n",
    "    \n",
    "    if re.findall(rgx_f7,v1[1],re.IGNORECASE):\n",
    "        f7=1\n",
    "    else:\n",
    "        f7=0\n",
    "     \n",
    "    if re.findall(rgx_f8,v1[1],re.IGNORECASE):\n",
    "        f8=1\n",
    "    else:\n",
    "        f8=0\n",
    "    \n",
    "    ## create test feature vector ###\n",
    "    test_logical_features.append([f1_1,f1_2,f1_4,f2,f3_1,f3_2,f4,f5,f6,f7,f8])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length logical train features... 4054\n",
      "Length logical test features... 1738\n"
     ]
    }
   ],
   "source": [
    "###### calculate logical feature vectors #########\n",
    "print('Length logical train features...',len(train_logical_features))\n",
    "print('Length logical test features...',len(test_logical_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wkhal001/envs/Twitter_crisis/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2143: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert embedding train shape torch.Size([4054, 36, 13, 768])\n",
      "Bert embedding test shape torch.Size([1738, 36, 13, 768])\n",
      "4054\n",
      "1738\n"
     ]
    }
   ],
   "source": [
    "###### Use BERT for feature extraction #########\n",
    "import transformers\n",
    "from transformers import AutoModel, BertTokenizerFast, BertModel, BertTokenizer\n",
    "\n",
    "###### Run BERT to get the train and test feature vectors ######\n",
    "bert = BertModel.from_pretrained('bert-base-uncased',output_hidden_states = True)    \n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "max_seq= 36\n",
    "\n",
    "###### vectorize text using BERT          \n",
    "max_seq_len = max_seq  \n",
    "#tokenize and encode sequences in the training set\n",
    "tokens_train = tokenizer.batch_encode_plus(\n",
    "        Train_X['text'].tolist(),\n",
    "        max_length = max_seq_len,\n",
    "        pad_to_max_length=True,\n",
    "        truncation=True,\n",
    "        return_token_type_ids=False\n",
    "    )\n",
    "        \n",
    "# tokenize and encode sequences in the validation set\n",
    "tokens_test = tokenizer.batch_encode_plus(\n",
    "        Test_X['text'].tolist(),\n",
    "        max_length = max_seq_len,\n",
    "        pad_to_max_length=True,\n",
    "        truncation=True,\n",
    "        return_token_type_ids=False\n",
    "    )                                                                \n",
    "        \n",
    "# for train set\n",
    "train_seq = torch.tensor(tokens_train['input_ids'])\n",
    "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
    "train_y = torch.tensor(Train_Y.tolist())\n",
    "\n",
    "# for validation set\n",
    "test_seq = torch.tensor(tokens_test['input_ids'])\n",
    "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
    "test_y = torch.tensor(Test_Y.tolist())\n",
    "    \n",
    "bert.eval()\n",
    "    \n",
    "with torch.no_grad():\n",
    "    outputs = bert(train_seq,train_mask)\n",
    "    hidden_states = outputs[2]\n",
    "    \n",
    "    \n",
    "with torch.no_grad():\n",
    "    outputs_test = bert(test_seq,test_mask)\n",
    "    hidden_states_test = outputs_test[2]\n",
    "        \n",
    "        \n",
    "token_embeddings = torch.stack(hidden_states, dim=0)\n",
    "token_embeddings = token_embeddings.permute(1,2,0,3)\n",
    "    \n",
    "token_embeddings_test = torch.stack(hidden_states_test, dim=0)\n",
    "token_embeddings_test = token_embeddings_test.permute(1,2,0,3)\n",
    "    \n",
    "print('Bert embedding train shape',token_embeddings.size())\n",
    "print('Bert embedding test shape',token_embeddings_test.size())\n",
    "    \n",
    "    \n",
    "#### add the word vectors of the last 4 layers -- each token is concatenated in 3072 length vector    \n",
    "Train_bert_classifier = []\n",
    "for input_tweet in token_embeddings: \n",
    "    token_vecs_cat = []\n",
    "    for token in input_tweet:\n",
    "        cat_vec = torch.cat((token[-1], token[-2], token[-3], token[-4]), dim=0)   # 4 last hidden layers\n",
    "        #cat_vec = torch.sum(torch.stack([token[-1],token[-2],token[-3],token[-4]]), dim = 0)           # summing the 4 last hidden layers\n",
    "        # cat_vec = token[-1]\n",
    "        token_vecs_cat.append(cat_vec)\n",
    "        \n",
    "    Train_bert_classifier.append(token_vecs_cat[0])\n",
    "        \n",
    "Test_bert_classifier = []\n",
    "for input_tweet in token_embeddings_test: \n",
    "    token_vecs_cat = []\n",
    "    for token in input_tweet:\n",
    "        cat_vec_t = torch.cat((token[-1], token[-2], token[-3], token[-4]), dim=0)\n",
    "        #cat_vec_t = torch.sum(torch.stack([token[-1],token[-2],token[-3],token[-4]]), dim = 0)           # summing the 4 last hidden layers\n",
    "        #cat_vec_t = token[-1]\n",
    "        token_vecs_cat.append(cat_vec_t)\n",
    "        \n",
    "    Test_bert_classifier.append(token_vecs_cat[0])\n",
    "    \n",
    "print(len(Train_bert_classifier))\n",
    "print(len(Test_bert_classifier))\n",
    "    \n",
    "#### convert train and test data tensors into numpy array\n",
    "ls_input_train = [e.numpy() for e in Train_bert_classifier]\n",
    "ls_input_test = [e.numpy() for e in Test_bert_classifier]  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers.merge import concatenate\n",
    "\n",
    "#### create Keras neural network with both inputs ###\n",
    "input_bert = Input(shape=(3072,))\n",
    "input_logical = Input(shape=(11,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the first branch operates on the first input\n",
    "x = Dense(64, activation=\"relu\")(input_bert)\n",
    "#x = Dense(5, activation=\"relu\")(x)\n",
    "x = Model(inputs=input_bert, outputs=x)\n",
    "\n",
    "# the second branch opreates on the second input\n",
    "y = Dense(10, activation=\"relu\")(input_logical)\n",
    "y = Dense(5, activation=\"relu\")(y)\n",
    "y = Model(inputs=input_logical, outputs=y)\n",
    "\n",
    "# combine the output of the two branches\n",
    "combined = concatenate([x.output, y.output])\n",
    "\n",
    "# apply a FC layer and then a regression prediction on the\n",
    "# combined outputs\n",
    "z = Dense(2, activation=\"softmax\")(combined)\n",
    "\n",
    "# our model will accept the inputs of the two branches and then output a single value\n",
    "model = Model(inputs=[x.input, y.input], outputs=z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hybrid_model(): \n",
    "    # the first branch operates on the first input\n",
    "    x = Dense(64, activation=\"relu\")(input_bert)\n",
    "    #x = Dense(5, activation=\"relu\")(x)\n",
    "    x = Model(inputs=input_bert, outputs=x)\n",
    "\n",
    "    # the second branch opreates on the second input\n",
    "    y = Dense(10, activation=\"relu\")(input_logical)\n",
    "    y = Dense(5, activation=\"relu\")(y)\n",
    "    y = Model(inputs=input_logical, outputs=y)\n",
    "\n",
    "    # combine the output of the two branches\n",
    "    combined = concatenate([x.output, y.output])\n",
    "\n",
    "    # apply a FC layer and then a regression prediction on the\n",
    "    # combined outputs\n",
    "    z = Dense(2, activation=\"softmax\")(combined)\n",
    "\n",
    "    # our model will accept the inputs of the two branches and then output a single value\n",
    "    model = Model(inputs=[x.input, y.input], outputs=z)\n",
    "    \n",
    "    return(model)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 11)]         0           []                               \n",
      "                                                                                                  \n",
      " input_1 (InputLayer)           [(None, 3072)]       0           []                               \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 10)           120         ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 64)           196672      ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 5)            55          ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 69)           0           ['dense[0][0]',                  \n",
      "                                                                  'dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 2)            140         ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 196,987\n",
      "Trainable params: 196,987\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------- iteration  1 ----------------------\n",
      "{'0': {'precision': 0.9928057553956835, 'recall': 0.9963898916967509, 'f1-score': 0.9945945945945946, 'support': 1662}, '1': {'precision': 0.9142857142857143, 'recall': 0.8421052631578947, 'f1-score': 0.8767123287671234, 'support': 76}, 'accuracy': 0.9896432681242808, 'macro avg': {'precision': 0.9535457348406988, 'recall': 0.9192475774273228, 'f1-score': 0.9356534616808589, 'support': 1738}, 'weighted avg': {'precision': 0.989372197786732, 'recall': 0.9896432681242808, 'f1-score': 0.9894397889542679, 'support': 1738}}\n",
      "F1 score (class 1).... 0.8767123287671234\n",
      "------------------------------------------------------------------\n",
      "------------- iteration  2 ----------------------\n",
      "{'0': {'precision': 0.9934052757793765, 'recall': 0.9969915764139591, 'f1-score': 0.9951951951951953, 'support': 1662}, '1': {'precision': 0.9285714285714286, 'recall': 0.8552631578947368, 'f1-score': 0.8904109589041096, 'support': 76}, 'accuracy': 0.9907940161104718, 'macro avg': {'precision': 0.9609883521754026, 'recall': 0.926127367154348, 'f1-score': 0.9428030770496525, 'support': 1738}, 'weighted avg': {'precision': 0.9905701938531373, 'recall': 0.9907940161104718, 'f1-score': 0.9906131457371271, 'support': 1738}}\n",
      "F1 score (class 1).... 0.8904109589041096\n",
      "------------------------------------------------------------------\n",
      "------------- iteration  3 ----------------------\n",
      "{'0': {'precision': 0.9857397504456328, 'recall': 0.9981949458483754, 'f1-score': 0.9919282511210762, 'support': 1662}, '1': {'precision': 0.9454545454545454, 'recall': 0.6842105263157895, 'f1-score': 0.7938931297709924, 'support': 76}, 'accuracy': 0.9844649021864211, 'macro avg': {'precision': 0.9655971479500891, 'recall': 0.8412027360820824, 'f1-score': 0.8929106904460342, 'support': 1738}, 'weighted avg': {'precision': 0.9839781419419948, 'recall': 0.9844649021864211, 'f1-score': 0.9832684874717055, 'support': 1738}}\n",
      "F1 score (class 1).... 0.7938931297709924\n",
      "------------------------------------------------------------------\n",
      "------------- iteration  4 ----------------------\n",
      "{'0': {'precision': 0.9922062350119905, 'recall': 0.9957882069795427, 'f1-score': 0.993993993993994, 'support': 1662}, '1': {'precision': 0.9, 'recall': 0.8289473684210527, 'f1-score': 0.8630136986301371, 'support': 76}, 'accuracy': 0.9884925201380897, 'macro avg': {'precision': 0.9461031175059953, 'recall': 0.9123677877002977, 'f1-score': 0.9285038463120656, 'support': 1738}, 'weighted avg': {'precision': 0.988174201720327, 'recall': 0.9884925201380897, 'f1-score': 0.9882664321714087, 'support': 1738}}\n",
      "F1 score (class 1).... 0.8630136986301371\n",
      "------------------------------------------------------------------\n",
      "------------- iteration  5 ----------------------\n",
      "{'0': {'precision': 0.9939975990396158, 'recall': 0.9963898916967509, 'f1-score': 0.9951923076923076, 'support': 1662}, '1': {'precision': 0.9166666666666666, 'recall': 0.868421052631579, 'f1-score': 0.8918918918918918, 'support': 76}, 'accuracy': 0.9907940161104718, 'macro avg': {'precision': 0.9553321328531412, 'recall': 0.9324054721641649, 'f1-score': 0.9435420997920997, 'support': 1738}, 'weighted avg': {'precision': 0.9906160392810749, 'recall': 0.9907940161104718, 'f1-score': 0.9906751433650167, 'support': 1738}}\n",
      "F1 score (class 1).... 0.8918918918918918\n",
      "------------------------------------------------------------------\n",
      "------------- iteration  6 ----------------------\n",
      "{'0': {'precision': 0.9928100659077291, 'recall': 0.9969915764139591, 'f1-score': 0.9948964274992494, 'support': 1662}, '1': {'precision': 0.927536231884058, 'recall': 0.8421052631578947, 'f1-score': 0.882758620689655, 'support': 76}, 'accuracy': 0.9902186421173763, 'macro avg': {'precision': 0.9601731488958936, 'recall': 0.9195484197859269, 'f1-score': 0.9388275240944522, 'support': 1738}, 'weighted avg': {'precision': 0.9899557440516884, 'recall': 0.9902186421173763, 'f1-score': 0.9899928179954928, 'support': 1738}}\n",
      "F1 score (class 1).... 0.882758620689655\n",
      "------------------------------------------------------------------\n",
      "------------- iteration  7 ----------------------\n",
      "{'0': {'precision': 0.9939903846153846, 'recall': 0.9951865222623345, 'f1-score': 0.9945880938063739, 'support': 1662}, '1': {'precision': 0.8918918918918919, 'recall': 0.868421052631579, 'f1-score': 0.88, 'support': 76}, 'accuracy': 0.9896432681242808, 'macro avg': {'precision': 0.9429411382536382, 'recall': 0.9318037874469567, 'f1-score': 0.937294046903187, 'support': 1738}, 'weighted avg': {'precision': 0.989525778489386, 'recall': 0.9896432681242808, 'f1-score': 0.9895773371151861, 'support': 1738}}\n",
      "F1 score (class 1).... 0.88\n",
      "------------------------------------------------------------------\n",
      "------------- iteration  8 ----------------------\n",
      "{'0': {'precision': 0.9933774834437086, 'recall': 0.9927797833935018, 'f1-score': 0.9930785434848028, 'support': 1662}, '1': {'precision': 0.8441558441558441, 'recall': 0.8552631578947368, 'f1-score': 0.8496732026143792, 'support': 76}, 'accuracy': 0.9867663981588032, 'macro avg': {'precision': 0.9187666637997763, 'recall': 0.9240214706441193, 'f1-score': 0.921375873049591, 'support': 1738}, 'weighted avg': {'precision': 0.9868522564092566, 'recall': 0.9867663981588032, 'f1-score': 0.9868076540106071, 'support': 1738}}\n",
      "F1 score (class 1).... 0.8496732026143792\n",
      "------------------------------------------------------------------\n",
      "------------- iteration  9 ----------------------\n",
      "{'0': {'precision': 0.9933894230769231, 'recall': 0.9945848375451264, 'f1-score': 0.9939867708959711, 'support': 1662}, '1': {'precision': 0.8783783783783784, 'recall': 0.8552631578947368, 'f1-score': 0.8666666666666667, 'support': 76}, 'accuracy': 0.9884925201380897, 'macro avg': {'precision': 0.9358839007276507, 'recall': 0.9249239977199316, 'f1-score': 0.9303267187813189, 'support': 1738}, 'weighted avg': {'precision': 0.9883601714100132, 'recall': 0.9884925201380897, 'f1-score': 0.9884192634613179, 'support': 1738}}\n",
      "F1 score (class 1).... 0.8666666666666667\n",
      "------------------------------------------------------------------\n",
      "------------- iteration  10 ----------------------\n",
      "{'0': {'precision': 0.9928014397120576, 'recall': 0.9957882069795427, 'f1-score': 0.9942925803544608, 'support': 1662}, '1': {'precision': 0.9014084507042254, 'recall': 0.8421052631578947, 'f1-score': 0.8707482993197279, 'support': 76}, 'accuracy': 0.9890678941311852, 'macro avg': {'precision': 0.9471049452081415, 'recall': 0.9189467350687187, 'f1-score': 0.9325204398370943, 'support': 1738}, 'weighted avg': {'precision': 0.9888049683860535, 'recall': 0.9890678941311852, 'f1-score': 0.9888901837154276, 'support': 1738}}\n",
      "F1 score (class 1).... 0.8707482993197279\n",
      "------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "########## run the model multiple times #########\n",
    "nb_reps = 10\n",
    "save_results = {'f1':[],'recall':[],'precision':[]}\n",
    "\n",
    "iteration = 1\n",
    "for i in range(nb_reps): \n",
    "    print('------------- iteration ',str(iteration),'----------------------')\n",
    "    iteration = iteration + 1\n",
    "    model =create_hybrid_model()\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(0.001),\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(), #BinaryCrossentropy(), SparseCategoricalCrossentropy() #keras.losses.SparseCategoricalCrossentropy()\n",
    "        metrics=[keras.metrics.SparseCategoricalCrossentropy()], #keras.metrics.SparseCategoricalAccuracy()\n",
    "    )\n",
    "    \n",
    "    Train_hybrid_bert = np.array(ls_input_train)\n",
    "    Train_hybrid_logical = np.array(train_logical_features)\n",
    "    Train_hybrid_Y = np.array(Train_Y)\n",
    "\n",
    "    history = model.fit(x=[Train_hybrid_bert,Train_hybrid_logical], y=Train_hybrid_Y, batch_size=8, epochs=100,verbose=0) \n",
    "    \n",
    "    Test_hybrid_bert = np.array(ls_input_test)\n",
    "    Test_hybrid_logical = np.array(test_logical_features)\n",
    "    Test_hybrid_Y = np.array(Test_Y)\n",
    "\n",
    "    predictions = model.predict([Test_hybrid_bert,Test_hybrid_logical])\n",
    "    preds = np.argmax(predictions, axis=1)\n",
    "    dict_r = classification_report(Test_Y, preds, output_dict = True)\n",
    "    print(dict_r)\n",
    "\n",
    "    f1 = f1_score(Test_hybrid_Y, preds, average='binary')    \n",
    "    print('F1 score (class 1)....',f1)\n",
    "    \n",
    "    save_results['f1'].append(dict_r['1']['f1-score'])\n",
    "    save_results['recall'].append(dict_r['1']['recall']) \n",
    "    save_results['precision'].append(dict_r['1']['precision'])\n",
    "    \n",
    "    print('------------------------------------------------------------------')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(\n",
    "#         optimizer=keras.optimizers.Adam(0.001),\n",
    "#         loss=keras.losses.SparseCategoricalCrossentropy(), #BinaryCrossentropy(), SparseCategoricalCrossentropy() #keras.losses.SparseCategoricalCrossentropy()\n",
    "#         metrics=[keras.metrics.SparseCategoricalCrossentropy()], #keras.metrics.SparseCategoricalAccuracy()\n",
    "#     )\n",
    "\n",
    "# Train_hybrid_bert = np.array(ls_input_train)\n",
    "# Train_hybrid_logical = np.array(train_logical_features)\n",
    "# Train_hybrid_Y = np.array(Train_Y)\n",
    "\n",
    "# history = model.fit(x=[Train_hybrid_bert,Train_hybrid_logical], y=Train_hybrid_Y, batch_size=16, epochs=50,verbose=2) \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_f1 = [0.8767,0.8904,0.7938,0.8630,0.8918,0.8827,0.88,0.8496,0.8666,0.8707]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8767, 0.8904, 0.7938, 0.863, 0.8918, 0.8827, 0.88, 0.8496, 0.8666, 0.8707]\n"
     ]
    }
   ],
   "source": [
    "print(ls_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average (10 runs)  0.86653\n",
      "stdev (10 runs)  0.028598409046658543\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "\n",
    "print('average (10 runs) ',statistics.mean(ls_f1))\n",
    "print('stdev (10 runs) ',statistics.stdev(ls_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_precision = [0.9142,0.9285,0.9454,0.9,0.9166,0.9275,0.8918,0.8441,0.8783,0.9014]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average (10 runs)  0.90478\n",
      "stdev (10 runs)  0.028950678364725382\n",
      "max (10 runs)  0.9454\n",
      "min (10 runs)  0.8441\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "\n",
    "print('average (10 runs) ',statistics.mean(ls_precision))\n",
    "print('stdev (10 runs) ',statistics.stdev(ls_precision))\n",
    "print('max (10 runs) ',max(ls_precision))\n",
    "print('min (10 runs) ',min(ls_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_recall = [0.8421,0.8552,0.6842,0.8289,0.8684,0.8421,0.8684,0.8552,0.8552,0.8421]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average (10 runs)  0.8341799999999999\n",
      "stdev (10 runs)  0.05413726997180406\n",
      "max (10 runs)  0.8684\n",
      "min (10 runs)  0.6842\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "\n",
    "print('average (10 runs) ',statistics.mean(ls_recall))\n",
    "print('stdev (10 runs) ',statistics.stdev(ls_recall))\n",
    "print('max (10 runs) ',max(ls_recall))\n",
    "print('min (10 runs) ',min(ls_recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score (class 1).... 0.8689655172413793\n"
     ]
    }
   ],
   "source": [
    "Test_hybrid_bert = np.array(ls_input_test)\n",
    "Test_hybrid_logical = np.array(test_logical_features)\n",
    "\n",
    "Test_hybrid_Y = np.array(Test_Y)\n",
    "\n",
    "predictions = model.predict([Test_hybrid_bert,Test_hybrid_logical])\n",
    "preds = np.argmax(predictions, axis=1)\n",
    "\n",
    "f1 = f1_score(Test_hybrid_Y, preds, average='binary')    \n",
    "score = f1\n",
    "\n",
    "print('F1 score (class 1)....',score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 0.9922109047333733,\n",
       "  'recall': 0.9963898916967509,\n",
       "  'f1-score': 0.9942960072050435,\n",
       "  'support': 1662},\n",
       " '1': {'precision': 0.9130434782608695,\n",
       "  'recall': 0.8289473684210527,\n",
       "  'f1-score': 0.8689655172413793,\n",
       "  'support': 76},\n",
       " 'accuracy': 0.9890678941311852,\n",
       " 'macro avg': {'precision': 0.9526271914971214,\n",
       "  'recall': 0.9126686300589018,\n",
       "  'f1-score': 0.9316307622232114,\n",
       "  'support': 1738},\n",
       " 'weighted avg': {'precision': 0.9887490379831372,\n",
       "  'recall': 0.9890678941311852,\n",
       "  'f1-score': 0.9888155024655507,\n",
       "  'support': 1738}}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### print scores ######\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "dict_r = classification_report(Test_Y, preds, output_dict = True)\n",
    "dict_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
