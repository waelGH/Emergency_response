{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code template for using logical features for tweets emergency rescue requests identification\n",
    "### Created by: Wael Khallouli\n",
    "### Paper: intelligent agent..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "############### Imports ################################\n",
    "########################################################\n",
    "from string import punctuation\n",
    "from os import listdir\n",
    "from numpy import array\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import string\n",
    "\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "### imports (1) ##\n",
    "import pandas as pd\n",
    "import numpy as pn\n",
    "from numpy import mean\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import string\n",
    "\n",
    "import collections\n",
    "from collections import Counter\n",
    "\n",
    "### imports (2) ##\n",
    "from string import punctuation\n",
    "from os import listdir\n",
    "from numpy import array\n",
    "\n",
    "from pickle import load\n",
    "from numpy import array\n",
    "\n",
    "\n",
    "### imports (4) ##\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers.merge import concatenate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from Baseline_Models import Display_metrics,Display_classification_report,Confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, f1_score, matthews_corrcoef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Read Harvey data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wkhal001/envs/Twitter_crisis/lib/python3.7/site-packages/ipykernel_launcher.py:10: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "########################################################\n",
    "############### Read data ##############################\n",
    "########################################################\n",
    "file_path = '/home/wkhal001/Desktop/data_rescue_mining/labeled_ds_Corrected_csv.csv'\n",
    "\n",
    "### Read data set \n",
    "labeledDF=pd.read_csv(file_path) \n",
    "\n",
    "#labeledDF.drop(['id','Unnamed: 0','loc','situ','save','sos','address','sos.pred'],1)\n",
    "labeledDF = labeledDF.drop(['id','Unnamed: 0','loc','situ','save','sos','address','sos.pred'],1)\n",
    "\n",
    "Training_set = labeledDF[['text','sos.correct']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sos.correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#Harvey floods TV station #KHOU in #Houston. h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@RandiRhodes RR call him out for visiting SA, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wow a tv station is flooding in Houston! So sc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My son, dil &amp;amp; 2 grandkids in grand lakes, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>is the beltway still flooded? ya boy need to g...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5787</th>\n",
       "      <td>Around 10,000,000,000,000 gallons of water fro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5788</th>\n",
       "      <td>The road to my residence is flooded. Thank God...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5789</th>\n",
       "      <td>Texas road closures and flooding kept up to da...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5790</th>\n",
       "      <td>@HellerWeather Tim, any maps to show where flo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5791</th>\n",
       "      <td>lrt more people died on the road trying to eva...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5792 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  sos.correct\n",
       "0     #Harvey floods TV station #KHOU in #Houston. h...            0\n",
       "1     @RandiRhodes RR call him out for visiting SA, ...            0\n",
       "2     Wow a tv station is flooding in Houston! So sc...            0\n",
       "3     My son, dil &amp; 2 grandkids in grand lakes, ...            0\n",
       "4     is the beltway still flooded? ya boy need to g...            0\n",
       "...                                                 ...          ...\n",
       "5787  Around 10,000,000,000,000 gallons of water fro...            0\n",
       "5788  The road to my residence is flooded. Thank God...            0\n",
       "5789  Texas road closures and flooding kept up to da...            0\n",
       "5790  @HellerWeather Tim, any maps to show where flo...            0\n",
       "5791  lrt more people died on the road trying to eva...            0\n",
       "\n",
       "[5792 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "Training_set_positives = Training_set[Training_set['sos.correct'] ==  1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sos.correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Urgently need #WaterRescue at 10415 Merry Mead...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Folks looking for boat assistance near - Hardy...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>@houstonpolice please help my sister !! üôèüèªüôèüèª#h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Elderly Frank Emmitte trapped in 3226 Ave G, D...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Grant rd &amp;amp; lake wood forest in houston. ne...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5166</th>\n",
       "      <td>@L0stSandal 777 Coolwood Dr Houston 8 Wk son n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5167</th>\n",
       "      <td>.@houstonpolice help needed in 4055 South Brae...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5177</th>\n",
       "      <td>Please help my mother-in-law: a cancer patient...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5197</th>\n",
       "      <td>@HarveyRescue @HarveyRelief #HARVEY SOS: 2121 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5601</th>\n",
       "      <td>Anyone with small boats over near norchester o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>253 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  sos.correct\n",
       "30    Urgently need #WaterRescue at 10415 Merry Mead...            1\n",
       "42    Folks looking for boat assistance near - Hardy...            1\n",
       "52    @houstonpolice please help my sister !! üôèüèªüôèüèª#h...            1\n",
       "70    Elderly Frank Emmitte trapped in 3226 Ave G, D...            1\n",
       "86    Grant rd &amp; lake wood forest in houston. ne...            1\n",
       "...                                                 ...          ...\n",
       "5166  @L0stSandal 777 Coolwood Dr Houston 8 Wk son n...            1\n",
       "5167  .@houstonpolice help needed in 4055 South Brae...            1\n",
       "5177  Please help my mother-in-law: a cancer patient...            1\n",
       "5197  @HarveyRescue @HarveyRelief #HARVEY SOS: 2121 ...            1\n",
       "5601  Anyone with small boats over near norchester o...            1\n",
       "\n",
       "[253 rows x 2 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Training_set_positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wkhal001/envs/Twitter_crisis/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "Training_set['f1_1'] = 0\n",
    "Training_set['f1_2'] = 0\n",
    "Training_set['f2'] = 0\n",
    "Training_set['f3_1'] = 0\n",
    "Training_set['f3_2'] = 0\n",
    "Training_set['f4'] = 0\n",
    "Training_set['f5'] = 0\n",
    "Training_set['f6'] = 0\n",
    "Training_set['f7'] = 0\n",
    "Training_set['f8'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text', 'sos.correct', 'f1_1', 'f1_2', 'f2', 'f3_1', 'f3_2', 'f4', 'f5',\n",
       "       'f6', 'f7', 'f8'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Training_set.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Logical Approach: filer data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------  Create filter 1 ---------------------------------------#\n",
    "# Feature 1.1 keywords with hurricane/flood\n",
    "rgx_f1_1 = \"\\\\b(Hurricane|HurricaneHarvey|Harvey2017|HARVEYHELP|HarveyStorm|harveyhouston|houstonflood|houstonfloods|houstonflooding|texasflood|texasfloods|texasflooding|harveyflood|harveyflooding|HurricaneFlood|HurricaneSOS)\\\\b\"\n",
    "\n",
    "# Feature 1.2 keywords with situation descriptions\n",
    "rgx_f1_2 = \"\\\\b(stranded|stuck|trapped|traps?|trapping|roofs?|rooftop|injured|hurt)\\\\b\"\n",
    "\n",
    "# Feature 1.3: contain both the following two keyword groups (ignore case):\n",
    "# group 1: names of cities and towns near Houston\n",
    "# group 2: flood related keywords. e.g. flood, flooding\n",
    "rgx_f1_3a = \"\\\\b(Houston|Texas|Galveston|Lake\\\\sJackson|Pasadena|League\\\\sCity|DICKINSON|Pearland|Missouri\\\\sCity|Sugar\\\\sLand|Richmond|Rosenberg|Alvin|Baytown|Fresno|Mont\\\\sBelvieu|Humble|Woodlands|Spring|Tomball|Cypress|Brookshire\\\\sKaty|FRIENDSWOOD)\\\\b\"\n",
    "rgx_f1_3b = \"\\\\b(flood|floods|flooding|flooded)\\\\b\"\n",
    "\n",
    "#------------------ Create filter 2: Requesting rescue ------------------------#\n",
    "rgx_f2 = \"\\\\b(rescue|rescues|rescuing|rescued|helps?|helping|WaterRescue|WaterRescueNeeded|aid|assistance|boats?|HarveyRescue|HarveySOS|HurricaneRescue|FloodRescue|HurricaneSOS|HarveyRelief)\\\\b\"\n",
    "\n",
    "# ------ Create filter 3: address description-----------------------------------#\n",
    "address_pattern = \"(\\\\b\\\\d+\\\\s+(#?[A-z]+\\\\.?(-[A-z]+)?\\\\s+){1,3}\\\\b(#@#|ANNEX|ANEX|ANNX|ANX|#@#|ARCADE|ARC|#@#|AVENUE|AV|AVE|AVEN|AVENU|AVN|AVNUE|#@#|BAYOU|BAYOO|BYU|BAYOU|#@#|BEACH|BCH|BEACH|#@#|BEND|BND|#@#|BLUFF|BLF|BLUF|BLUFFS|BLFS|#@#|BOTTOM|BOT|BTM|BOTTM|#@#|BOULEVARD|BLVD|BOUL|BOULV|#@#|BRANCH|BR|BRNCH|#@#|BRIDGE|BRDGE|BRG|#@#|BROOK|BRK|BROOKS|BRKS|#@#|BURG|BG|BURGS|BGS|#@#|BYPASS|BYP|BYPA|BYPAS|BYPS|#@#|CAMP|CP|CMP|#@#|CANYON|CANYN|CYN|CNYN|#@#|CAPE|CPE|#@#|CAUSEWAY|CSWY|CAUSWA|CSWY|#@#|CENTER|CEN|CTR|CENT|CENTR|CENTRE|CNTER|CNTR|CENTERS|CTRS|#@#|CIRCLE|CIR|CIRC|CIRCL|CRCL|CRCLE|CIRCLES|CIRS|#@#|CLIFF|CLF|CLIFFS|CLFS|CLIFFS|#@#|CLUB|CLB|#@#|COMMON|CMN|COMMONS|CMNS|#@#|CORNER|COR|CORNERS|CORS|#@#|COURSE|CRSE|#@#|COURT|CT|COURTS|CTS|#@#|COVE|CV|COVES|COVES|CVS|#@#|CREEK|CRK|#@#|CRESCENT|CRES|CRSENT|CRSNT|CREST|CRST|CR|#@#|CROSSING|CRSSNG|XING|#@#|CROSSROAD|XRD|CROSSROADS|XRDS|#@#|CURVE|CURV|#@#|DALE|DL|#@#|#DAM#|#DM#|#@#|DIVIDE|DIV|DV|DIVIDE|DVD|#@#|DRIVE|DR|DRIV|DRV|DRIVES|DRS|#@#|ESTATE|EST|ESTATES|ESTS|#@#|EXPRESSWAY|EXP|EXPY|EXPR|EXPRESS|EXPW|#@#|EXTENSION|EXT|EXTN|EXTNSN|EXTENSIONS|EXTS|#@#|FALL|FALLS|FLS|#@#|FERRY|FRY|FRRY|FRY|#@#|FIELD|FLD|FIELDS|FLDS|#@#|FLAT|FLT|FLATS|FLTS|#@#|FORD|FRD|FORDS|FRDS|#@#|FOREST|FRST|FORESTS|FRST|#@#|FORGE|FORG|FRG|FORGES|FRGS|#@#|FORK|FRK|FORKS|FRKS|#@#|FORT|FT|FRT|#@#|FREEWAY|FWY|FREEWY|FRWAY|FRWY|FWY|#@#|GARDEN|GDN|GRDN|GARDENS|GDNS|GRDNS|#@#|GATEWAY|GTWY|GATEWY|GATWAY|GTWAY|GTWY|#@#|GLEN|GLN|GLENS|GLNS|#@#|GREEN|GRN|GREENS|GRNS|#@#|GROVE|GROV|GRV|GROVES|GRVS|#@#|HARBOR|HARB|HBR|HARBR|HRBOR|HARBORS|HBRS|#@#|HAVEN|HVN|#@#|HEIGHTS|HT|HTS|#@#|HIGHWAY|HWY|HIWAY|HIWY|HWAY|HWY|#@#|HILL|HL|HILLS|HLS|#@#|HOLLOW|HLLW|HOLW|HOLLOWS|HOLWS|#@#|INLET|INLT|#@#|ISLAND|#IS#|ISLND|ISLANDS|ISS|ISLNDS|#@#|ISLE|ISLES|#@#|JUNCTION|JCT|JCTION|JCTN|JUNCTN|JUNCTON|JUNCTIONS|JCTNS|JCTS|JUNCTIONS|#@#|KEY|KY|KEYS|KYS|#@#|KNOLL|KNL|KNOL|KNOLLS|KNLS|#@#|LAKE|LK|LAKES|LKS|#@#|LAND|LANDING|LNDG|LNDNG|#@#|LANE|LN|#@#|LIGHT|LGT|LIGHTS|LGTS|#@#|LOAF|LF|#@#|LOCK|LCK|LOCKS|LCKS|#@#|LODGE|LDG|LDGE|#@#|LOOP|LOOPS|#@#|MALL|#@#|MANOR|MNR|MANORS|MNRS|#@#|MEADOW|MDW|MEADOWS|MDWS|#@#|MEWS|#@#|MILL|ML|MILLS|MLS|#@#|MISSION|MISSN|MSN|MSSN|#@#|MOTORWAY|MTWY|#@#|MOUNT|MNT|MT|MOUNTAIN|MNTAIN|MTN|MNTN|MOUNTIN|MTIN|MOUNTAINS|MNTNS|MTNS|#@#|NECK|NCK|#@#|ORCHARD|ORCH|ORCHRD|#@#|OVAL|OVL|#@#|OVERPASS|OPAS|#@#|PARK|PRK|PARKS|#@#|PARKWAY|PARKWY|PKWAY|PKWY|PKY|PARKWAYS|PKWYS|#@#|PASS|PASSAGE|PSGE|#@#|#PATH#|#PATHS#|#@#|PIKE|PIKES|#@#|PINE|PNE|PINES|PNES|#@#|PLACE|PL|#@#|PLAIN|PLN|PLAINS|PLNS|#@#|PLAZA|PLZ|PLZA|#@#|#POINT#|PT|#POINTS#|PTS|#@#|PORT|PRT|PORTS|PRTS|#@#|PRAIRIE|PR|PRR|#@#|RADIAL|RAD|RADL|RADIEL|RADL|#@#|RAMP|#@#|RANCH|RNCH|RANCHES|RNCHS|#@#|RAPID|RPD|RAPIDS|RPDS|#@#|REST|RST|#@#|RIDGE|RDG|RDGE|RIDGES|RDGS|#@#|RIVER|RIV|RVR|RIVR|#@#|ROAD|RD|ROADS|RDS|#@#|ROUTE|RTE|#@#|ROW|#@#|RUE|#@#|#RUN#|#@#|SHOAL|SHL|SHL|SHOALS|SHLS|#@#|SHORE|SHOAR|SHR|SHORES|SHOARS|SHRS|#@#|SKYWAY|SKWY|#@#|SPRING|SPG|SPNG|SPRINGS|SPGS|SPNGS|#@#|SPUR|SPURS|#@#|SQUARE|SQ|SQR|SQRE|SQU|SQUARES|SQRS|#@#|STATION|STA|STATN|STN|#@#|STRAVENUE|STRA|STRAV|STRAVEN|STRAVN|STRVN|STRVNUE|#@#|STREAM|STRM|STREME|#@#|STREET|ST|STRT|STR|STREETS|STS|#@#|SUMMIT|SMT|SUMIT|SUMITT|SUMMIT|#@#|TERRACE|TER|TERR|#@#|THROUGHWAY|TRWY|#@#|TRACE|TRCE|TRACES|TRCE|#@#|TRACK|TRAK|TRACKS|TRAK|TRK|TRKS|#@#|TRAFFICWAY|TRFY|#@#|TRAIL|TRL|TRAILS|TRL|TRLS|#@#|TRAILER|TRLR|TRLRS|#@#|TUNNEL|TUNL|TUNLS|TUNNELS|TUNNL|#@#|TURNPIKE|TRNPK|TPKE|TURNPK|#@#|UNDERPASS|UPAS|#@#|UNION|UN|UNIONS|UNS|#@#|VALLEY|VLY|VALLY|VLLY|VLY|VALLEYS|VLYS|#@#|VIADUCT|VDCT|#VIA#|VIADCT|#@#|VIEW|VW|VIEWS|VWS|#@#|VILLAGE|VILL|VLG|VILLG|VILLIAGE|VILLAGES|VLGS|#@#|VILLE|VL|#@#|VISTA|VIS|VIST|VST|VSTA|#@#|#WALK#|#WALKS#|#@#|#WALL#|#@#|#WAY#|WY|#WAYS#|#@#|#WELL#|WL|WELLS|WLS|#@#)\\\\.?\\\\b|#@#)|(\\\\b\\\\d+\\\\s+(AVENUE|AV|AVE|AVEN|AVENU|AVN|AVNUE|#@#|HIGHWAY|HWY|HIWAY|HIWY|HWAY|#@#|ROAD|RD|ROADS|RDS|#@#|ROUTE|RTE|#@#|STREET|ST|STRT|STR|STREETS|STS|#@#)\\\\.?\\\\s+([A-z]|\\\\d+)\\\\b)\"\n",
    "non_address_pattern = \"\\\\b\\\\d+\\\\s+(am|pm|hrs?|hours?|mins?|minutes?|seconds?|#@#|days?|months?|mon|yr|yrs|years?|#@#|ft|feet|foot|in|inch(es)?|meters?|miles?|#@#|pounds?|pnd|ounce|oz|kg|kilograms?|grams?|tons?|#@#|gallons?|liters?|cubes?|volumes?|quarts?|bottles?|cups?|#@#|per|per\\\\s+cent|percent|degrees?|times?|#@#|dollars?|USD|GBP|hundreds?|thousands?|millions?|billions?|trillions?|#@#|from|to|at|and|or|were|are|Fan\\\\sClub|live|hurricane|exit|entrance|#@#|rescued|donation|people|patients|seniors|elderly|women|children|clergy|#@#)\\\\.?\\\\s+(#?[A-z]+\\\\.?(-[A-z]+)?\\\\s+){0,2}\\\\b(#@#|ANNEX|ANEX|ANNX|ANX|#@#|ARCADE|ARC|#@#|AVENUE|AV|AVE|AVEN|AVENU|AVN|AVNUE|#@#|BAYOU|BAYOO|BYU|BAYOU|#@#|BEACH|BCH|BEACH|#@#|BEND|BND|#@#|BLUFF|BLF|BLUF|BLUFFS|BLFS|#@#|BOTTOM|BOT|BTM|BOTTM|#@#|BOULEVARD|BLVD|BOUL|BOULV|#@#|BRANCH|BR|BRNCH|#@#|BRIDGE|BRDGE|BRG|#@#|BROOK|BRK|BROOKS|BRKS|#@#|BURG|BG|BURGS|BGS|#@#|BYPASS|BYP|BYPA|BYPAS|BYPS|#@#|CAMP|CP|CMP|#@#|CANYON|CANYN|CYN|CNYN|#@#|CAPE|CPE|#@#|CAUSEWAY|CSWY|CAUSWA|CSWY|#@#|CENTER|CEN|CTR|CENT|CENTR|CENTRE|CNTER|CNTR|CENTERS|CTRS|#@#|CIRCLE|CIR|CIRC|CIRCL|CRCL|CRCLE|CIRCLES|CIRS|#@#|CLIFF|CLF|CLIFFS|CLFS|CLIFFS|#@#|CLUB|CLB|#@#|COMMON|CMN|COMMONS|CMNS|#@#|CORNER|COR|CORNERS|CORS|#@#|COURSE|CRSE|#@#|COURT|CT|COURTS|CTS|#@#|COVE|CV|COVES|COVES|CVS|#@#|CREEK|CRK|#@#|CRESCENT|CRES|CRSENT|CRSNT|CREST|CRST|CR|#@#|CROSSING|CRSSNG|XING|#@#|CROSSROAD|XRD|CROSSROADS|XRDS|#@#|CURVE|CURV|#@#|DALE|DL|#@#|#DAM#|DM|#@#|DIVIDE|DIV|DV|DIVIDE|DVD|#@#|DRIVE|DR|DRIV|DRV|DRIVES|DRS|#@#|ESTATE|EST|ESTATES|ESTS|#@#|EXPRESSWAY|EXP|EXPY|EXPR|EXPRESS|EXPW|#@#|EXTENSION|EXT|EXTN|EXTNSN|EXTENSIONS|EXTS|#@#|FALL|FALLS|FLS|#@#|FERRY|FRY|FRRY|FRY|#@#|FIELD|FLD|FIELDS|FLDS|#@#|FLAT|FLT|FLATS|FLTS|#@#|FORD|FRD|FORDS|FRDS|#@#|FOREST|FRST|FORESTS|FRST|#@#|FORGE|FORG|FRG|FORGES|FRGS|#@#|FORK|FRK|FORKS|FRKS|#@#|FORT|FT|FRT|#@#|FREEWAY|FWY|FREEWY|FRWAY|FRWY|FWY|#@#|GARDEN|GDN|GRDN|GARDENS|GDNS|GRDNS|#@#|GATEWAY|GTWY|GATEWY|GATWAY|GTWAY|GTWY|#@#|GLEN|GLN|GLENS|GLNS|#@#|GREEN|GRN|GREENS|GRNS|#@#|GROVE|GROV|GRV|GROVES|GRVS|#@#|HARBOR|HARB|HBR|HARBR|HRBOR|HARBORS|HBRS|#@#|HAVEN|HVN|#@#|HEIGHTS|HT|HTS|#@#|HIGHWAY|HWY|HIWAY|HIWY|HWAY|HWY|#@#|HILL|HL|HILLS|HLS|#@#|HOLLOW|HLLW|HOLW|HOLLOWS|HOLWS|#@#|INLET|INLT|#@#|ISLAND|#IS#|ISLND|ISLANDS|ISS|ISLNDS|#@#|ISLE|ISLES|#@#|JUNCTION|JCT|JCTION|JCTN|JUNCTN|JUNCTON|JUNCTIONS|JCTNS|JCTS|JUNCTIONS|#@#|KEY|KY|KEYS|KYS|#@#|KNOLL|KNL|KNOL|KNOLLS|KNLS|#@#|LAKE|LK|LAKES|LKS|#@#|LAND|LANDING|LNDG|LNDNG|#@#|LANE|LN|#@#|LIGHT|LGT|LIGHTS|LGTS|#@#|LOAF|LF|#@#|LOCK|LCK|LOCKS|LCKS|#@#|LODGE|LDG|LDGE|#@#|LOOP|LOOPS|#@#|MALL|#@#|MANOR|MNR|MANORS|MNRS|#@#|MEADOW|MDW|MEADOWS|MDWS|#@#|MEWS|#@#|MILL|ML|MILLS|MLS|#@#|MISSION|MISSN|MSN|MSSN|#@#|MOTORWAY|MTWY|#@#|MOUNT|MNT|MT|MOUNTAIN|MNTAIN|MTN|MNTN|MOUNTIN|MTIN|MOUNTAINS|MNTNS|MTNS|#@#|NECK|NCK|#@#|ORCHARD|ORCH|ORCHRD|#@#|OVAL|OVL|#@#|OVERPASS|OPAS|#@#|PARK|PRK|PARKS|#@#|PARKWAY|PARKWY|PKWAY|PKWY|PKY|PARKWAYS|PKWYS|#@#|PASS|PASSAGE|PSGE|#@#|#PATH#|#PATHS#|#@#|PIKE|PIKES|#@#|PINE|PNE|PINES|PNES|#@#|PLACE|PL|#@#|PLAIN|PLN|PLAINS|PLNS|#@#|PLAZA|PLZ|PLZA|#@#|#POINT#|PT|#POINTS#|PTS|#@#|PORT|PRT|PORTS|PRTS|#@#|PRAIRIE|PR|PRR|#@#|RADIAL|RAD|RADL|RADIEL|RADL|#@#|RAMP|#@#|RANCH|RNCH|RANCHES|RNCHS|#@#|RAPID|RPD|RAPIDS|RPDS|#@#|REST|RST|#@#|RIDGE|RDG|RDGE|RIDGES|RDGS|#@#|RIVER|RIV|RVR|RIVR|#@#|ROAD|RD|ROADS|RDS|#@#|ROUTE|RTE|#@#|ROW|#@#|RUE|#@#|#RUN#|#@#|SHOAL|SHL|SHL|SHOALS|SHLS|#@#|SHORE|SHOAR|SHR|SHORES|SHOARS|SHRS|#@#|SKYWAY|SKWY|#@#|SPRING|SPG|SPNG|SPRINGS|SPGS|SPNGS|#@#|SPUR|SPURS|#@#|SQUARE|SQ|SQR|SQRE|SQU|SQUARES|SQRS|#@#|STATION|STA|STATN|STN|#@#|STRAVENUE|STRA|STRAV|STRAVEN|STRAVN|STRVN|STRVNUE|#@#|STREAM|STRM|STREME|#@#|STREET|ST|STRT|STR|STREETS|STS|#@#|SUMMIT|SMT|SUMIT|SUMITT|SUMMIT|#@#|TERRACE|TER|TERR|#@#|THROUGHWAY|TRWY|#@#|TRACE|TRCE|TRACES|TRCE|#@#|TRACK|TRAK|TRACKS|TRAK|TRK|TRKS|#@#|TRAFFICWAY|TRFY|#@#|TRAIL|TRL|TRAILS|TRL|TRLS|#@#|TRAILER|TRLR|TRLRS|#@#|TUNNEL|TUNL|TUNLS|TUNNELS|TUNNL|#@#|TURNPIKE|TRNPK|TPKE|TURNPK|#@#|UNDERPASS|UPAS|#@#|UNION|UN|UNIONS|UNS|#@#|VALLEY|VLY|VALLY|VLLY|VLY|VALLEYS|VLYS|#@#|VIADUCT|VDCT|#VIA#|VIADCT|#@#|VIEW|VW|VIEWS|VWS|#@#|VILLAGE|VILL|VLG|VILLG|VILLIAGE|VILLAGES|VLGS|#@#|VILLE|VL|#@#|VISTA|VIS|VIST|VST|VSTA|#@#|#WALK#|#WALKS#|#@#|#WALL#|#@#|#WAY#|WY|#WAYS#|#@#|#WELL#|WL|WELLS|WLS|#@#)\\\\.?\\\\b\"\n",
    "\n",
    "# ------ Create filter 4: with key words of tweets about political -------#\n",
    "rgx_f4 = \"\\\\b(realDonaldTrump|Trump|DonaldTrump|BarackObama|Obama|Election|Election2016|vote|republicans|republican|democrats|democrat|GOP|dems|immigrant|immigrants|climate\\\\s?change|gas\\\\s?prices|ICE|buzzfeed(news)?|tedcruz|SenTedCruz)\\\\b\"\n",
    "# all tweets about ICE and buzzfeed are polical ones\n",
    "\n",
    "# ------ Create filter 5: with key words of tweets about offering helps -------#\n",
    "rgx_f5 = \"\\\\b(donate|donating|donated|donations|Charity|Charities|church|shelters?|sheltering|(we|I)\\\\s+can\\\\s+help|open\\\\s+for\\\\s+helps?|drop\\\\s+off|HELP\\\\sthe\\\\s#?AmericanRedCross)\\\\b\"\n",
    "\n",
    "# ------ Create filter 6: with key words of tweets about commercial -------#\n",
    "rgx_f6 = \"\\\\$\\\\d+(.\\\\d{0,2})?|\\\\$\\\\$+|\\\\b(sales|for\\\\ssale|dollors|hundreds?|thousands?|millions?|billions?|trillions?|[A-z]*market)\\\\b\"\n",
    "# 2 regex, one  for market; one for open;\n",
    "\n",
    "\n",
    "# ------ Create filter 7: with key words of tweets of newsreport -------#\n",
    "rgx_f7 = \"#BREAKING:\\\\s+|\\\\b(Press\\\\sConference|Live\\\\svideo\\\\sfeed|Live\\\\sStream|County\\\\sUpdate:|National\\\\s+Hurricane\\\\s+Center|Tropical\\\\s+Storm\\\\s+Harvey|MANDATORY\\\\s+EVACUATION|After\\\\s+Hurricane\\\\s+Harvey|Ahead\\\\s+of\\\\s+Hurricane\\\\s+Harvey|like\\\\s+a\\\\s+river|6\\\\s+mil\\\\s+people|High\\\\s+call\\\\s+volume|Epic\\\\s+flooding|cameras?|webcam|\\\\bFM\\\\s+\\\\d+|News\\\\s+in\\\\s+the\\\\s+#?DMV)\\\\b\"\n",
    "# SOS tweet not likely use \"Tropical Storm Harvey\" or \"National Hurricane Center\"\n",
    "# typically used by news\n",
    "\n",
    "\n",
    "# ------ Create filter 8: rescue status update --------------#\n",
    "rgx_f8 = \"-\\\\sAwaiting\\\\sUpdates?\\\\b|-\\\\sRescued!\\\\s|\\\\b(Ha(ve|s)\\\\sBeen\\\\sRescued)\\\\b\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "### filter 1 final ####################\n",
    "Training_set['f1_1'] = Training_set.apply(lambda row: 1 if re.findall(rgx_f1_1,row['text'],re.IGNORECASE) else 0,axis=1)\n",
    "Training_set['f1_2'] = Training_set.apply(lambda row: 1 if re.findall(rgx_f1_2,row['text'],re.IGNORECASE) else 0,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "Training_set['f2'] = Training_set.apply(lambda row: 1 if re.findall(rgx_f2,row['text'],re.IGNORECASE) else 0,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "Training_set['f3_1'] = Training_set.apply(lambda row: 1 if re.findall(address_pattern,row['text'],re.IGNORECASE) else 0,axis=1)\n",
    "Training_set['f3_2'] = Training_set.apply(lambda row: 1 if re.findall(non_address_pattern,row['text'],re.IGNORECASE) else 0,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "Training_set['f4'] = Training_set.apply(lambda row: 1 if re.findall(rgx_f4,row['text'],re.IGNORECASE) else 0,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "Training_set['f5'] = Training_set.apply(lambda row: 1 if re.findall(rgx_f5,row['text'],re.IGNORECASE) else 0,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "Training_set['f6'] = Training_set.apply(lambda row: 1 if re.findall(rgx_f6,row['text'],re.IGNORECASE) else 0,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "Training_set['f7'] = Training_set.apply(lambda row: 1 if re.findall(rgx_f7,row['text'],re.IGNORECASE) else 0,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "Training_set['f8'] = Training_set.apply(lambda row: 1 if re.findall(rgx_f8,row['text'],re.IGNORECASE) else 0,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sos.correct</th>\n",
       "      <th>f1_1</th>\n",
       "      <th>f1_2</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3_1</th>\n",
       "      <th>f3_2</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#Harvey floods TV station #KHOU in #Houston. h...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@RandiRhodes RR call him out for visiting SA, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wow a tv station is flooding in Houston! So sc...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My son, dil &amp;amp; 2 grandkids in grand lakes, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>is the beltway still flooded? ya boy need to g...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5787</th>\n",
       "      <td>Around 10,000,000,000,000 gallons of water fro...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5788</th>\n",
       "      <td>The road to my residence is flooded. Thank God...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5789</th>\n",
       "      <td>Texas road closures and flooding kept up to da...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5790</th>\n",
       "      <td>@HellerWeather Tim, any maps to show where flo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5791</th>\n",
       "      <td>lrt more people died on the road trying to eva...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5792 rows √ó 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  sos.correct  f1_1  \\\n",
       "0     #Harvey floods TV station #KHOU in #Houston. h...            0     0   \n",
       "1     @RandiRhodes RR call him out for visiting SA, ...            0     0   \n",
       "2     Wow a tv station is flooding in Houston! So sc...            0     0   \n",
       "3     My son, dil &amp; 2 grandkids in grand lakes, ...            0     0   \n",
       "4     is the beltway still flooded? ya boy need to g...            0     0   \n",
       "...                                                 ...          ...   ...   \n",
       "5787  Around 10,000,000,000,000 gallons of water fro...            0     0   \n",
       "5788  The road to my residence is flooded. Thank God...            0     1   \n",
       "5789  Texas road closures and flooding kept up to da...            0     0   \n",
       "5790  @HellerWeather Tim, any maps to show where flo...            0     0   \n",
       "5791  lrt more people died on the road trying to eva...            0     1   \n",
       "\n",
       "      f1_2  f2  f3_1  f3_2  f4  f5  f6  f7  f8  \n",
       "0        0   0     0     0   0   0   0   0   0  \n",
       "1        0   0     0     0   0   1   0   0   0  \n",
       "2        0   0     0     0   0   0   0   0   0  \n",
       "3        0   1     1     0   0   0   0   0   0  \n",
       "4        0   0     0     0   0   0   0   0   0  \n",
       "...    ...  ..   ...   ...  ..  ..  ..  ..  ..  \n",
       "5787     0   0     0     0   0   0   0   0   0  \n",
       "5788     0   0     0     0   0   0   0   0   0  \n",
       "5789     0   0     0     0   0   0   0   0   0  \n",
       "5790     0   0     0     0   0   0   0   0   0  \n",
       "5791     0   0     0     0   0   0   0   0   0  \n",
       "\n",
       "[5792 rows x 12 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Training_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Clasification: evaluate the logical expression for each tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "Training_set['filter_sos'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logical_evaluation_address(x,y):\n",
    "    if x == 1:\n",
    "        if y == 0:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def logical_evaluation_final(x,y):\n",
    "    if x == 1:\n",
    "        if y == 0:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def evaluate_expression(f1_1,f1_2,f2,f3_1,f3_2,f4,f5,f6,f7,f8): \n",
    "    f1 = f1_1 or f1_2\n",
    "    f3 = logical_evaluation_address(f3_1,f3_2)\n",
    "    f1_union_f2= f1 or f2\n",
    "    f1_f2_intersect_f3 = f1_union_f2 and f3\n",
    "    \n",
    "    excluded_filters = f4 or f5 or f6 or f7 or f8\n",
    "    \n",
    "    return logical_evaluation_final(f1_f2_intersect_f3,excluded_filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "## run classifier ###\n",
    "Training_set['filter_sos'] = Training_set.apply(lambda row: 1 if evaluate_expression(row['f1_1'],row['f1_2'],row['f2'],row['f3_1'],row['f3_2'],row['f4'],row['f5'],row['f6'],row['f7'],row['f8']) else 0,axis=1)\n",
    "\n",
    "labels = Training_set['sos.correct']\n",
    "preds = Training_set['filter_sos']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_rescue = Training_set[Training_set['sos.correct'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sos.correct</th>\n",
       "      <th>f1_1</th>\n",
       "      <th>f1_2</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3_1</th>\n",
       "      <th>f3_2</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>filter_sos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Urgently need #WaterRescue at 10415 Merry Mead...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Folks looking for boat assistance near - Hardy...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>@houstonpolice please help my sister !! üôèüèªüôèüèª#h...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Elderly Frank Emmitte trapped in 3226 Ave G, D...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Grant rd &amp;amp; lake wood forest in houston. ne...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5166</th>\n",
       "      <td>@L0stSandal 777 Coolwood Dr Houston 8 Wk son n...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5167</th>\n",
       "      <td>.@houstonpolice help needed in 4055 South Brae...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5177</th>\n",
       "      <td>Please help my mother-in-law: a cancer patient...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5197</th>\n",
       "      <td>@HarveyRescue @HarveyRelief #HARVEY SOS: 2121 ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5601</th>\n",
       "      <td>Anyone with small boats over near norchester o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>253 rows √ó 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  sos.correct  f1_1  \\\n",
       "30    Urgently need #WaterRescue at 10415 Merry Mead...            1     1   \n",
       "42    Folks looking for boat assistance near - Hardy...            1     1   \n",
       "52    @houstonpolice please help my sister !! üôèüèªüôèüèª#h...            1     1   \n",
       "70    Elderly Frank Emmitte trapped in 3226 Ave G, D...            1     1   \n",
       "86    Grant rd &amp; lake wood forest in houston. ne...            1     1   \n",
       "...                                                 ...          ...   ...   \n",
       "5166  @L0stSandal 777 Coolwood Dr Houston 8 Wk son n...            1     1   \n",
       "5167  .@houstonpolice help needed in 4055 South Brae...            1     0   \n",
       "5177  Please help my mother-in-law: a cancer patient...            1     0   \n",
       "5197  @HarveyRescue @HarveyRelief #HARVEY SOS: 2121 ...            1     0   \n",
       "5601  Anyone with small boats over near norchester o...            1     0   \n",
       "\n",
       "      f1_2  f2  f3_1  f3_2  f4  f5  f6  f7  f8  filter_sos  \n",
       "30       0   1     1     0   0   0   0   0   0           1  \n",
       "42       0   1     0     0   0   0   0   0   0           0  \n",
       "52       0   1     1     0   0   0   0   0   0           1  \n",
       "70       1   1     1     0   0   0   0   0   0           1  \n",
       "86       0   1     0     0   0   0   0   0   0           0  \n",
       "...    ...  ..   ...   ...  ..  ..  ..  ..  ..         ...  \n",
       "5166     0   1     1     0   0   0   0   0   0           1  \n",
       "5167     1   1     1     0   0   0   0   0   0           1  \n",
       "5177     0   1     1     0   0   0   0   0   0           1  \n",
       "5197     0   1     1     0   0   0   0   0   0           1  \n",
       "5601     0   1     0     0   0   0   0   0   0           0  \n",
       "\n",
       "[253 rows x 13 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set_rescue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_rescue.to_csv('/home/wkhal001/Desktop/filtered_logical_positives.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Evaluation of the approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 0.9954586739327884,\n",
       "  'recall': 0.9893482578082686,\n",
       "  'f1-score': 0.9923940601231439,\n",
       "  'support': 5539},\n",
       " '1': {'precision': 0.794425087108014,\n",
       "  'recall': 0.9011857707509882,\n",
       "  'f1-score': 0.8444444444444444,\n",
       "  'support': 253},\n",
       " 'accuracy': 0.9854972375690608,\n",
       " 'macro avg': {'precision': 0.8949418805204012,\n",
       "  'recall': 0.9452670142796284,\n",
       "  'f1-score': 0.9184192522837942,\n",
       "  'support': 5792},\n",
       " 'weighted avg': {'precision': 0.9866773380442062,\n",
       "  'recall': 0.9854972375690608,\n",
       "  'f1-score': 0.9859314819520958,\n",
       "  'support': 5792}}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_r = classification_report(labels, preds,output_dict = True)\n",
    "\n",
    "dict_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "############# contextual words ###################\n",
    "##################################################\n",
    "\n",
    "# please help my sister\n",
    "# Urgently need\n",
    "# @houstonpolice\n",
    "# Needs help\n",
    "# trapped in\n",
    "# IN NEED OF RESCUE\n",
    "# Rescue for\n",
    "# need rescuing\n",
    "# Please send help\n",
    "# please help my friend\n",
    "# Please send help asap\n",
    "# we are stuck on\n",
    "# please share\n",
    "# still waiting for\n",
    "# PLZ HELP CALL 911\n",
    "# Please RT\n",
    "# Men stranded on\n",
    "# life in danger\n",
    "# RT emergency service\n",
    "# they are trapped inside\n",
    "# Pls send help \n",
    "# they need rescue help \n",
    "# have been trapped for\n",
    "# Please retweet\n",
    "\n",
    "#list_help_words_bigrams =[('please','help'),('Urgently','need'),('Needs','help'),('send','help'),('need','rescuing'),('PLZ','HELP')]\n",
    "#list_retweet_help_bigrams = [('please','RT'),('please','share'),('please','retweet')]#\n",
    "#list_situation_bigrams =[('stranded','in'),('trapped','inside')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "############# hashtags ###########################\n",
    "##################################################\n",
    "#HurricaneHarvey\n",
    "#houstonflood\n",
    "#Harveyflood\n",
    "#hurricaneharvey\n",
    "#WaterRescueNeeded\n",
    "#houston #harvey #HARVEYHELP #HarveyRelief #HarveyStorm\n",
    "#rescue #flood #Khou #harvey #help #retweet\n",
    "#Help \n",
    "#HarveyFlood #HarveyRelief #Relief #harveyhouston #Houston\n",
    "#harveysos\n",
    "#houston\n",
    "#harveyrescue #harveysos #harveystorm #Texas\n",
    "#sendhelp  #Urgent #Houstonfloods \n",
    "#Harveyflood\n",
    "#HoustonFloods #houstonPolice\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
